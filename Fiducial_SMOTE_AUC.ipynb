{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keg/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/keg/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/keg/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/keg/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/keg/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/keg/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/keg/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/home/keg/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/keg/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/keg/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/keg/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/keg/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/keg/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keg/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:80: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0118 15:57:29.594923 140462657562368 deprecation_wrapper.py:119] From /home/keg/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3484 samples, validate on 871 samples\n",
      "Epoch 1/200\n",
      " - 36s - loss: 2.6358 - auc: 0.8540 - val_loss: 2.1097 - val_auc: 0.9601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keg/anaconda3/lib/python3.6/site-packages/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `roc_accuracy` which is not available. Available metrics are: val_loss,val_auc,loss,auc,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200\n",
      " - 13s - loss: 2.0214 - auc: 0.9347 - val_loss: 1.3823 - val_auc: 0.9754\n",
      "Epoch 3/200\n",
      " - 13s - loss: 1.8939 - auc: 0.9421 - val_loss: 1.2972 - val_auc: 0.9780\n",
      "Epoch 4/200\n",
      " - 13s - loss: 1.8898 - auc: 0.9404 - val_loss: 1.2862 - val_auc: 0.9782\n",
      "Epoch 5/200\n",
      " - 14s - loss: 1.8236 - auc: 0.9453 - val_loss: 1.2521 - val_auc: 0.9776\n",
      "Epoch 6/200\n",
      " - 14s - loss: 1.7379 - auc: 0.9508 - val_loss: 1.2360 - val_auc: 0.9781\n",
      "Epoch 7/200\n",
      " - 14s - loss: 1.7182 - auc: 0.9498 - val_loss: 1.2651 - val_auc: 0.9784\n",
      "Epoch 8/200\n",
      " - 13s - loss: 1.7413 - auc: 0.9501 - val_loss: 1.2083 - val_auc: 0.9789\n",
      "Epoch 9/200\n",
      " - 12s - loss: 1.6875 - auc: 0.9528 - val_loss: 1.2339 - val_auc: 0.9780\n",
      "Epoch 10/200\n",
      " - 13s - loss: 1.6478 - auc: 0.9565 - val_loss: 1.2019 - val_auc: 0.9801\n",
      "Epoch 11/200\n",
      " - 16s - loss: 1.6607 - auc: 0.9551 - val_loss: 1.1709 - val_auc: 0.9787\n",
      "Epoch 12/200\n",
      " - 17s - loss: 1.6416 - auc: 0.9532 - val_loss: 1.1474 - val_auc: 0.9840\n",
      "Epoch 13/200\n",
      " - 17s - loss: 1.5726 - auc: 0.9599 - val_loss: 1.1581 - val_auc: 0.9797\n",
      "Epoch 14/200\n",
      " - 17s - loss: 1.6158 - auc: 0.9563 - val_loss: 1.1404 - val_auc: 0.9836\n",
      "Epoch 15/200\n",
      " - 18s - loss: 1.6069 - auc: 0.9564 - val_loss: 1.2171 - val_auc: 0.9804\n",
      "Epoch 16/200\n",
      " - 19s - loss: 1.6100 - auc: 0.9580 - val_loss: 1.1593 - val_auc: 0.9814\n",
      "Epoch 17/200\n",
      " - 19s - loss: 1.5581 - auc: 0.9609 - val_loss: 1.1499 - val_auc: 0.9826\n",
      "Epoch 18/200\n",
      " - 19s - loss: 1.5960 - auc: 0.9583 - val_loss: 1.1662 - val_auc: 0.9813\n",
      "Epoch 19/200\n",
      " - 19s - loss: 1.5539 - auc: 0.9595 - val_loss: 1.1504 - val_auc: 0.9819\n",
      "Epoch 20/200\n",
      " - 19s - loss: 1.5616 - auc: 0.9626 - val_loss: 1.1075 - val_auc: 0.9806\n",
      "Epoch 21/200\n",
      " - 19s - loss: 1.5191 - auc: 0.9631 - val_loss: 1.1348 - val_auc: 0.9818\n",
      "Epoch 22/200\n",
      " - 19s - loss: 1.5154 - auc: 0.9625 - val_loss: 1.0523 - val_auc: 0.9860\n",
      "Epoch 23/200\n",
      " - 19s - loss: 1.5106 - auc: 0.9628 - val_loss: 1.1087 - val_auc: 0.9843\n",
      "Epoch 24/200\n",
      " - 19s - loss: 1.5374 - auc: 0.9614 - val_loss: 1.0792 - val_auc: 0.9841\n",
      "Epoch 25/200\n",
      " - 19s - loss: 1.5597 - auc: 0.9601 - val_loss: 1.0833 - val_auc: 0.9829\n",
      "Epoch 26/200\n",
      " - 19s - loss: 1.5283 - auc: 0.9626 - val_loss: 1.0785 - val_auc: 0.9844\n",
      "Epoch 27/200\n",
      " - 19s - loss: 1.5029 - auc: 0.9613 - val_loss: 1.0750 - val_auc: 0.9839\n",
      "Epoch 28/200\n",
      " - 19s - loss: 1.5315 - auc: 0.9608 - val_loss: 1.0996 - val_auc: 0.9841\n",
      "Epoch 29/200\n",
      " - 19s - loss: 1.5049 - auc: 0.9618 - val_loss: 1.0875 - val_auc: 0.9868\n",
      "Epoch 30/200\n",
      " - 19s - loss: 1.5396 - auc: 0.9608 - val_loss: 1.0958 - val_auc: 0.9855\n",
      "Epoch 31/200\n",
      " - 19s - loss: 1.4613 - auc: 0.9655 - val_loss: 1.0969 - val_auc: 0.9844\n",
      "Epoch 32/200\n",
      " - 19s - loss: 1.5154 - auc: 0.9623 - val_loss: 1.0675 - val_auc: 0.9842\n",
      "Epoch 33/200\n",
      " - 19s - loss: 1.4849 - auc: 0.9642 - val_loss: 1.0778 - val_auc: 0.9838\n",
      "Epoch 34/200\n",
      " - 19s - loss: 1.4374 - auc: 0.9670 - val_loss: 1.0687 - val_auc: 0.9841\n",
      "Epoch 35/200\n",
      " - 19s - loss: 1.4746 - auc: 0.9638 - val_loss: 1.0347 - val_auc: 0.9867\n",
      "Epoch 36/200\n",
      " - 19s - loss: 1.4901 - auc: 0.9630 - val_loss: 1.0185 - val_auc: 0.9854\n",
      "Epoch 37/200\n",
      " - 19s - loss: 1.4543 - auc: 0.9648 - val_loss: 1.0844 - val_auc: 0.9847\n",
      "Epoch 38/200\n",
      " - 19s - loss: 1.4684 - auc: 0.9651 - val_loss: 1.0288 - val_auc: 0.9856\n",
      "Epoch 39/200\n",
      " - 19s - loss: 1.4775 - auc: 0.9632 - val_loss: 1.1417 - val_auc: 0.9829\n",
      "Epoch 40/200\n",
      " - 19s - loss: 1.4709 - auc: 0.9639 - val_loss: 1.0018 - val_auc: 0.9874\n",
      "Epoch 41/200\n",
      " - 19s - loss: 1.4559 - auc: 0.9651 - val_loss: 1.0653 - val_auc: 0.9860\n",
      "Epoch 42/200\n",
      " - 19s - loss: 1.4183 - auc: 0.9681 - val_loss: 1.0398 - val_auc: 0.9862\n",
      "Epoch 43/200\n",
      " - 19s - loss: 1.4369 - auc: 0.9660 - val_loss: 1.0326 - val_auc: 0.9842\n",
      "Epoch 44/200\n",
      " - 19s - loss: 1.4128 - auc: 0.9687 - val_loss: 1.0788 - val_auc: 0.9855\n",
      "Epoch 45/200\n",
      " - 19s - loss: 1.4666 - auc: 0.9652 - val_loss: 1.0690 - val_auc: 0.9867\n",
      "Epoch 46/200\n",
      " - 19s - loss: 1.4910 - auc: 0.9617 - val_loss: 1.0264 - val_auc: 0.9874\n",
      "Epoch 47/200\n",
      " - 19s - loss: 1.4549 - auc: 0.9643 - val_loss: 1.0496 - val_auc: 0.9873\n",
      "Epoch 48/200\n",
      " - 19s - loss: 1.4666 - auc: 0.9650 - val_loss: 1.0163 - val_auc: 0.9875\n",
      "Epoch 49/200\n",
      " - 19s - loss: 1.4499 - auc: 0.9644 - val_loss: 1.0151 - val_auc: 0.9873\n",
      "Epoch 50/200\n",
      " - 19s - loss: 1.4800 - auc: 0.9637 - val_loss: 0.9805 - val_auc: 0.9878\n",
      "Epoch 51/200\n",
      " - 19s - loss: 1.4399 - auc: 0.9656 - val_loss: 1.0393 - val_auc: 0.9864\n",
      "Epoch 52/200\n",
      " - 19s - loss: 1.4688 - auc: 0.9641 - val_loss: 1.0785 - val_auc: 0.9852\n",
      "Epoch 53/200\n",
      " - 19s - loss: 1.4116 - auc: 0.9681 - val_loss: 1.0958 - val_auc: 0.9834\n",
      "Epoch 54/200\n",
      " - 19s - loss: 1.4109 - auc: 0.9680 - val_loss: 1.0202 - val_auc: 0.9876\n",
      "Epoch 55/200\n",
      " - 19s - loss: 1.3787 - auc: 0.9697 - val_loss: 1.0147 - val_auc: 0.9856\n",
      "Epoch 56/200\n",
      " - 19s - loss: 1.3906 - auc: 0.9681 - val_loss: 0.9999 - val_auc: 0.9873\n",
      "Epoch 57/200\n",
      " - 19s - loss: 1.4259 - auc: 0.9673 - val_loss: 0.9937 - val_auc: 0.9872\n",
      "Epoch 58/200\n",
      " - 19s - loss: 1.3926 - auc: 0.9700 - val_loss: 0.9897 - val_auc: 0.9873\n",
      "Epoch 59/200\n",
      " - 19s - loss: 1.3925 - auc: 0.9686 - val_loss: 1.0358 - val_auc: 0.9858\n",
      "Epoch 60/200\n",
      " - 19s - loss: 1.3928 - auc: 0.9679 - val_loss: 0.9650 - val_auc: 0.9878\n",
      "Epoch 61/200\n",
      " - 19s - loss: 1.4588 - auc: 0.9658 - val_loss: 1.0256 - val_auc: 0.9868\n",
      "Epoch 62/200\n",
      " - 19s - loss: 1.4393 - auc: 0.9644 - val_loss: 0.9656 - val_auc: 0.9881\n",
      "Epoch 63/200\n",
      " - 19s - loss: 1.4167 - auc: 0.9681 - val_loss: 1.0052 - val_auc: 0.9873\n",
      "Epoch 64/200\n",
      " - 19s - loss: 1.4278 - auc: 0.9643 - val_loss: 0.9977 - val_auc: 0.9872\n",
      "Epoch 65/200\n",
      " - 19s - loss: 1.3885 - auc: 0.9692 - val_loss: 0.9881 - val_auc: 0.9888\n",
      "Epoch 66/200\n",
      " - 19s - loss: 1.4080 - auc: 0.9687 - val_loss: 1.0522 - val_auc: 0.9847\n",
      "Epoch 67/200\n",
      " - 19s - loss: 1.3395 - auc: 0.9724 - val_loss: 0.9986 - val_auc: 0.9871\n",
      "Epoch 68/200\n",
      " - 19s - loss: 1.4144 - auc: 0.9679 - val_loss: 1.0088 - val_auc: 0.9875\n",
      "Epoch 69/200\n",
      " - 19s - loss: 1.4146 - auc: 0.9666 - val_loss: 1.0243 - val_auc: 0.9870\n",
      "Epoch 70/200\n",
      " - 19s - loss: 1.3807 - auc: 0.9676 - val_loss: 1.0275 - val_auc: 0.9863\n",
      "Epoch 71/200\n",
      " - 19s - loss: 1.4037 - auc: 0.9681 - val_loss: 0.9943 - val_auc: 0.9881\n",
      "Epoch 72/200\n",
      " - 19s - loss: 1.3814 - auc: 0.9693 - val_loss: 1.0016 - val_auc: 0.9879\n",
      "Epoch 73/200\n",
      " - 19s - loss: 1.3937 - auc: 0.9677 - val_loss: 0.9884 - val_auc: 0.9882\n",
      "Epoch 74/200\n",
      " - 19s - loss: 1.3936 - auc: 0.9688 - val_loss: 1.0547 - val_auc: 0.9868\n",
      "Epoch 75/200\n",
      " - 19s - loss: 1.3653 - auc: 0.9693 - val_loss: 1.0508 - val_auc: 0.9858\n",
      "Epoch 76/200\n",
      " - 19s - loss: 1.3838 - auc: 0.9690 - val_loss: 1.0533 - val_auc: 0.9860\n",
      "Epoch 77/200\n",
      " - 19s - loss: 1.3726 - auc: 0.9702 - val_loss: 1.0040 - val_auc: 0.9870\n",
      "Epoch 78/200\n",
      " - 19s - loss: 1.4250 - auc: 0.9671 - val_loss: 0.9553 - val_auc: 0.9893\n",
      "Epoch 79/200\n",
      " - 19s - loss: 1.3976 - auc: 0.9682 - val_loss: 1.0043 - val_auc: 0.9875\n",
      "Epoch 80/200\n",
      " - 19s - loss: 1.3552 - auc: 0.9717 - val_loss: 1.0413 - val_auc: 0.9867\n",
      "Epoch 81/200\n",
      " - 19s - loss: 1.3890 - auc: 0.9690 - val_loss: 1.0350 - val_auc: 0.9858\n",
      "Epoch 82/200\n",
      " - 19s - loss: 1.3957 - auc: 0.9690 - val_loss: 0.9630 - val_auc: 0.9883\n",
      "Epoch 83/200\n",
      " - 19s - loss: 1.3879 - auc: 0.9686 - val_loss: 1.0464 - val_auc: 0.9869\n",
      "Epoch 84/200\n",
      " - 19s - loss: 1.3825 - auc: 0.9688 - val_loss: 0.9701 - val_auc: 0.9882\n",
      "Epoch 85/200\n",
      " - 19s - loss: 1.3730 - auc: 0.9703 - val_loss: 1.0023 - val_auc: 0.9870\n",
      "Epoch 86/200\n",
      " - 19s - loss: 1.3721 - auc: 0.9702 - val_loss: 1.0367 - val_auc: 0.9866\n",
      "Epoch 87/200\n",
      " - 19s - loss: 1.3704 - auc: 0.9695 - val_loss: 0.9691 - val_auc: 0.9882\n",
      "Epoch 88/200\n",
      " - 19s - loss: 1.3116 - auc: 0.9729 - val_loss: 0.9738 - val_auc: 0.9877\n",
      "Epoch 89/200\n",
      " - 19s - loss: 1.3178 - auc: 0.9718 - val_loss: 1.0080 - val_auc: 0.9870\n",
      "Epoch 90/200\n",
      " - 19s - loss: 1.3864 - auc: 0.9694 - val_loss: 1.0502 - val_auc: 0.9859\n",
      "Epoch 91/200\n",
      " - 19s - loss: 1.3807 - auc: 0.9701 - val_loss: 1.0159 - val_auc: 0.9872\n",
      "Epoch 92/200\n",
      " - 19s - loss: 1.3873 - auc: 0.9677 - val_loss: 0.9642 - val_auc: 0.9884\n",
      "Epoch 93/200\n",
      " - 19s - loss: 1.3570 - auc: 0.9694 - val_loss: 0.9611 - val_auc: 0.9872\n",
      "Epoch 94/200\n",
      " - 19s - loss: 1.3544 - auc: 0.9713 - val_loss: 0.9886 - val_auc: 0.9878\n",
      "Epoch 95/200\n",
      " - 19s - loss: 1.3437 - auc: 0.9704 - val_loss: 0.9978 - val_auc: 0.9863\n",
      "Epoch 96/200\n",
      " - 19s - loss: 1.3553 - auc: 0.9686 - val_loss: 0.9790 - val_auc: 0.9882\n",
      "Epoch 97/200\n",
      " - 19s - loss: 1.3563 - auc: 0.9690 - val_loss: 1.0313 - val_auc: 0.9864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/200\n",
      " - 19s - loss: 1.3558 - auc: 0.9719 - val_loss: 1.0185 - val_auc: 0.9864\n",
      "Epoch 99/200\n",
      " - 19s - loss: 1.3419 - auc: 0.9719 - val_loss: 1.0865 - val_auc: 0.9844\n",
      "Epoch 100/200\n",
      " - 19s - loss: 1.3361 - auc: 0.9718 - val_loss: 1.0266 - val_auc: 0.9866\n",
      "Epoch 101/200\n",
      " - 19s - loss: 1.3687 - auc: 0.9699 - val_loss: 0.9858 - val_auc: 0.9866\n",
      "Epoch 102/200\n",
      " - 19s - loss: 1.3493 - auc: 0.9695 - val_loss: 1.0592 - val_auc: 0.9856\n",
      "Epoch 103/200\n",
      " - 19s - loss: 1.3461 - auc: 0.9694 - val_loss: 0.9511 - val_auc: 0.9887\n",
      "Epoch 104/200\n",
      " - 19s - loss: 1.3459 - auc: 0.9706 - val_loss: 1.0299 - val_auc: 0.9862\n",
      "Epoch 105/200\n",
      " - 19s - loss: 1.3868 - auc: 0.9674 - val_loss: 0.9949 - val_auc: 0.9878\n",
      "Epoch 106/200\n",
      " - 19s - loss: 1.3105 - auc: 0.9722 - val_loss: 1.0170 - val_auc: 0.9869\n",
      "Epoch 107/200\n",
      " - 19s - loss: 1.3258 - auc: 0.9720 - val_loss: 1.0099 - val_auc: 0.9867\n",
      "Epoch 108/200\n",
      " - 19s - loss: 1.3253 - auc: 0.9719 - val_loss: 0.9975 - val_auc: 0.9866\n",
      "Epoch 109/200\n",
      " - 19s - loss: 1.3399 - auc: 0.9711 - val_loss: 0.9728 - val_auc: 0.9876\n",
      "Epoch 110/200\n",
      " - 19s - loss: 1.3552 - auc: 0.9694 - val_loss: 0.9553 - val_auc: 0.9885\n",
      "Epoch 111/200\n",
      " - 19s - loss: 1.3524 - auc: 0.9696 - val_loss: 1.0475 - val_auc: 0.9860\n",
      "Epoch 112/200\n",
      " - 19s - loss: 1.3394 - auc: 0.9699 - val_loss: 0.9694 - val_auc: 0.9870\n",
      "Epoch 113/200\n",
      " - 19s - loss: 1.3962 - auc: 0.9682 - val_loss: 0.9569 - val_auc: 0.9898\n",
      "Epoch 114/200\n",
      " - 19s - loss: 1.3233 - auc: 0.9722 - val_loss: 0.9995 - val_auc: 0.9876\n",
      "Epoch 115/200\n",
      " - 19s - loss: 1.4334 - auc: 0.9673 - val_loss: 0.9763 - val_auc: 0.9876\n",
      "Epoch 116/200\n",
      " - 19s - loss: 1.3364 - auc: 0.9703 - val_loss: 0.9957 - val_auc: 0.9857\n",
      "Epoch 117/200\n",
      " - 19s - loss: 1.3150 - auc: 0.9726 - val_loss: 0.9514 - val_auc: 0.9889\n",
      "Epoch 118/200\n",
      " - 19s - loss: 1.3198 - auc: 0.9716 - val_loss: 0.9661 - val_auc: 0.9885\n",
      "Epoch 119/200\n",
      " - 19s - loss: 1.3304 - auc: 0.9706 - val_loss: 1.0166 - val_auc: 0.9864\n",
      "Epoch 120/200\n",
      " - 19s - loss: 1.3234 - auc: 0.9709 - val_loss: 1.0025 - val_auc: 0.9877\n",
      "Epoch 121/200\n",
      " - 19s - loss: 1.4143 - auc: 0.9658 - val_loss: 0.9808 - val_auc: 0.9880\n",
      "Epoch 122/200\n",
      " - 19s - loss: 1.3093 - auc: 0.9727 - val_loss: 0.9508 - val_auc: 0.9882\n",
      "Epoch 123/200\n",
      " - 19s - loss: 1.3209 - auc: 0.9706 - val_loss: 1.0071 - val_auc: 0.9875\n",
      "Epoch 124/200\n",
      " - 19s - loss: 1.3218 - auc: 0.9704 - val_loss: 0.9359 - val_auc: 0.9891\n",
      "Epoch 125/200\n",
      " - 19s - loss: 1.3176 - auc: 0.9716 - val_loss: 0.9358 - val_auc: 0.9886\n",
      "Epoch 126/200\n",
      " - 19s - loss: 1.3551 - auc: 0.9700 - val_loss: 0.9562 - val_auc: 0.9889\n",
      "Epoch 127/200\n",
      " - 19s - loss: 1.3147 - auc: 0.9723 - val_loss: 0.9658 - val_auc: 0.9884\n",
      "Epoch 128/200\n",
      " - 19s - loss: 1.3208 - auc: 0.9728 - val_loss: 0.9508 - val_auc: 0.9884\n",
      "Epoch 129/200\n",
      " - 19s - loss: 1.3249 - auc: 0.9709 - val_loss: 0.9759 - val_auc: 0.9869\n",
      "Epoch 130/200\n",
      " - 19s - loss: 1.2970 - auc: 0.9729 - val_loss: 0.9728 - val_auc: 0.9874\n",
      "Epoch 131/200\n",
      " - 19s - loss: 1.3262 - auc: 0.9710 - val_loss: 0.9902 - val_auc: 0.9882\n",
      "Epoch 132/200\n",
      " - 19s - loss: 1.3281 - auc: 0.9717 - val_loss: 0.9494 - val_auc: 0.9888\n",
      "Epoch 133/200\n",
      " - 19s - loss: 1.3020 - auc: 0.9729 - val_loss: 0.9047 - val_auc: 0.9896\n",
      "Epoch 134/200\n",
      " - 19s - loss: 1.3076 - auc: 0.9728 - val_loss: 1.0317 - val_auc: 0.9862\n",
      "Epoch 135/200\n",
      " - 19s - loss: 1.3217 - auc: 0.9721 - val_loss: 1.0070 - val_auc: 0.9868\n",
      "Epoch 136/200\n",
      " - 19s - loss: 1.3413 - auc: 0.9703 - val_loss: 1.0180 - val_auc: 0.9870\n",
      "Epoch 137/200\n",
      " - 19s - loss: 1.2957 - auc: 0.9722 - val_loss: 1.0167 - val_auc: 0.9855\n",
      "Epoch 138/200\n",
      " - 19s - loss: 1.3361 - auc: 0.9725 - val_loss: 0.9650 - val_auc: 0.9884\n",
      "Epoch 139/200\n",
      " - 19s - loss: 1.2632 - auc: 0.9743 - val_loss: 0.9448 - val_auc: 0.9886\n",
      "Epoch 140/200\n",
      " - 19s - loss: 1.3154 - auc: 0.9716 - val_loss: 0.9822 - val_auc: 0.9875\n",
      "Epoch 141/200\n",
      " - 19s - loss: 1.3011 - auc: 0.9729 - val_loss: 1.0196 - val_auc: 0.9861\n",
      "Epoch 142/200\n",
      " - 19s - loss: 1.3315 - auc: 0.9714 - val_loss: 0.9879 - val_auc: 0.9882\n",
      "Epoch 143/200\n",
      " - 19s - loss: 1.2647 - auc: 0.9750 - val_loss: 0.9299 - val_auc: 0.9895\n",
      "Epoch 144/200\n",
      " - 19s - loss: 1.3671 - auc: 0.9701 - val_loss: 0.9423 - val_auc: 0.9894\n",
      "Epoch 145/200\n",
      " - 19s - loss: 1.3249 - auc: 0.9723 - val_loss: 1.0758 - val_auc: 0.9859\n",
      "Epoch 146/200\n",
      " - 19s - loss: 1.3155 - auc: 0.9719 - val_loss: 0.9402 - val_auc: 0.9895\n",
      "Epoch 147/200\n",
      " - 19s - loss: 1.2950 - auc: 0.9720 - val_loss: 0.9220 - val_auc: 0.9898\n",
      "Epoch 148/200\n",
      " - 19s - loss: 1.2915 - auc: 0.9744 - val_loss: 0.9715 - val_auc: 0.9881\n",
      "Epoch 149/200\n",
      " - 19s - loss: 1.3043 - auc: 0.9734 - val_loss: 0.9548 - val_auc: 0.9879\n",
      "Epoch 150/200\n",
      " - 19s - loss: 1.2782 - auc: 0.9738 - val_loss: 0.9483 - val_auc: 0.9871\n",
      "Epoch 151/200\n",
      " - 19s - loss: 1.3332 - auc: 0.9713 - val_loss: 0.9832 - val_auc: 0.9890\n",
      "Epoch 152/200\n",
      " - 19s - loss: 1.2920 - auc: 0.9721 - val_loss: 0.9714 - val_auc: 0.9883\n",
      "Epoch 153/200\n",
      " - 19s - loss: 1.2859 - auc: 0.9742 - val_loss: 0.9473 - val_auc: 0.9895\n",
      "Epoch 154/200\n",
      " - 19s - loss: 1.3062 - auc: 0.9719 - val_loss: 0.9192 - val_auc: 0.9895\n",
      "Epoch 155/200\n",
      " - 19s - loss: 1.3331 - auc: 0.9710 - val_loss: 0.8932 - val_auc: 0.9905\n",
      "Epoch 156/200\n",
      " - 19s - loss: 1.3115 - auc: 0.9730 - val_loss: 1.0652 - val_auc: 0.9858\n",
      "Epoch 157/200\n",
      " - 19s - loss: 1.2927 - auc: 0.9742 - val_loss: 0.9826 - val_auc: 0.9882\n",
      "Epoch 158/200\n",
      " - 19s - loss: 1.2696 - auc: 0.9747 - val_loss: 0.9629 - val_auc: 0.9885\n",
      "Epoch 159/200\n",
      " - 19s - loss: 1.3729 - auc: 0.9696 - val_loss: 0.9531 - val_auc: 0.9894\n",
      "Epoch 160/200\n",
      " - 19s - loss: 1.3280 - auc: 0.9714 - val_loss: 1.0133 - val_auc: 0.9875\n",
      "Epoch 161/200\n",
      " - 19s - loss: 1.2516 - auc: 0.9758 - val_loss: 0.9461 - val_auc: 0.9888\n",
      "Epoch 162/200\n",
      " - 19s - loss: 1.2997 - auc: 0.9714 - val_loss: 1.0247 - val_auc: 0.9872\n",
      "Epoch 163/200\n",
      " - 19s - loss: 1.3141 - auc: 0.9732 - val_loss: 0.9241 - val_auc: 0.9893\n",
      "Epoch 164/200\n",
      " - 19s - loss: 1.2489 - auc: 0.9753 - val_loss: 0.9767 - val_auc: 0.9865\n",
      "Epoch 165/200\n",
      " - 19s - loss: 1.2620 - auc: 0.9733 - val_loss: 1.0225 - val_auc: 0.9860\n",
      "Epoch 166/200\n",
      " - 19s - loss: 1.3239 - auc: 0.9716 - val_loss: 1.0079 - val_auc: 0.9866\n",
      "Epoch 167/200\n",
      " - 19s - loss: 1.3185 - auc: 0.9724 - val_loss: 0.9779 - val_auc: 0.9888\n",
      "Epoch 168/200\n",
      " - 19s - loss: 1.2577 - auc: 0.9752 - val_loss: 0.8886 - val_auc: 0.9910\n",
      "Epoch 169/200\n",
      " - 19s - loss: 1.2728 - auc: 0.9731 - val_loss: 0.9133 - val_auc: 0.9903\n",
      "Epoch 170/200\n",
      " - 19s - loss: 1.3087 - auc: 0.9695 - val_loss: 0.9837 - val_auc: 0.9878\n",
      "Epoch 171/200\n",
      " - 19s - loss: 1.2555 - auc: 0.9759 - val_loss: 0.9673 - val_auc: 0.9890\n",
      "Epoch 172/200\n",
      " - 19s - loss: 1.3102 - auc: 0.9722 - val_loss: 0.9744 - val_auc: 0.9890\n",
      "Epoch 173/200\n",
      " - 19s - loss: 1.3369 - auc: 0.9716 - val_loss: 1.0062 - val_auc: 0.9869\n",
      "Epoch 174/200\n",
      " - 19s - loss: 1.3277 - auc: 0.9717 - val_loss: 0.9707 - val_auc: 0.9885\n",
      "Epoch 175/200\n",
      " - 19s - loss: 1.2780 - auc: 0.9730 - val_loss: 0.9566 - val_auc: 0.9867\n",
      "Epoch 176/200\n",
      " - 19s - loss: 1.2951 - auc: 0.9738 - val_loss: 0.9232 - val_auc: 0.9871\n",
      "Epoch 177/200\n",
      " - 19s - loss: 1.2560 - auc: 0.9733 - val_loss: 0.9766 - val_auc: 0.9873\n",
      "Epoch 178/200\n",
      " - 19s - loss: 1.3372 - auc: 0.9711 - val_loss: 0.9803 - val_auc: 0.9886\n",
      "Epoch 179/200\n",
      " - 19s - loss: 1.2657 - auc: 0.9756 - val_loss: 0.9812 - val_auc: 0.9880\n",
      "Epoch 180/200\n",
      " - 19s - loss: 1.3163 - auc: 0.9712 - val_loss: 0.9015 - val_auc: 0.9896\n",
      "Epoch 181/200\n",
      " - 19s - loss: 1.2874 - auc: 0.9740 - val_loss: 1.0049 - val_auc: 0.9875\n",
      "Epoch 182/200\n",
      " - 19s - loss: 1.3040 - auc: 0.9720 - val_loss: 0.9418 - val_auc: 0.9886\n",
      "Epoch 183/200\n",
      " - 19s - loss: 1.3085 - auc: 0.9711 - val_loss: 0.9327 - val_auc: 0.9889\n",
      "Epoch 184/200\n",
      " - 19s - loss: 1.3021 - auc: 0.9733 - val_loss: 0.9324 - val_auc: 0.9902\n",
      "Epoch 185/200\n",
      " - 19s - loss: 1.2927 - auc: 0.9734 - val_loss: 1.0207 - val_auc: 0.9878\n",
      "Epoch 186/200\n",
      " - 19s - loss: 1.2761 - auc: 0.9734 - val_loss: 0.9184 - val_auc: 0.9897\n",
      "Epoch 187/200\n",
      " - 19s - loss: 1.2908 - auc: 0.9728 - val_loss: 0.9358 - val_auc: 0.9903\n",
      "Epoch 188/200\n",
      " - 19s - loss: 1.2606 - auc: 0.9751 - val_loss: 0.9682 - val_auc: 0.9897\n",
      "Epoch 189/200\n",
      " - 19s - loss: 1.2545 - auc: 0.9751 - val_loss: 0.9438 - val_auc: 0.9883\n",
      "Epoch 190/200\n",
      " - 19s - loss: 1.2755 - auc: 0.9719 - val_loss: 0.8815 - val_auc: 0.9903\n",
      "Epoch 191/200\n",
      " - 19s - loss: 1.2658 - auc: 0.9742 - val_loss: 0.9014 - val_auc: 0.9906\n",
      "Epoch 192/200\n",
      " - 19s - loss: 1.2639 - auc: 0.9737 - val_loss: 0.9589 - val_auc: 0.9883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/200\n",
      " - 19s - loss: 1.2880 - auc: 0.9729 - val_loss: 0.9379 - val_auc: 0.9877\n",
      "Epoch 194/200\n",
      " - 19s - loss: 1.3014 - auc: 0.9723 - val_loss: 0.9925 - val_auc: 0.9875\n",
      "Epoch 195/200\n",
      " - 19s - loss: 1.2504 - auc: 0.9753 - val_loss: 0.9394 - val_auc: 0.9884\n",
      "Epoch 196/200\n",
      " - 19s - loss: 1.2499 - auc: 0.9745 - val_loss: 0.9409 - val_auc: 0.9892\n",
      "Epoch 197/200\n",
      " - 19s - loss: 1.2960 - auc: 0.9731 - val_loss: 0.9308 - val_auc: 0.9898\n",
      "Epoch 198/200\n",
      " - 19s - loss: 1.2979 - auc: 0.9714 - val_loss: 0.9313 - val_auc: 0.9885\n",
      "Epoch 199/200\n",
      " - 19s - loss: 1.2636 - auc: 0.9742 - val_loss: 0.9816 - val_auc: 0.9868\n",
      "Epoch 200/200\n",
      " - 19s - loss: 1.2940 - auc: 0.9738 - val_loss: 0.9177 - val_auc: 0.9889\n",
      "Original,AUSAIC Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keg/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:80: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6200 samples, validate on 871 samples\n",
      "Epoch 1/200\n",
      " - 60s - loss: 2.3976 - auc: 0.8871 - val_loss: 1.5573 - val_auc: 0.9694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keg/anaconda3/lib/python3.6/site-packages/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `roc_accuracy` which is not available. Available metrics are: val_loss,val_auc,loss,auc,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200\n",
      " - 31s - loss: 1.8733 - auc: 0.9427 - val_loss: 1.3895 - val_auc: 0.9762\n",
      "Epoch 3/200\n",
      " - 31s - loss: 1.7720 - auc: 0.9481 - val_loss: 1.2614 - val_auc: 0.9795\n",
      "Epoch 4/200\n",
      " - 31s - loss: 1.7097 - auc: 0.9522 - val_loss: 1.2069 - val_auc: 0.9808\n",
      "Epoch 5/200\n",
      " - 31s - loss: 1.6166 - auc: 0.9567 - val_loss: 1.1882 - val_auc: 0.9809\n",
      "Epoch 6/200\n",
      " - 31s - loss: 1.6187 - auc: 0.9564 - val_loss: 1.1476 - val_auc: 0.9824\n",
      "Epoch 7/200\n",
      " - 31s - loss: 1.6066 - auc: 0.9569 - val_loss: 1.1848 - val_auc: 0.9810\n",
      "Epoch 8/200\n",
      " - 31s - loss: 1.5906 - auc: 0.9587 - val_loss: 1.1861 - val_auc: 0.9818\n",
      "Epoch 9/200\n",
      " - 31s - loss: 1.5503 - auc: 0.9603 - val_loss: 1.1500 - val_auc: 0.9836\n",
      "Epoch 10/200\n",
      " - 31s - loss: 1.5216 - auc: 0.9612 - val_loss: 1.1213 - val_auc: 0.9821\n",
      "Epoch 11/200\n",
      " - 31s - loss: 1.5540 - auc: 0.9606 - val_loss: 1.1303 - val_auc: 0.9824\n",
      "Epoch 12/200\n",
      " - 31s - loss: 1.5344 - auc: 0.9614 - val_loss: 1.1274 - val_auc: 0.9824\n",
      "Epoch 13/200\n",
      " - 31s - loss: 1.5216 - auc: 0.9614 - val_loss: 1.1340 - val_auc: 0.9828\n",
      "Epoch 14/200\n",
      " - 31s - loss: 1.4816 - auc: 0.9636 - val_loss: 1.1174 - val_auc: 0.9825\n",
      "Epoch 15/200\n",
      " - 31s - loss: 1.4919 - auc: 0.9630 - val_loss: 1.1523 - val_auc: 0.9816\n",
      "Epoch 16/200\n",
      " - 31s - loss: 1.4964 - auc: 0.9630 - val_loss: 1.1407 - val_auc: 0.9831\n",
      "Epoch 17/200\n",
      " - 31s - loss: 1.4402 - auc: 0.9661 - val_loss: 1.0972 - val_auc: 0.9839\n",
      "Epoch 18/200\n",
      " - 31s - loss: 1.4653 - auc: 0.9634 - val_loss: 1.0624 - val_auc: 0.9849\n",
      "Epoch 19/200\n",
      " - 31s - loss: 1.4344 - auc: 0.9672 - val_loss: 1.1038 - val_auc: 0.9840\n",
      "Epoch 20/200\n",
      " - 31s - loss: 1.4158 - auc: 0.9655 - val_loss: 1.0858 - val_auc: 0.9840\n",
      "Epoch 21/200\n",
      " - 31s - loss: 1.4258 - auc: 0.9668 - val_loss: 1.0867 - val_auc: 0.9841\n",
      "Epoch 22/200\n",
      " - 31s - loss: 1.4198 - auc: 0.9658 - val_loss: 1.0500 - val_auc: 0.9846\n",
      "Epoch 23/200\n",
      " - 31s - loss: 1.4127 - auc: 0.9668 - val_loss: 1.0946 - val_auc: 0.9828\n",
      "Epoch 24/200\n",
      " - 31s - loss: 1.3973 - auc: 0.9664 - val_loss: 1.0732 - val_auc: 0.9838\n",
      "Epoch 25/200\n",
      " - 31s - loss: 1.4269 - auc: 0.9677 - val_loss: 1.1022 - val_auc: 0.9836\n",
      "Epoch 26/200\n",
      " - 31s - loss: 1.4062 - auc: 0.9671 - val_loss: 1.0477 - val_auc: 0.9851\n",
      "Epoch 27/200\n",
      " - 31s - loss: 1.3710 - auc: 0.9690 - val_loss: 1.0236 - val_auc: 0.9853\n",
      "Epoch 28/200\n",
      " - 31s - loss: 1.3718 - auc: 0.9686 - val_loss: 1.0585 - val_auc: 0.9821\n",
      "Epoch 29/200\n",
      " - 31s - loss: 1.3786 - auc: 0.9675 - val_loss: 1.0550 - val_auc: 0.9829\n",
      "Epoch 30/200\n",
      " - 31s - loss: 1.3794 - auc: 0.9678 - val_loss: 1.0207 - val_auc: 0.9853\n",
      "Epoch 31/200\n",
      " - 31s - loss: 1.3754 - auc: 0.9698 - val_loss: 1.0780 - val_auc: 0.9823\n",
      "Epoch 32/200\n",
      " - 31s - loss: 1.3686 - auc: 0.9685 - val_loss: 1.0060 - val_auc: 0.9856\n",
      "Epoch 33/200\n",
      " - 31s - loss: 1.3506 - auc: 0.9703 - val_loss: 1.0502 - val_auc: 0.9846\n",
      "Epoch 34/200\n",
      " - 31s - loss: 1.3502 - auc: 0.9706 - val_loss: 1.0151 - val_auc: 0.9853\n",
      "Epoch 35/200\n",
      " - 31s - loss: 1.3350 - auc: 0.9696 - val_loss: 1.0111 - val_auc: 0.9827\n",
      "Epoch 36/200\n",
      " - 31s - loss: 1.3397 - auc: 0.9703 - val_loss: 1.0114 - val_auc: 0.9856\n",
      "Epoch 37/200\n",
      " - 31s - loss: 1.3650 - auc: 0.9683 - val_loss: 1.0460 - val_auc: 0.9838\n",
      "Epoch 38/200\n",
      " - 31s - loss: 1.3403 - auc: 0.9700 - val_loss: 1.0287 - val_auc: 0.9852\n",
      "Epoch 39/200\n",
      " - 31s - loss: 1.3286 - auc: 0.9724 - val_loss: 0.9714 - val_auc: 0.9859\n",
      "Epoch 40/200\n",
      " - 31s - loss: 1.3518 - auc: 0.9685 - val_loss: 0.9889 - val_auc: 0.9841\n",
      "Epoch 41/200\n",
      " - 31s - loss: 1.3527 - auc: 0.9690 - val_loss: 1.0154 - val_auc: 0.9843\n",
      "Epoch 42/200\n",
      " - 31s - loss: 1.3268 - auc: 0.9704 - val_loss: 0.9997 - val_auc: 0.9839\n",
      "Epoch 43/200\n",
      " - 31s - loss: 1.3169 - auc: 0.9713 - val_loss: 1.0106 - val_auc: 0.9853\n",
      "Epoch 44/200\n",
      " - 31s - loss: 1.3277 - auc: 0.9708 - val_loss: 1.0347 - val_auc: 0.9832\n",
      "Epoch 45/200\n",
      " - 31s - loss: 1.2974 - auc: 0.9721 - val_loss: 0.9801 - val_auc: 0.9844\n",
      "Epoch 46/200\n",
      " - 31s - loss: 1.3239 - auc: 0.9706 - val_loss: 1.0341 - val_auc: 0.9815\n",
      "Epoch 47/200\n",
      " - 31s - loss: 1.3004 - auc: 0.9711 - val_loss: 1.0180 - val_auc: 0.9826\n",
      "Epoch 48/200\n",
      " - 31s - loss: 1.3082 - auc: 0.9718 - val_loss: 1.0570 - val_auc: 0.9813\n",
      "Epoch 49/200\n",
      " - 31s - loss: 1.3543 - auc: 0.9698 - val_loss: 1.0844 - val_auc: 0.9826\n",
      "Epoch 50/200\n",
      " - 31s - loss: 1.2716 - auc: 0.9746 - val_loss: 0.9713 - val_auc: 0.9841\n",
      "Epoch 51/200\n",
      " - 31s - loss: 1.3200 - auc: 0.9702 - val_loss: 0.9728 - val_auc: 0.9858\n",
      "Epoch 52/200\n",
      " - 31s - loss: 1.3202 - auc: 0.9710 - val_loss: 0.9632 - val_auc: 0.9858\n",
      "Epoch 53/200\n",
      " - 31s - loss: 1.3034 - auc: 0.9703 - val_loss: 0.9927 - val_auc: 0.9846\n",
      "Epoch 54/200\n",
      " - 31s - loss: 1.3081 - auc: 0.9714 - val_loss: 0.9932 - val_auc: 0.9841\n",
      "Epoch 55/200\n",
      " - 31s - loss: 1.3036 - auc: 0.9729 - val_loss: 0.9804 - val_auc: 0.9837\n",
      "Epoch 56/200\n",
      " - 31s - loss: 1.3015 - auc: 0.9709 - val_loss: 0.9773 - val_auc: 0.9858\n",
      "Epoch 57/200\n",
      " - 31s - loss: 1.2964 - auc: 0.9718 - val_loss: 1.0060 - val_auc: 0.9838\n",
      "Epoch 58/200\n",
      " - 31s - loss: 1.3057 - auc: 0.9714 - val_loss: 0.9959 - val_auc: 0.9862\n",
      "Epoch 59/200\n",
      " - 31s - loss: 1.2521 - auc: 0.9749 - val_loss: 0.9974 - val_auc: 0.9833\n",
      "Epoch 60/200\n",
      " - 31s - loss: 1.2824 - auc: 0.9736 - val_loss: 1.0077 - val_auc: 0.9836\n",
      "Epoch 61/200\n",
      " - 31s - loss: 1.2744 - auc: 0.9741 - val_loss: 0.9340 - val_auc: 0.9866\n",
      "Epoch 62/200\n",
      " - 31s - loss: 1.2840 - auc: 0.9733 - val_loss: 0.9998 - val_auc: 0.9852\n",
      "Epoch 63/200\n",
      " - 31s - loss: 1.2923 - auc: 0.9737 - val_loss: 1.0162 - val_auc: 0.9814\n",
      "Epoch 64/200\n",
      " - 31s - loss: 1.2933 - auc: 0.9726 - val_loss: 0.9751 - val_auc: 0.9858\n",
      "Epoch 65/200\n",
      " - 31s - loss: 1.3156 - auc: 0.9705 - val_loss: 0.9446 - val_auc: 0.9828\n",
      "Epoch 66/200\n",
      " - 31s - loss: 1.2878 - auc: 0.9722 - val_loss: 1.0626 - val_auc: 0.9813\n",
      "Epoch 67/200\n",
      " - 31s - loss: 1.2706 - auc: 0.9738 - val_loss: 1.0004 - val_auc: 0.9860\n",
      "Epoch 68/200\n",
      " - 31s - loss: 1.2481 - auc: 0.9740 - val_loss: 1.0002 - val_auc: 0.9838\n",
      "Epoch 69/200\n",
      " - 31s - loss: 1.2706 - auc: 0.9736 - val_loss: 0.9693 - val_auc: 0.9828\n",
      "Epoch 70/200\n",
      " - 31s - loss: 1.2779 - auc: 0.9725 - val_loss: 0.9520 - val_auc: 0.9857\n",
      "Epoch 71/200\n",
      " - 31s - loss: 1.2578 - auc: 0.9730 - val_loss: 0.9453 - val_auc: 0.9873\n",
      "Epoch 72/200\n",
      " - 31s - loss: 1.2875 - auc: 0.9711 - val_loss: 0.9690 - val_auc: 0.9846\n",
      "Epoch 73/200\n",
      " - 31s - loss: 1.2578 - auc: 0.9740 - val_loss: 0.9726 - val_auc: 0.9844\n",
      "Epoch 74/200\n",
      " - 31s - loss: 1.2881 - auc: 0.9712 - val_loss: 0.9575 - val_auc: 0.9854\n",
      "Epoch 75/200\n",
      " - 31s - loss: 1.2661 - auc: 0.9731 - val_loss: 0.9572 - val_auc: 0.9874\n",
      "Epoch 76/200\n",
      " - 31s - loss: 1.2851 - auc: 0.9723 - val_loss: 0.9929 - val_auc: 0.9843\n",
      "Epoch 77/200\n",
      " - 31s - loss: 1.2826 - auc: 0.9726 - val_loss: 1.0655 - val_auc: 0.9850\n",
      "Epoch 78/200\n",
      " - 31s - loss: 1.2828 - auc: 0.9730 - val_loss: 0.9503 - val_auc: 0.9851\n",
      "Epoch 79/200\n",
      " - 31s - loss: 1.2340 - auc: 0.9757 - val_loss: 0.9376 - val_auc: 0.9853\n",
      "Epoch 80/200\n",
      " - 31s - loss: 1.2199 - auc: 0.9749 - val_loss: 0.9697 - val_auc: 0.9855\n",
      "Epoch 81/200\n",
      " - 31s - loss: 1.2554 - auc: 0.9732 - val_loss: 0.9158 - val_auc: 0.9855\n",
      "Epoch 82/200\n",
      " - 31s - loss: 1.2491 - auc: 0.9730 - val_loss: 0.9855 - val_auc: 0.9830\n",
      "Epoch 83/200\n",
      " - 31s - loss: 1.2752 - auc: 0.9731 - val_loss: 1.0243 - val_auc: 0.9843\n",
      "Epoch 84/200\n",
      " - 31s - loss: 1.2508 - auc: 0.9739 - val_loss: 0.9545 - val_auc: 0.9847\n",
      "Epoch 85/200\n",
      " - 31s - loss: 1.2720 - auc: 0.9733 - val_loss: 0.9722 - val_auc: 0.9833\n",
      "Epoch 86/200\n",
      " - 31s - loss: 1.2769 - auc: 0.9725 - val_loss: 0.9974 - val_auc: 0.9846\n",
      "Epoch 87/200\n",
      " - 31s - loss: 1.2484 - auc: 0.9745 - val_loss: 1.0028 - val_auc: 0.9837\n",
      "Epoch 88/200\n",
      " - 31s - loss: 1.2562 - auc: 0.9733 - val_loss: 0.9998 - val_auc: 0.9834\n",
      "Epoch 89/200\n",
      " - 31s - loss: 1.2549 - auc: 0.9728 - val_loss: 0.9995 - val_auc: 0.9836\n",
      "Epoch 90/200\n",
      " - 31s - loss: 1.2329 - auc: 0.9747 - val_loss: 0.9581 - val_auc: 0.9843\n",
      "Epoch 91/200\n",
      " - 31s - loss: 1.2505 - auc: 0.9741 - val_loss: 0.9860 - val_auc: 0.9841\n",
      "Epoch 92/200\n",
      " - 31s - loss: 1.2332 - auc: 0.9753 - val_loss: 0.9337 - val_auc: 0.9862\n",
      "Epoch 93/200\n",
      " - 31s - loss: 1.2521 - auc: 0.9729 - val_loss: 0.9985 - val_auc: 0.9835\n",
      "Epoch 94/200\n",
      " - 31s - loss: 1.2529 - auc: 0.9739 - val_loss: 0.9854 - val_auc: 0.9862\n",
      "Epoch 95/200\n",
      " - 31s - loss: 1.2358 - auc: 0.9744 - val_loss: 0.9165 - val_auc: 0.9864\n",
      "Epoch 96/200\n",
      " - 31s - loss: 1.2246 - auc: 0.9746 - val_loss: 0.9987 - val_auc: 0.9840\n",
      "Epoch 97/200\n",
      " - 31s - loss: 1.2284 - auc: 0.9750 - val_loss: 0.9189 - val_auc: 0.9856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/200\n",
      " - 31s - loss: 1.2352 - auc: 0.9746 - val_loss: 0.9942 - val_auc: 0.9869\n",
      "Epoch 99/200\n",
      " - 31s - loss: 1.2311 - auc: 0.9748 - val_loss: 0.9087 - val_auc: 0.9854\n",
      "Epoch 100/200\n",
      " - 31s - loss: 1.2216 - auc: 0.9761 - val_loss: 0.9797 - val_auc: 0.9866\n",
      "Epoch 101/200\n",
      " - 31s - loss: 1.2428 - auc: 0.9742 - val_loss: 0.9210 - val_auc: 0.9879\n",
      "Epoch 102/200\n",
      " - 31s - loss: 1.2094 - auc: 0.9769 - val_loss: 0.9271 - val_auc: 0.9853\n",
      "Epoch 103/200\n",
      " - 31s - loss: 1.2259 - auc: 0.9746 - val_loss: 1.0203 - val_auc: 0.9856\n",
      "Epoch 104/200\n",
      " - 31s - loss: 1.2351 - auc: 0.9741 - val_loss: 0.9192 - val_auc: 0.9868\n",
      "Epoch 105/200\n",
      " - 31s - loss: 1.2165 - auc: 0.9754 - val_loss: 1.0190 - val_auc: 0.9839\n",
      "Epoch 106/200\n",
      " - 31s - loss: 1.2224 - auc: 0.9757 - val_loss: 0.9279 - val_auc: 0.9843\n",
      "Epoch 107/200\n",
      " - 31s - loss: 1.2264 - auc: 0.9750 - val_loss: 0.9414 - val_auc: 0.9871\n",
      "Epoch 108/200\n",
      " - 31s - loss: 1.2042 - auc: 0.9769 - val_loss: 0.9381 - val_auc: 0.9851\n",
      "Epoch 109/200\n",
      " - 31s - loss: 1.2346 - auc: 0.9742 - val_loss: 0.9452 - val_auc: 0.9840\n",
      "Epoch 110/200\n",
      " - 31s - loss: 1.2330 - auc: 0.9749 - val_loss: 0.9047 - val_auc: 0.9867\n",
      "Epoch 111/200\n",
      " - 31s - loss: 1.2112 - auc: 0.9762 - val_loss: 0.9412 - val_auc: 0.9881\n",
      "Epoch 112/200\n",
      " - 31s - loss: 1.2255 - auc: 0.9747 - val_loss: 0.9375 - val_auc: 0.9858\n",
      "Epoch 113/200\n",
      " - 31s - loss: 1.2373 - auc: 0.9754 - val_loss: 0.9264 - val_auc: 0.9862\n",
      "Epoch 114/200\n",
      " - 31s - loss: 1.2393 - auc: 0.9741 - val_loss: 0.9271 - val_auc: 0.9860\n",
      "Epoch 115/200\n",
      " - 31s - loss: 1.2123 - auc: 0.9758 - val_loss: 0.9052 - val_auc: 0.9868\n",
      "Epoch 116/200\n",
      " - 31s - loss: 1.2277 - auc: 0.9757 - val_loss: 0.9412 - val_auc: 0.9873\n",
      "Epoch 117/200\n",
      " - 31s - loss: 1.2501 - auc: 0.9732 - val_loss: 0.9089 - val_auc: 0.9874\n",
      "Epoch 118/200\n",
      " - 31s - loss: 1.1908 - auc: 0.9770 - val_loss: 0.9148 - val_auc: 0.9862\n",
      "Epoch 119/200\n",
      " - 31s - loss: 1.2244 - auc: 0.9754 - val_loss: 0.9497 - val_auc: 0.9851\n",
      "Epoch 120/200\n",
      " - 31s - loss: 1.1937 - auc: 0.9764 - val_loss: 0.8988 - val_auc: 0.9854\n",
      "Epoch 121/200\n",
      " - 31s - loss: 1.2188 - auc: 0.9745 - val_loss: 0.9521 - val_auc: 0.9852\n",
      "Epoch 122/200\n",
      " - 31s - loss: 1.2230 - auc: 0.9751 - val_loss: 0.9725 - val_auc: 0.9846\n",
      "Epoch 123/200\n",
      " - 31s - loss: 1.2037 - auc: 0.9763 - val_loss: 0.8857 - val_auc: 0.9873\n",
      "Epoch 124/200\n",
      " - 31s - loss: 1.2190 - auc: 0.9761 - val_loss: 0.9347 - val_auc: 0.9852\n",
      "Epoch 125/200\n",
      " - 31s - loss: 1.2129 - auc: 0.9762 - val_loss: 0.9424 - val_auc: 0.9844\n",
      "Epoch 126/200\n",
      " - 31s - loss: 1.2300 - auc: 0.9757 - val_loss: 0.9982 - val_auc: 0.9846\n",
      "Epoch 127/200\n",
      " - 31s - loss: 1.2250 - auc: 0.9748 - val_loss: 0.9968 - val_auc: 0.9838\n",
      "Epoch 128/200\n",
      " - 31s - loss: 1.2096 - auc: 0.9756 - val_loss: 0.9211 - val_auc: 0.9857\n",
      "Epoch 129/200\n",
      " - 31s - loss: 1.2324 - auc: 0.9745 - val_loss: 0.9098 - val_auc: 0.9864\n",
      "Epoch 130/200\n",
      " - 31s - loss: 1.2228 - auc: 0.9752 - val_loss: 0.9533 - val_auc: 0.9854\n",
      "Epoch 131/200\n",
      " - 31s - loss: 1.2143 - auc: 0.9763 - val_loss: 1.0160 - val_auc: 0.9835\n",
      "Epoch 132/200\n",
      " - 31s - loss: 1.1941 - auc: 0.9764 - val_loss: 0.8976 - val_auc: 0.9858\n",
      "Epoch 133/200\n",
      " - 31s - loss: 1.2298 - auc: 0.9743 - val_loss: 0.9155 - val_auc: 0.9856\n",
      "Epoch 134/200\n",
      " - 31s - loss: 1.2050 - auc: 0.9762 - val_loss: 0.8840 - val_auc: 0.9875\n",
      "Epoch 135/200\n",
      " - 31s - loss: 1.2267 - auc: 0.9741 - val_loss: 0.9026 - val_auc: 0.9853\n",
      "Epoch 136/200\n",
      " - 31s - loss: 1.1905 - auc: 0.9765 - val_loss: 0.9889 - val_auc: 0.9850\n",
      "Epoch 137/200\n",
      " - 31s - loss: 1.1954 - auc: 0.9760 - val_loss: 0.9441 - val_auc: 0.9867\n",
      "Epoch 138/200\n",
      " - 31s - loss: 1.2042 - auc: 0.9762 - val_loss: 0.9743 - val_auc: 0.9860\n",
      "Epoch 139/200\n",
      " - 31s - loss: 1.2263 - auc: 0.9752 - val_loss: 0.9192 - val_auc: 0.9870\n",
      "Epoch 140/200\n",
      " - 31s - loss: 1.1962 - auc: 0.9768 - val_loss: 1.0072 - val_auc: 0.9835\n",
      "Epoch 141/200\n",
      " - 31s - loss: 1.1887 - auc: 0.9759 - val_loss: 0.9414 - val_auc: 0.9854\n",
      "Epoch 142/200\n",
      " - 31s - loss: 1.1747 - auc: 0.9780 - val_loss: 0.9034 - val_auc: 0.9857\n",
      "Epoch 143/200\n",
      " - 31s - loss: 1.1898 - auc: 0.9769 - val_loss: 0.9801 - val_auc: 0.9854\n",
      "Epoch 144/200\n",
      " - 31s - loss: 1.2138 - auc: 0.9754 - val_loss: 1.0396 - val_auc: 0.9849\n",
      "Epoch 145/200\n",
      " - 31s - loss: 1.2128 - auc: 0.9750 - val_loss: 0.9289 - val_auc: 0.9873\n",
      "Epoch 146/200\n",
      " - 31s - loss: 1.2195 - auc: 0.9752 - val_loss: 0.9484 - val_auc: 0.9863\n",
      "Epoch 147/200\n",
      " - 31s - loss: 1.1944 - auc: 0.9758 - val_loss: 0.9354 - val_auc: 0.9850\n",
      "Epoch 148/200\n",
      " - 31s - loss: 1.1834 - auc: 0.9769 - val_loss: 0.9447 - val_auc: 0.9857\n",
      "Epoch 149/200\n",
      " - 31s - loss: 1.1688 - auc: 0.9777 - val_loss: 0.9625 - val_auc: 0.9856\n",
      "Epoch 150/200\n",
      " - 31s - loss: 1.2034 - auc: 0.9762 - val_loss: 0.9684 - val_auc: 0.9847\n",
      "Epoch 151/200\n",
      " - 31s - loss: 1.1975 - auc: 0.9775 - val_loss: 0.9244 - val_auc: 0.9862\n",
      "Epoch 152/200\n",
      " - 31s - loss: 1.1820 - auc: 0.9776 - val_loss: 1.0231 - val_auc: 0.9850\n",
      "Epoch 153/200\n",
      " - 31s - loss: 1.1833 - auc: 0.9767 - val_loss: 0.9133 - val_auc: 0.9874\n",
      "Epoch 154/200\n",
      " - 31s - loss: 1.1930 - auc: 0.9750 - val_loss: 1.0046 - val_auc: 0.9857\n",
      "Epoch 155/200\n",
      " - 31s - loss: 1.2098 - auc: 0.9757 - val_loss: 0.9217 - val_auc: 0.9866\n",
      "Epoch 156/200\n",
      " - 31s - loss: 1.2193 - auc: 0.9751 - val_loss: 0.9543 - val_auc: 0.9845\n",
      "Epoch 157/200\n",
      " - 31s - loss: 1.1875 - auc: 0.9763 - val_loss: 0.8755 - val_auc: 0.9861\n",
      "Epoch 158/200\n",
      " - 31s - loss: 1.1874 - auc: 0.9766 - val_loss: 0.9151 - val_auc: 0.9871\n",
      "Epoch 159/200\n",
      " - 31s - loss: 1.1963 - auc: 0.9758 - val_loss: 0.9175 - val_auc: 0.9874\n",
      "Epoch 160/200\n",
      " - 31s - loss: 1.2016 - auc: 0.9768 - val_loss: 0.9325 - val_auc: 0.9864\n",
      "Epoch 161/200\n",
      " - 31s - loss: 1.1738 - auc: 0.9771 - val_loss: 0.9565 - val_auc: 0.9863\n",
      "Epoch 162/200\n",
      " - 31s - loss: 1.1773 - auc: 0.9772 - val_loss: 0.9285 - val_auc: 0.9863\n",
      "Epoch 163/200\n",
      " - 31s - loss: 1.1894 - auc: 0.9770 - val_loss: 0.9055 - val_auc: 0.9863\n",
      "Epoch 164/200\n",
      " - 31s - loss: 1.1741 - auc: 0.9776 - val_loss: 0.9123 - val_auc: 0.9859\n",
      "Epoch 165/200\n",
      " - 31s - loss: 1.2077 - auc: 0.9757 - val_loss: 0.9943 - val_auc: 0.9864\n",
      "Epoch 166/200\n",
      " - 31s - loss: 1.1959 - auc: 0.9761 - val_loss: 0.9385 - val_auc: 0.9870\n",
      "Epoch 167/200\n",
      " - 31s - loss: 1.2090 - auc: 0.9760 - val_loss: 0.9293 - val_auc: 0.9866\n",
      "Epoch 168/200\n",
      " - 31s - loss: 1.1826 - auc: 0.9762 - val_loss: 0.9879 - val_auc: 0.9863\n",
      "Epoch 169/200\n",
      " - 31s - loss: 1.2041 - auc: 0.9762 - val_loss: 0.9242 - val_auc: 0.9863\n",
      "Epoch 170/200\n",
      " - 31s - loss: 1.1877 - auc: 0.9759 - val_loss: 0.8806 - val_auc: 0.9880\n",
      "Epoch 171/200\n",
      " - 31s - loss: 1.1538 - auc: 0.9785 - val_loss: 0.9312 - val_auc: 0.9868\n",
      "Epoch 172/200\n",
      " - 31s - loss: 1.2113 - auc: 0.9748 - val_loss: 0.9908 - val_auc: 0.9862\n",
      "Epoch 173/200\n",
      " - 31s - loss: 1.1726 - auc: 0.9784 - val_loss: 0.8736 - val_auc: 0.9878\n",
      "Epoch 174/200\n",
      " - 31s - loss: 1.1975 - auc: 0.9760 - val_loss: 0.9129 - val_auc: 0.9885\n",
      "Epoch 175/200\n",
      " - 31s - loss: 1.2057 - auc: 0.9753 - val_loss: 0.8990 - val_auc: 0.9874\n",
      "Epoch 176/200\n",
      " - 31s - loss: 1.1901 - auc: 0.9770 - val_loss: 0.9008 - val_auc: 0.9874\n",
      "Epoch 177/200\n",
      " - 31s - loss: 1.1903 - auc: 0.9771 - val_loss: 0.8826 - val_auc: 0.9877\n",
      "Epoch 178/200\n",
      " - 31s - loss: 1.1865 - auc: 0.9764 - val_loss: 0.9149 - val_auc: 0.9865\n",
      "Epoch 179/200\n",
      " - 31s - loss: 1.2118 - auc: 0.9745 - val_loss: 0.8686 - val_auc: 0.9880\n",
      "Epoch 180/200\n",
      " - 31s - loss: 1.1729 - auc: 0.9783 - val_loss: 0.8676 - val_auc: 0.9868\n",
      "Epoch 181/200\n",
      " - 31s - loss: 1.1792 - auc: 0.9776 - val_loss: 0.9474 - val_auc: 0.9876\n",
      "Epoch 182/200\n",
      " - 31s - loss: 1.1793 - auc: 0.9776 - val_loss: 0.9454 - val_auc: 0.9859\n",
      "Epoch 183/200\n",
      " - 31s - loss: 1.2021 - auc: 0.9748 - val_loss: 0.9270 - val_auc: 0.9861\n",
      "Epoch 184/200\n",
      " - 31s - loss: 1.1940 - auc: 0.9769 - val_loss: 0.8612 - val_auc: 0.9871\n",
      "Epoch 185/200\n",
      " - 31s - loss: 1.1942 - auc: 0.9764 - val_loss: 0.8801 - val_auc: 0.9876\n",
      "Epoch 186/200\n",
      " - 31s - loss: 1.1853 - auc: 0.9766 - val_loss: 0.8853 - val_auc: 0.9869\n",
      "Epoch 187/200\n",
      " - 31s - loss: 1.1337 - auc: 0.9791 - val_loss: 0.8674 - val_auc: 0.9881\n",
      "Epoch 188/200\n",
      " - 31s - loss: 1.1939 - auc: 0.9756 - val_loss: 0.9192 - val_auc: 0.9870\n",
      "Epoch 189/200\n",
      " - 31s - loss: 1.2047 - auc: 0.9752 - val_loss: 0.9422 - val_auc: 0.9861\n",
      "Epoch 190/200\n",
      " - 31s - loss: 1.1740 - auc: 0.9773 - val_loss: 0.9502 - val_auc: 0.9863\n",
      "Epoch 191/200\n",
      " - 31s - loss: 1.1746 - auc: 0.9778 - val_loss: 0.9473 - val_auc: 0.9849\n",
      "Epoch 192/200\n",
      " - 31s - loss: 1.1728 - auc: 0.9768 - val_loss: 0.9418 - val_auc: 0.9852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/200\n",
      " - 31s - loss: 1.1997 - auc: 0.9753 - val_loss: 1.0206 - val_auc: 0.9848\n",
      "Epoch 194/200\n",
      " - 30s - loss: 1.1683 - auc: 0.9772 - val_loss: 0.8724 - val_auc: 0.9855\n",
      "Epoch 195/200\n",
      " - 31s - loss: 1.1903 - auc: 0.9770 - val_loss: 0.9318 - val_auc: 0.9860\n",
      "Epoch 196/200\n",
      " - 31s - loss: 1.1490 - auc: 0.9787 - val_loss: 0.9496 - val_auc: 0.9857\n",
      "Epoch 197/200\n",
      " - 31s - loss: 1.1722 - auc: 0.9769 - val_loss: 0.9163 - val_auc: 0.9901\n",
      "Epoch 198/200\n",
      " - 31s - loss: 1.1529 - auc: 0.9782 - val_loss: 0.9955 - val_auc: 0.9858\n",
      "Epoch 199/200\n",
      " - 31s - loss: 1.1827 - auc: 0.9765 - val_loss: 0.8737 - val_auc: 0.9877\n",
      "Epoch 200/200\n",
      " - 31s - loss: 1.1541 - auc: 0.9776 - val_loss: 0.9229 - val_auc: 0.9869\n",
      "SMOTE,AUSAIC Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keg/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:80: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5471 samples, validate on 871 samples\n",
      "Epoch 1/200\n",
      " - 57s - loss: 2.4606 - auc: 0.8800 - val_loss: 1.6259 - val_auc: 0.9711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keg/anaconda3/lib/python3.6/site-packages/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `roc_accuracy` which is not available. Available metrics are: val_loss,val_auc,loss,auc,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200\n",
      " - 28s - loss: 1.9358 - auc: 0.9386 - val_loss: 1.3526 - val_auc: 0.9766\n",
      "Epoch 3/200\n",
      " - 28s - loss: 1.8027 - auc: 0.9474 - val_loss: 1.3454 - val_auc: 0.9766\n",
      "Epoch 4/200\n",
      " - 28s - loss: 1.7600 - auc: 0.9473 - val_loss: 1.3480 - val_auc: 0.9759\n",
      "Epoch 5/200\n",
      " - 28s - loss: 1.7076 - auc: 0.9514 - val_loss: 1.2741 - val_auc: 0.9779\n",
      "Epoch 6/200\n",
      " - 28s - loss: 1.6801 - auc: 0.9521 - val_loss: 1.2685 - val_auc: 0.9793\n",
      "Epoch 7/200\n",
      " - 28s - loss: 1.6610 - auc: 0.9536 - val_loss: 1.2529 - val_auc: 0.9784\n",
      "Epoch 8/200\n",
      " - 28s - loss: 1.6487 - auc: 0.9545 - val_loss: 1.2386 - val_auc: 0.9797\n",
      "Epoch 9/200\n",
      " - 28s - loss: 1.6153 - auc: 0.9577 - val_loss: 1.2344 - val_auc: 0.9785\n",
      "Epoch 10/200\n",
      " - 28s - loss: 1.6068 - auc: 0.9578 - val_loss: 1.2286 - val_auc: 0.9808\n",
      "Epoch 11/200\n",
      " - 28s - loss: 1.5914 - auc: 0.9574 - val_loss: 1.2099 - val_auc: 0.9789\n",
      "Epoch 12/200\n",
      " - 28s - loss: 1.5784 - auc: 0.9581 - val_loss: 1.1890 - val_auc: 0.9810\n",
      "Epoch 13/200\n",
      " - 28s - loss: 1.5648 - auc: 0.9599 - val_loss: 1.1933 - val_auc: 0.9796\n",
      "Epoch 14/200\n",
      " - 28s - loss: 1.5633 - auc: 0.9599 - val_loss: 1.1840 - val_auc: 0.9806\n",
      "Epoch 15/200\n",
      " - 28s - loss: 1.5301 - auc: 0.9622 - val_loss: 1.1468 - val_auc: 0.9817\n",
      "Epoch 16/200\n",
      " - 28s - loss: 1.5431 - auc: 0.9604 - val_loss: 1.1759 - val_auc: 0.9809\n",
      "Epoch 17/200\n",
      " - 28s - loss: 1.4974 - auc: 0.9637 - val_loss: 1.1666 - val_auc: 0.9810\n",
      "Epoch 18/200\n",
      " - 28s - loss: 1.4896 - auc: 0.9636 - val_loss: 1.1329 - val_auc: 0.9818\n",
      "Epoch 19/200\n",
      " - 28s - loss: 1.4910 - auc: 0.9625 - val_loss: 1.1331 - val_auc: 0.9810\n",
      "Epoch 20/200\n",
      " - 28s - loss: 1.5074 - auc: 0.9612 - val_loss: 1.1729 - val_auc: 0.9815\n",
      "Epoch 21/200\n",
      " - 28s - loss: 1.4866 - auc: 0.9628 - val_loss: 1.1128 - val_auc: 0.9831\n",
      "Epoch 22/200\n",
      " - 28s - loss: 1.4959 - auc: 0.9638 - val_loss: 1.1507 - val_auc: 0.9822\n",
      "Epoch 23/200\n",
      " - 28s - loss: 1.4632 - auc: 0.9637 - val_loss: 1.1290 - val_auc: 0.9835\n",
      "Epoch 24/200\n",
      " - 28s - loss: 1.4901 - auc: 0.9630 - val_loss: 1.1255 - val_auc: 0.9832\n",
      "Epoch 25/200\n",
      " - 28s - loss: 1.4845 - auc: 0.9626 - val_loss: 1.1313 - val_auc: 0.9824\n",
      "Epoch 26/200\n",
      " - 28s - loss: 1.4846 - auc: 0.9625 - val_loss: 1.1682 - val_auc: 0.9824\n",
      "Epoch 27/200\n",
      " - 28s - loss: 1.4994 - auc: 0.9616 - val_loss: 1.1928 - val_auc: 0.9811\n",
      "Epoch 28/200\n",
      " - 28s - loss: 1.4526 - auc: 0.9656 - val_loss: 1.1047 - val_auc: 0.9835\n",
      "Epoch 29/200\n",
      " - 28s - loss: 1.4568 - auc: 0.9651 - val_loss: 1.1312 - val_auc: 0.9829\n",
      "Epoch 30/200\n",
      " - 28s - loss: 1.4380 - auc: 0.9659 - val_loss: 1.1391 - val_auc: 0.9823\n",
      "Epoch 31/200\n",
      " - 28s - loss: 1.4090 - auc: 0.9659 - val_loss: 1.1265 - val_auc: 0.9818\n",
      "Epoch 32/200\n",
      " - 28s - loss: 1.4590 - auc: 0.9659 - val_loss: 1.0939 - val_auc: 0.9834\n",
      "Epoch 33/200\n",
      " - 28s - loss: 1.4314 - auc: 0.9667 - val_loss: 1.1056 - val_auc: 0.9836\n",
      "Epoch 34/200\n",
      " - 28s - loss: 1.3981 - auc: 0.9669 - val_loss: 1.1429 - val_auc: 0.9817\n",
      "Epoch 35/200\n",
      " - 28s - loss: 1.4146 - auc: 0.9668 - val_loss: 1.0660 - val_auc: 0.9829\n",
      "Epoch 36/200\n",
      " - 28s - loss: 1.4126 - auc: 0.9664 - val_loss: 1.1067 - val_auc: 0.9831\n",
      "Epoch 37/200\n",
      " - 28s - loss: 1.4209 - auc: 0.9667 - val_loss: 1.1398 - val_auc: 0.9827\n",
      "Epoch 38/200\n",
      " - 28s - loss: 1.4172 - auc: 0.9683 - val_loss: 1.1492 - val_auc: 0.9823\n",
      "Epoch 39/200\n",
      " - 28s - loss: 1.3823 - auc: 0.9698 - val_loss: 1.0617 - val_auc: 0.9832\n",
      "Epoch 40/200\n",
      " - 28s - loss: 1.3804 - auc: 0.9680 - val_loss: 1.0877 - val_auc: 0.9819\n",
      "Epoch 41/200\n",
      " - 28s - loss: 1.4181 - auc: 0.9677 - val_loss: 1.1175 - val_auc: 0.9825\n",
      "Epoch 42/200\n",
      " - 28s - loss: 1.4002 - auc: 0.9672 - val_loss: 1.0543 - val_auc: 0.9846\n",
      "Epoch 43/200\n",
      " - 28s - loss: 1.3821 - auc: 0.9664 - val_loss: 1.0868 - val_auc: 0.9836\n",
      "Epoch 44/200\n",
      " - 28s - loss: 1.4425 - auc: 0.9643 - val_loss: 1.1114 - val_auc: 0.9833\n",
      "Epoch 45/200\n",
      " - 28s - loss: 1.3616 - auc: 0.9691 - val_loss: 1.0837 - val_auc: 0.9842\n",
      "Epoch 46/200\n",
      " - 28s - loss: 1.3900 - auc: 0.9667 - val_loss: 1.1281 - val_auc: 0.9816\n",
      "Epoch 47/200\n",
      " - 28s - loss: 1.4040 - auc: 0.9678 - val_loss: 1.1213 - val_auc: 0.9816\n",
      "Epoch 48/200\n",
      " - 28s - loss: 1.3563 - auc: 0.9695 - val_loss: 1.0779 - val_auc: 0.9840\n",
      "Epoch 49/200\n",
      " - 28s - loss: 1.3780 - auc: 0.9680 - val_loss: 1.1026 - val_auc: 0.9832\n",
      "Epoch 50/200\n",
      " - 28s - loss: 1.3683 - auc: 0.9689 - val_loss: 1.0958 - val_auc: 0.9831\n",
      "Epoch 51/200\n",
      " - 28s - loss: 1.3808 - auc: 0.9676 - val_loss: 1.0565 - val_auc: 0.9838\n",
      "Epoch 52/200\n",
      " - 28s - loss: 1.3813 - auc: 0.9683 - val_loss: 1.0584 - val_auc: 0.9835\n",
      "Epoch 53/200\n",
      " - 28s - loss: 1.3707 - auc: 0.9688 - val_loss: 1.0677 - val_auc: 0.9845\n",
      "Epoch 54/200\n",
      " - 28s - loss: 1.3654 - auc: 0.9701 - val_loss: 1.1139 - val_auc: 0.9818\n",
      "Epoch 55/200\n",
      " - 28s - loss: 1.3582 - auc: 0.9686 - val_loss: 1.1252 - val_auc: 0.9826\n",
      "Epoch 56/200\n",
      " - 28s - loss: 1.3756 - auc: 0.9671 - val_loss: 1.1169 - val_auc: 0.9828\n",
      "Epoch 57/200\n",
      " - 28s - loss: 1.3582 - auc: 0.9697 - val_loss: 1.0523 - val_auc: 0.9841\n",
      "Epoch 58/200\n",
      " - 28s - loss: 1.3400 - auc: 0.9709 - val_loss: 0.9946 - val_auc: 0.9861\n",
      "Epoch 59/200\n",
      " - 28s - loss: 1.3547 - auc: 0.9707 - val_loss: 1.0348 - val_auc: 0.9864\n",
      "Epoch 60/200\n",
      " - 28s - loss: 1.3717 - auc: 0.9684 - val_loss: 1.0540 - val_auc: 0.9852\n",
      "Epoch 61/200\n",
      " - 28s - loss: 1.3425 - auc: 0.9708 - val_loss: 1.0377 - val_auc: 0.9840\n",
      "Epoch 62/200\n",
      " - 28s - loss: 1.3858 - auc: 0.9670 - val_loss: 1.0570 - val_auc: 0.9849\n",
      "Epoch 63/200\n",
      " - 28s - loss: 1.3938 - auc: 0.9683 - val_loss: 1.1125 - val_auc: 0.9840\n",
      "Epoch 64/200\n",
      " - 28s - loss: 1.3622 - auc: 0.9708 - val_loss: 1.0696 - val_auc: 0.9845\n",
      "Epoch 65/200\n",
      " - 28s - loss: 1.3657 - auc: 0.9688 - val_loss: 1.0769 - val_auc: 0.9841\n",
      "Epoch 66/200\n",
      " - 28s - loss: 1.3586 - auc: 0.9677 - val_loss: 1.0984 - val_auc: 0.9829\n",
      "Epoch 67/200\n",
      " - 28s - loss: 1.3212 - auc: 0.9702 - val_loss: 1.0498 - val_auc: 0.9847\n",
      "Epoch 68/200\n",
      " - 28s - loss: 1.3171 - auc: 0.9714 - val_loss: 1.0536 - val_auc: 0.9842\n",
      "Epoch 69/200\n",
      " - 28s - loss: 1.3333 - auc: 0.9699 - val_loss: 1.0083 - val_auc: 0.9866\n",
      "Epoch 70/200\n",
      " - 28s - loss: 1.3543 - auc: 0.9690 - val_loss: 1.0598 - val_auc: 0.9836\n",
      "Epoch 71/200\n",
      " - 28s - loss: 1.3178 - auc: 0.9712 - val_loss: 1.0108 - val_auc: 0.9854\n",
      "Epoch 72/200\n",
      " - 28s - loss: 1.3286 - auc: 0.9699 - val_loss: 1.0626 - val_auc: 0.9831\n",
      "Epoch 73/200\n",
      " - 28s - loss: 1.3306 - auc: 0.9708 - val_loss: 1.0414 - val_auc: 0.9844\n",
      "Epoch 74/200\n",
      " - 28s - loss: 1.2823 - auc: 0.9719 - val_loss: 1.0473 - val_auc: 0.9836\n",
      "Epoch 75/200\n",
      " - 28s - loss: 1.2899 - auc: 0.9715 - val_loss: 1.0496 - val_auc: 0.9836\n",
      "Epoch 76/200\n",
      " - 28s - loss: 1.3327 - auc: 0.9704 - val_loss: 1.0625 - val_auc: 0.9834\n",
      "Epoch 77/200\n",
      " - 28s - loss: 1.3289 - auc: 0.9695 - val_loss: 1.0727 - val_auc: 0.9829\n",
      "Epoch 78/200\n",
      " - 28s - loss: 1.3297 - auc: 0.9684 - val_loss: 1.0782 - val_auc: 0.9833\n",
      "Epoch 79/200\n",
      " - 28s - loss: 1.3119 - auc: 0.9717 - val_loss: 1.0980 - val_auc: 0.9829\n",
      "Epoch 80/200\n",
      " - 28s - loss: 1.2977 - auc: 0.9716 - val_loss: 1.0256 - val_auc: 0.9845\n",
      "Epoch 81/200\n",
      " - 28s - loss: 1.2933 - auc: 0.9714 - val_loss: 0.9834 - val_auc: 0.9856\n",
      "Epoch 82/200\n",
      " - 28s - loss: 1.2855 - auc: 0.9730 - val_loss: 1.1656 - val_auc: 0.9799\n",
      "Epoch 83/200\n",
      " - 28s - loss: 1.3335 - auc: 0.9702 - val_loss: 1.0722 - val_auc: 0.9829\n",
      "Epoch 84/200\n",
      " - 28s - loss: 1.2890 - auc: 0.9717 - val_loss: 1.0844 - val_auc: 0.9825\n",
      "Epoch 85/200\n",
      " - 28s - loss: 1.3312 - auc: 0.9712 - val_loss: 0.9938 - val_auc: 0.9857\n",
      "Epoch 86/200\n",
      " - 28s - loss: 1.3170 - auc: 0.9712 - val_loss: 0.9831 - val_auc: 0.9862\n",
      "Epoch 87/200\n",
      " - 28s - loss: 1.3217 - auc: 0.9695 - val_loss: 1.0229 - val_auc: 0.9854\n",
      "Epoch 88/200\n",
      " - 28s - loss: 1.3304 - auc: 0.9707 - val_loss: 1.0332 - val_auc: 0.9847\n",
      "Epoch 89/200\n",
      " - 28s - loss: 1.3196 - auc: 0.9700 - val_loss: 0.9981 - val_auc: 0.9855\n",
      "Epoch 90/200\n",
      " - 28s - loss: 1.3091 - auc: 0.9711 - val_loss: 1.0465 - val_auc: 0.9846\n",
      "Epoch 91/200\n",
      " - 28s - loss: 1.3301 - auc: 0.9686 - val_loss: 1.1484 - val_auc: 0.9809\n",
      "Epoch 92/200\n",
      " - 28s - loss: 1.2947 - auc: 0.9736 - val_loss: 0.9894 - val_auc: 0.9848\n",
      "Epoch 93/200\n",
      " - 28s - loss: 1.3041 - auc: 0.9710 - val_loss: 1.0458 - val_auc: 0.9845\n",
      "Epoch 94/200\n",
      " - 28s - loss: 1.2880 - auc: 0.9726 - val_loss: 0.9927 - val_auc: 0.9854\n",
      "Epoch 95/200\n",
      " - 28s - loss: 1.3013 - auc: 0.9718 - val_loss: 1.0430 - val_auc: 0.9840\n",
      "Epoch 96/200\n",
      " - 28s - loss: 1.3112 - auc: 0.9715 - val_loss: 1.0622 - val_auc: 0.9836\n",
      "Epoch 97/200\n",
      " - 28s - loss: 1.2920 - auc: 0.9724 - val_loss: 1.0275 - val_auc: 0.9849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/200\n",
      " - 28s - loss: 1.3094 - auc: 0.9704 - val_loss: 1.0270 - val_auc: 0.9849\n",
      "Epoch 99/200\n",
      " - 28s - loss: 1.3122 - auc: 0.9718 - val_loss: 1.0219 - val_auc: 0.9840\n",
      "Epoch 100/200\n",
      " - 28s - loss: 1.2973 - auc: 0.9711 - val_loss: 1.0160 - val_auc: 0.9855\n",
      "Epoch 101/200\n",
      " - 28s - loss: 1.3163 - auc: 0.9703 - val_loss: 1.0713 - val_auc: 0.9832\n",
      "Epoch 102/200\n",
      " - 28s - loss: 1.2967 - auc: 0.9725 - val_loss: 1.0450 - val_auc: 0.9849\n",
      "Epoch 103/200\n",
      " - 28s - loss: 1.3189 - auc: 0.9698 - val_loss: 0.9865 - val_auc: 0.9860\n",
      "Epoch 104/200\n",
      " - 28s - loss: 1.2790 - auc: 0.9735 - val_loss: 1.0386 - val_auc: 0.9842\n",
      "Epoch 105/200\n",
      " - 29s - loss: 1.2925 - auc: 0.9721 - val_loss: 0.9998 - val_auc: 0.9857\n",
      "Epoch 106/200\n",
      " - 28s - loss: 1.2793 - auc: 0.9717 - val_loss: 1.0359 - val_auc: 0.9834\n",
      "Epoch 107/200\n",
      " - 28s - loss: 1.2596 - auc: 0.9742 - val_loss: 1.0109 - val_auc: 0.9854\n",
      "Epoch 108/200\n",
      " - 28s - loss: 1.3135 - auc: 0.9704 - val_loss: 0.9991 - val_auc: 0.9846\n",
      "Epoch 109/200\n",
      " - 28s - loss: 1.2788 - auc: 0.9727 - val_loss: 0.9494 - val_auc: 0.9863\n",
      "Epoch 110/200\n",
      " - 28s - loss: 1.2617 - auc: 0.9726 - val_loss: 1.0504 - val_auc: 0.9843\n",
      "Epoch 111/200\n",
      " - 28s - loss: 1.2823 - auc: 0.9722 - val_loss: 0.9897 - val_auc: 0.9854\n",
      "Epoch 112/200\n",
      " - 28s - loss: 1.2865 - auc: 0.9718 - val_loss: 1.0434 - val_auc: 0.9837\n",
      "Epoch 113/200\n",
      " - 28s - loss: 1.3080 - auc: 0.9723 - val_loss: 1.0808 - val_auc: 0.9827\n",
      "Epoch 114/200\n",
      " - 28s - loss: 1.2944 - auc: 0.9716 - val_loss: 1.0534 - val_auc: 0.9839\n",
      "Epoch 115/200\n",
      " - 28s - loss: 1.2998 - auc: 0.9722 - val_loss: 1.0941 - val_auc: 0.9825\n",
      "Epoch 116/200\n",
      " - 28s - loss: 1.2526 - auc: 0.9730 - val_loss: 1.0662 - val_auc: 0.9830\n",
      "Epoch 117/200\n",
      " - 28s - loss: 1.2957 - auc: 0.9700 - val_loss: 0.9893 - val_auc: 0.9860\n",
      "Epoch 118/200\n",
      " - 28s - loss: 1.2946 - auc: 0.9710 - val_loss: 1.0071 - val_auc: 0.9854\n",
      "Epoch 119/200\n",
      " - 28s - loss: 1.2562 - auc: 0.9725 - val_loss: 1.0026 - val_auc: 0.9849\n",
      "Epoch 120/200\n",
      " - 28s - loss: 1.2657 - auc: 0.9740 - val_loss: 1.0630 - val_auc: 0.9839\n",
      "Epoch 121/200\n",
      " - 28s - loss: 1.2677 - auc: 0.9731 - val_loss: 1.0166 - val_auc: 0.9840\n",
      "Epoch 122/200\n",
      " - 28s - loss: 1.2828 - auc: 0.9722 - val_loss: 1.0574 - val_auc: 0.9839\n",
      "Epoch 123/200\n",
      " - 28s - loss: 1.2804 - auc: 0.9745 - val_loss: 1.0216 - val_auc: 0.9849\n",
      "Epoch 124/200\n",
      " - 28s - loss: 1.2433 - auc: 0.9742 - val_loss: 0.9987 - val_auc: 0.9846\n",
      "Epoch 125/200\n",
      " - 28s - loss: 1.2883 - auc: 0.9715 - val_loss: 0.9919 - val_auc: 0.9852\n",
      "Epoch 126/200\n",
      " - 28s - loss: 1.2617 - auc: 0.9750 - val_loss: 1.0199 - val_auc: 0.9848\n",
      "Epoch 127/200\n",
      " - 28s - loss: 1.2660 - auc: 0.9730 - val_loss: 0.9688 - val_auc: 0.9870\n",
      "Epoch 128/200\n",
      " - 28s - loss: 1.2538 - auc: 0.9736 - val_loss: 1.0437 - val_auc: 0.9837\n",
      "Epoch 129/200\n",
      " - 28s - loss: 1.2416 - auc: 0.9736 - val_loss: 1.0016 - val_auc: 0.9857\n",
      "Epoch 130/200\n",
      " - 28s - loss: 1.2658 - auc: 0.9725 - val_loss: 0.9605 - val_auc: 0.9867\n",
      "Epoch 131/200\n",
      " - 28s - loss: 1.2603 - auc: 0.9719 - val_loss: 0.9968 - val_auc: 0.9863\n",
      "Epoch 132/200\n",
      " - 28s - loss: 1.2593 - auc: 0.9727 - val_loss: 1.0097 - val_auc: 0.9838\n",
      "Epoch 133/200\n",
      " - 28s - loss: 1.2851 - auc: 0.9728 - val_loss: 1.0155 - val_auc: 0.9853\n",
      "Epoch 134/200\n",
      " - 28s - loss: 1.2650 - auc: 0.9733 - val_loss: 0.9880 - val_auc: 0.9848\n",
      "Epoch 135/200\n",
      " - 28s - loss: 1.2684 - auc: 0.9739 - val_loss: 0.9740 - val_auc: 0.9855\n",
      "Epoch 136/200\n",
      " - 28s - loss: 1.2841 - auc: 0.9723 - val_loss: 1.0134 - val_auc: 0.9849\n",
      "Epoch 137/200\n",
      " - 28s - loss: 1.2749 - auc: 0.9716 - val_loss: 1.0189 - val_auc: 0.9854\n",
      "Epoch 138/200\n",
      " - 28s - loss: 1.2829 - auc: 0.9713 - val_loss: 1.0067 - val_auc: 0.9854\n",
      "Epoch 139/200\n",
      " - 28s - loss: 1.2648 - auc: 0.9731 - val_loss: 0.9984 - val_auc: 0.9859\n",
      "Epoch 140/200\n",
      " - 28s - loss: 1.2934 - auc: 0.9718 - val_loss: 0.9735 - val_auc: 0.9857\n",
      "Epoch 141/200\n",
      " - 28s - loss: 1.2929 - auc: 0.9723 - val_loss: 0.9488 - val_auc: 0.9870\n",
      "Epoch 142/200\n",
      " - 28s - loss: 1.2700 - auc: 0.9722 - val_loss: 0.9703 - val_auc: 0.9862\n",
      "Epoch 143/200\n",
      " - 28s - loss: 1.2267 - auc: 0.9739 - val_loss: 1.0575 - val_auc: 0.9831\n",
      "Epoch 144/200\n",
      " - 28s - loss: 1.2572 - auc: 0.9738 - val_loss: 1.0689 - val_auc: 0.9834\n",
      "Epoch 145/200\n",
      " - 28s - loss: 1.2503 - auc: 0.9732 - val_loss: 1.0332 - val_auc: 0.9839\n",
      "Epoch 146/200\n",
      " - 28s - loss: 1.2754 - auc: 0.9723 - val_loss: 0.9460 - val_auc: 0.9872\n",
      "Epoch 147/200\n",
      " - 28s - loss: 1.2716 - auc: 0.9727 - val_loss: 0.9777 - val_auc: 0.9853\n",
      "Epoch 148/200\n",
      " - 28s - loss: 1.2807 - auc: 0.9713 - val_loss: 0.9820 - val_auc: 0.9855\n",
      "Epoch 149/200\n",
      " - 28s - loss: 1.2315 - auc: 0.9747 - val_loss: 0.9739 - val_auc: 0.9859\n",
      "Epoch 150/200\n",
      " - 28s - loss: 1.2691 - auc: 0.9722 - val_loss: 0.9627 - val_auc: 0.9857\n",
      "Epoch 151/200\n",
      " - 28s - loss: 1.2554 - auc: 0.9739 - val_loss: 0.9977 - val_auc: 0.9854\n",
      "Epoch 152/200\n",
      " - 28s - loss: 1.2466 - auc: 0.9745 - val_loss: 1.0821 - val_auc: 0.9827\n",
      "Epoch 153/200\n",
      " - 28s - loss: 1.2398 - auc: 0.9748 - val_loss: 1.0204 - val_auc: 0.9842\n",
      "Epoch 154/200\n",
      " - 28s - loss: 1.2404 - auc: 0.9725 - val_loss: 1.0434 - val_auc: 0.9842\n",
      "Epoch 155/200\n",
      " - 28s - loss: 1.2577 - auc: 0.9737 - val_loss: 1.0388 - val_auc: 0.9836\n",
      "Epoch 156/200\n",
      " - 28s - loss: 1.2632 - auc: 0.9719 - val_loss: 1.0748 - val_auc: 0.9826\n",
      "Epoch 157/200\n",
      " - 28s - loss: 1.2466 - auc: 0.9740 - val_loss: 0.9824 - val_auc: 0.9853\n",
      "Epoch 158/200\n",
      " - 28s - loss: 1.2532 - auc: 0.9728 - val_loss: 1.0682 - val_auc: 0.9827\n",
      "Epoch 159/200\n",
      " - 28s - loss: 1.2830 - auc: 0.9705 - val_loss: 0.9711 - val_auc: 0.9862\n",
      "Epoch 160/200\n",
      " - 28s - loss: 1.2396 - auc: 0.9745 - val_loss: 0.9505 - val_auc: 0.9861\n",
      "Epoch 161/200\n",
      " - 28s - loss: 1.2633 - auc: 0.9717 - val_loss: 0.9918 - val_auc: 0.9841\n",
      "Epoch 162/200\n",
      " - 28s - loss: 1.2375 - auc: 0.9744 - val_loss: 0.9301 - val_auc: 0.9871\n",
      "Epoch 163/200\n",
      " - 28s - loss: 1.2515 - auc: 0.9742 - val_loss: 0.9899 - val_auc: 0.9850\n",
      "Epoch 164/200\n",
      " - 28s - loss: 1.2531 - auc: 0.9746 - val_loss: 1.0466 - val_auc: 0.9837\n",
      "Epoch 165/200\n",
      " - 28s - loss: 1.2674 - auc: 0.9740 - val_loss: 0.9528 - val_auc: 0.9865\n",
      "Epoch 166/200\n",
      " - 28s - loss: 1.2627 - auc: 0.9732 - val_loss: 1.0228 - val_auc: 0.9839\n",
      "Epoch 167/200\n",
      " - 28s - loss: 1.2440 - auc: 0.9747 - val_loss: 1.0123 - val_auc: 0.9842\n",
      "Epoch 168/200\n",
      " - 28s - loss: 1.2716 - auc: 0.9726 - val_loss: 0.9731 - val_auc: 0.9868\n",
      "Epoch 169/200\n",
      " - 28s - loss: 1.2659 - auc: 0.9733 - val_loss: 1.1047 - val_auc: 0.9811\n",
      "Epoch 170/200\n",
      " - 28s - loss: 1.2601 - auc: 0.9738 - val_loss: 1.0082 - val_auc: 0.9851\n",
      "Epoch 171/200\n",
      " - 28s - loss: 1.2492 - auc: 0.9732 - val_loss: 0.9448 - val_auc: 0.9865\n",
      "Epoch 172/200\n",
      " - 28s - loss: 1.2138 - auc: 0.9749 - val_loss: 1.1003 - val_auc: 0.9819\n",
      "Epoch 173/200\n",
      " - 28s - loss: 1.2575 - auc: 0.9735 - val_loss: 1.0394 - val_auc: 0.9833\n",
      "Epoch 174/200\n",
      " - 28s - loss: 1.2557 - auc: 0.9748 - val_loss: 0.9792 - val_auc: 0.9855\n",
      "Epoch 175/200\n",
      " - 28s - loss: 1.2827 - auc: 0.9738 - val_loss: 0.9737 - val_auc: 0.9858\n",
      "Epoch 176/200\n",
      " - 28s - loss: 1.2786 - auc: 0.9727 - val_loss: 1.0333 - val_auc: 0.9835\n",
      "Epoch 177/200\n",
      " - 28s - loss: 1.2335 - auc: 0.9739 - val_loss: 0.9964 - val_auc: 0.9848\n",
      "Epoch 178/200\n",
      " - 28s - loss: 1.2340 - auc: 0.9739 - val_loss: 1.0088 - val_auc: 0.9849\n",
      "Epoch 179/200\n",
      " - 28s - loss: 1.2562 - auc: 0.9719 - val_loss: 0.9379 - val_auc: 0.9865\n",
      "Epoch 180/200\n",
      " - 28s - loss: 1.2479 - auc: 0.9741 - val_loss: 0.9948 - val_auc: 0.9850\n",
      "Epoch 181/200\n",
      " - 28s - loss: 1.2415 - auc: 0.9765 - val_loss: 1.0262 - val_auc: 0.9831\n",
      "Epoch 182/200\n",
      " - 28s - loss: 1.2516 - auc: 0.9735 - val_loss: 0.9712 - val_auc: 0.9859\n",
      "Epoch 183/200\n",
      " - 28s - loss: 1.2584 - auc: 0.9723 - val_loss: 1.0146 - val_auc: 0.9847\n",
      "Epoch 184/200\n",
      " - 28s - loss: 1.2393 - auc: 0.9736 - val_loss: 0.9923 - val_auc: 0.9852\n",
      "Epoch 185/200\n",
      " - 28s - loss: 1.2384 - auc: 0.9738 - val_loss: 1.0170 - val_auc: 0.9836\n",
      "Epoch 186/200\n",
      " - 28s - loss: 1.2505 - auc: 0.9720 - val_loss: 1.0183 - val_auc: 0.9851\n",
      "Epoch 187/200\n",
      " - 28s - loss: 1.2191 - auc: 0.9745 - val_loss: 0.9854 - val_auc: 0.9862\n",
      "Epoch 188/200\n",
      " - 28s - loss: 1.2466 - auc: 0.9729 - val_loss: 0.9610 - val_auc: 0.9862\n",
      "Epoch 189/200\n",
      " - 28s - loss: 1.2704 - auc: 0.9717 - val_loss: 1.0410 - val_auc: 0.9841\n",
      "Epoch 190/200\n",
      " - 28s - loss: 1.2400 - auc: 0.9738 - val_loss: 0.9419 - val_auc: 0.9866\n",
      "Epoch 191/200\n",
      " - 28s - loss: 1.2141 - auc: 0.9751 - val_loss: 0.9398 - val_auc: 0.9865\n",
      "Epoch 192/200\n",
      " - 28s - loss: 1.2061 - auc: 0.9760 - val_loss: 1.0407 - val_auc: 0.9839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/200\n",
      " - 28s - loss: 1.2408 - auc: 0.9738 - val_loss: 0.9891 - val_auc: 0.9849\n",
      "Epoch 194/200\n",
      " - 28s - loss: 1.2214 - auc: 0.9754 - val_loss: 1.0260 - val_auc: 0.9841\n",
      "Epoch 195/200\n",
      " - 28s - loss: 1.2578 - auc: 0.9732 - val_loss: 0.9891 - val_auc: 0.9842\n",
      "Epoch 196/200\n",
      " - 28s - loss: 1.2851 - auc: 0.9705 - val_loss: 0.9867 - val_auc: 0.9850\n",
      "Epoch 197/200\n",
      " - 28s - loss: 1.2025 - auc: 0.9763 - val_loss: 0.9655 - val_auc: 0.9869\n",
      "Epoch 198/200\n",
      " - 28s - loss: 1.2056 - auc: 0.9765 - val_loss: 1.0266 - val_auc: 0.9843\n",
      "Epoch 199/200\n",
      " - 28s - loss: 1.2327 - auc: 0.9749 - val_loss: 0.9279 - val_auc: 0.9875\n",
      "Epoch 200/200\n",
      " - 28s - loss: 1.2343 - auc: 0.9746 - val_loss: 1.0036 - val_auc: 0.9850\n",
      "SVMSMOTE,AUSAIC Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keg/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:80: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5920 samples, validate on 871 samples\n",
      "Epoch 1/200\n",
      " - 61s - loss: 2.4310 - auc: 0.8862 - val_loss: 1.5638 - val_auc: 0.9751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keg/anaconda3/lib/python3.6/site-packages/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `roc_accuracy` which is not available. Available metrics are: val_loss,val_auc,loss,auc,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200\n",
      " - 30s - loss: 1.9165 - auc: 0.9420 - val_loss: 1.4102 - val_auc: 0.9762\n",
      "Epoch 3/200\n",
      " - 30s - loss: 1.8503 - auc: 0.9440 - val_loss: 1.2860 - val_auc: 0.9805\n",
      "Epoch 4/200\n",
      " - 30s - loss: 1.7887 - auc: 0.9471 - val_loss: 1.2898 - val_auc: 0.9796\n",
      "Epoch 5/200\n",
      " - 30s - loss: 1.7520 - auc: 0.9496 - val_loss: 1.3045 - val_auc: 0.9792\n",
      "Epoch 6/200\n",
      " - 30s - loss: 1.7011 - auc: 0.9517 - val_loss: 1.2368 - val_auc: 0.9813\n",
      "Epoch 7/200\n",
      " - 30s - loss: 1.6776 - auc: 0.9543 - val_loss: 1.2539 - val_auc: 0.9817\n",
      "Epoch 8/200\n",
      " - 30s - loss: 1.6394 - auc: 0.9555 - val_loss: 1.2192 - val_auc: 0.9816\n",
      "Epoch 9/200\n",
      " - 30s - loss: 1.6348 - auc: 0.9562 - val_loss: 1.2055 - val_auc: 0.9830\n",
      "Epoch 10/200\n",
      " - 30s - loss: 1.6191 - auc: 0.9572 - val_loss: 1.2013 - val_auc: 0.9832\n",
      "Epoch 11/200\n",
      " - 30s - loss: 1.6248 - auc: 0.9557 - val_loss: 1.1997 - val_auc: 0.9835\n",
      "Epoch 12/200\n",
      " - 30s - loss: 1.5355 - auc: 0.9608 - val_loss: 1.1849 - val_auc: 0.9849\n",
      "Epoch 13/200\n",
      " - 30s - loss: 1.5743 - auc: 0.9593 - val_loss: 1.1728 - val_auc: 0.9840\n",
      "Epoch 14/200\n",
      " - 30s - loss: 1.5784 - auc: 0.9583 - val_loss: 1.1716 - val_auc: 0.9843\n",
      "Epoch 15/200\n",
      " - 30s - loss: 1.5352 - auc: 0.9619 - val_loss: 1.1175 - val_auc: 0.9847\n",
      "Epoch 16/200\n",
      " - 30s - loss: 1.5296 - auc: 0.9609 - val_loss: 1.0878 - val_auc: 0.9862\n",
      "Epoch 17/200\n",
      " - 30s - loss: 1.5280 - auc: 0.9617 - val_loss: 1.1708 - val_auc: 0.9845\n",
      "Epoch 18/200\n",
      " - 30s - loss: 1.5170 - auc: 0.9618 - val_loss: 1.1269 - val_auc: 0.9861\n",
      "Epoch 19/200\n",
      " - 30s - loss: 1.4879 - auc: 0.9640 - val_loss: 1.1736 - val_auc: 0.9850\n",
      "Epoch 20/200\n",
      " - 30s - loss: 1.5158 - auc: 0.9615 - val_loss: 1.1472 - val_auc: 0.9869\n",
      "Epoch 21/200\n",
      " - 30s - loss: 1.5056 - auc: 0.9624 - val_loss: 1.1099 - val_auc: 0.9878\n",
      "Epoch 22/200\n",
      " - 30s - loss: 1.4650 - auc: 0.9646 - val_loss: 1.0708 - val_auc: 0.9880\n",
      "Epoch 23/200\n",
      " - 30s - loss: 1.4755 - auc: 0.9644 - val_loss: 1.0845 - val_auc: 0.9877\n",
      "Epoch 24/200\n",
      " - 30s - loss: 1.4903 - auc: 0.9634 - val_loss: 1.1630 - val_auc: 0.9853\n",
      "Epoch 25/200\n",
      " - 30s - loss: 1.4770 - auc: 0.9641 - val_loss: 1.1460 - val_auc: 0.9853\n",
      "Epoch 26/200\n",
      " - 30s - loss: 1.4969 - auc: 0.9625 - val_loss: 1.0507 - val_auc: 0.9880\n",
      "Epoch 27/200\n",
      " - 30s - loss: 1.4781 - auc: 0.9644 - val_loss: 1.0679 - val_auc: 0.9882\n",
      "Epoch 28/200\n",
      " - 30s - loss: 1.4562 - auc: 0.9649 - val_loss: 1.0952 - val_auc: 0.9875\n",
      "Epoch 29/200\n",
      " - 30s - loss: 1.4678 - auc: 0.9632 - val_loss: 1.0944 - val_auc: 0.9880\n",
      "Epoch 30/200\n",
      " - 30s - loss: 1.4292 - auc: 0.9674 - val_loss: 1.1119 - val_auc: 0.9860\n",
      "Epoch 31/200\n",
      " - 30s - loss: 1.4777 - auc: 0.9640 - val_loss: 1.0761 - val_auc: 0.9875\n",
      "Epoch 32/200\n",
      " - 30s - loss: 1.4252 - auc: 0.9672 - val_loss: 1.0375 - val_auc: 0.9881\n",
      "Epoch 33/200\n",
      " - 30s - loss: 1.4442 - auc: 0.9655 - val_loss: 1.0396 - val_auc: 0.9892\n",
      "Epoch 34/200\n",
      " - 30s - loss: 1.4224 - auc: 0.9667 - val_loss: 1.0615 - val_auc: 0.9884\n",
      "Epoch 35/200\n",
      " - 30s - loss: 1.4420 - auc: 0.9661 - val_loss: 1.0611 - val_auc: 0.9881\n",
      "Epoch 36/200\n",
      " - 30s - loss: 1.4185 - auc: 0.9673 - val_loss: 1.0319 - val_auc: 0.9890\n",
      "Epoch 37/200\n",
      " - 30s - loss: 1.4103 - auc: 0.9672 - val_loss: 1.0089 - val_auc: 0.9899\n",
      "Epoch 38/200\n",
      " - 30s - loss: 1.3992 - auc: 0.9692 - val_loss: 1.0076 - val_auc: 0.9880\n",
      "Epoch 39/200\n",
      " - 30s - loss: 1.3839 - auc: 0.9690 - val_loss: 1.0781 - val_auc: 0.9870\n",
      "Epoch 40/200\n",
      " - 30s - loss: 1.3854 - auc: 0.9680 - val_loss: 1.0299 - val_auc: 0.9887\n",
      "Epoch 41/200\n",
      " - 30s - loss: 1.4247 - auc: 0.9660 - val_loss: 1.1108 - val_auc: 0.9869\n",
      "Epoch 42/200\n",
      " - 30s - loss: 1.4152 - auc: 0.9669 - val_loss: 1.0545 - val_auc: 0.9875\n",
      "Epoch 43/200\n",
      " - 30s - loss: 1.4034 - auc: 0.9676 - val_loss: 1.0249 - val_auc: 0.9893\n",
      "Epoch 44/200\n",
      " - 30s - loss: 1.4144 - auc: 0.9676 - val_loss: 1.0427 - val_auc: 0.9897\n",
      "Epoch 45/200\n",
      " - 30s - loss: 1.3648 - auc: 0.9702 - val_loss: 1.0300 - val_auc: 0.9893\n",
      "Epoch 46/200\n",
      " - 30s - loss: 1.4156 - auc: 0.9662 - val_loss: 0.9916 - val_auc: 0.9886\n",
      "Epoch 47/200\n",
      " - 30s - loss: 1.3969 - auc: 0.9678 - val_loss: 1.0759 - val_auc: 0.9878\n",
      "Epoch 48/200\n",
      " - 30s - loss: 1.4126 - auc: 0.9661 - val_loss: 1.0793 - val_auc: 0.9881\n",
      "Epoch 49/200\n",
      " - 30s - loss: 1.3926 - auc: 0.9681 - val_loss: 1.0396 - val_auc: 0.9877\n",
      "Epoch 50/200\n",
      " - 30s - loss: 1.3754 - auc: 0.9689 - val_loss: 0.9904 - val_auc: 0.9899\n",
      "Epoch 51/200\n",
      " - 30s - loss: 1.3786 - auc: 0.9690 - val_loss: 1.0411 - val_auc: 0.9885\n",
      "Epoch 52/200\n",
      " - 30s - loss: 1.3588 - auc: 0.9694 - val_loss: 1.0596 - val_auc: 0.9877\n",
      "Epoch 53/200\n",
      " - 30s - loss: 1.3573 - auc: 0.9702 - val_loss: 1.0235 - val_auc: 0.9876\n",
      "Epoch 54/200\n",
      " - 30s - loss: 1.3771 - auc: 0.9691 - val_loss: 1.0325 - val_auc: 0.9887\n",
      "Epoch 55/200\n",
      " - 30s - loss: 1.3966 - auc: 0.9690 - val_loss: 1.0184 - val_auc: 0.9889\n",
      "Epoch 56/200\n",
      " - 30s - loss: 1.3743 - auc: 0.9691 - val_loss: 1.0242 - val_auc: 0.9900\n",
      "Epoch 57/200\n",
      " - 30s - loss: 1.3583 - auc: 0.9695 - val_loss: 0.9915 - val_auc: 0.9898\n",
      "Epoch 58/200\n",
      " - 30s - loss: 1.3849 - auc: 0.9677 - val_loss: 1.0604 - val_auc: 0.9884\n",
      "Epoch 59/200\n",
      " - 30s - loss: 1.3983 - auc: 0.9687 - val_loss: 0.9806 - val_auc: 0.9902\n",
      "Epoch 60/200\n",
      " - 30s - loss: 1.3746 - auc: 0.9687 - val_loss: 1.0051 - val_auc: 0.9897\n",
      "Epoch 61/200\n",
      " - 30s - loss: 1.3775 - auc: 0.9692 - val_loss: 1.0403 - val_auc: 0.9883\n",
      "Epoch 62/200\n",
      " - 30s - loss: 1.3455 - auc: 0.9718 - val_loss: 1.0762 - val_auc: 0.9870\n",
      "Epoch 63/200\n",
      " - 30s - loss: 1.3711 - auc: 0.9700 - val_loss: 0.9936 - val_auc: 0.9903\n",
      "Epoch 64/200\n",
      " - 30s - loss: 1.3303 - auc: 0.9723 - val_loss: 1.0252 - val_auc: 0.9894\n",
      "Epoch 65/200\n",
      " - 30s - loss: 1.3862 - auc: 0.9681 - val_loss: 1.0270 - val_auc: 0.9883\n",
      "Epoch 66/200\n",
      " - 30s - loss: 1.3628 - auc: 0.9699 - val_loss: 1.0088 - val_auc: 0.9887\n",
      "Epoch 67/200\n",
      " - 30s - loss: 1.3280 - auc: 0.9716 - val_loss: 0.9993 - val_auc: 0.9901\n",
      "Epoch 68/200\n",
      " - 30s - loss: 1.3417 - auc: 0.9706 - val_loss: 1.0235 - val_auc: 0.9888\n",
      "Epoch 69/200\n",
      " - 30s - loss: 1.3755 - auc: 0.9692 - val_loss: 1.0204 - val_auc: 0.9891\n",
      "Epoch 70/200\n",
      " - 30s - loss: 1.3560 - auc: 0.9702 - val_loss: 1.0361 - val_auc: 0.9891\n",
      "Epoch 71/200\n",
      " - 30s - loss: 1.3535 - auc: 0.9709 - val_loss: 1.0296 - val_auc: 0.9890\n",
      "Epoch 72/200\n",
      " - 30s - loss: 1.3367 - auc: 0.9717 - val_loss: 1.0075 - val_auc: 0.9887\n",
      "Epoch 73/200\n",
      " - 30s - loss: 1.3679 - auc: 0.9691 - val_loss: 0.9693 - val_auc: 0.9904\n",
      "Epoch 74/200\n",
      " - 30s - loss: 1.3498 - auc: 0.9696 - val_loss: 0.9679 - val_auc: 0.9898\n",
      "Epoch 75/200\n",
      " - 30s - loss: 1.3345 - auc: 0.9714 - val_loss: 0.9939 - val_auc: 0.9896\n",
      "Epoch 76/200\n",
      " - 30s - loss: 1.3313 - auc: 0.9715 - val_loss: 1.0595 - val_auc: 0.9878\n",
      "Epoch 77/200\n",
      " - 30s - loss: 1.3287 - auc: 0.9721 - val_loss: 1.0464 - val_auc: 0.9880\n",
      "Epoch 78/200\n",
      " - 30s - loss: 1.3356 - auc: 0.9710 - val_loss: 1.0196 - val_auc: 0.9888\n",
      "Epoch 79/200\n",
      " - 30s - loss: 1.3197 - auc: 0.9718 - val_loss: 0.9953 - val_auc: 0.9892\n",
      "Epoch 80/200\n",
      " - 30s - loss: 1.3067 - auc: 0.9721 - val_loss: 1.0037 - val_auc: 0.9893\n",
      "Epoch 81/200\n",
      " - 30s - loss: 1.3481 - auc: 0.9698 - val_loss: 0.9738 - val_auc: 0.9899\n",
      "Epoch 82/200\n",
      " - 30s - loss: 1.3362 - auc: 0.9709 - val_loss: 0.9710 - val_auc: 0.9904\n",
      "Epoch 83/200\n",
      " - 30s - loss: 1.3576 - auc: 0.9695 - val_loss: 1.0116 - val_auc: 0.9877\n",
      "Epoch 84/200\n",
      " - 30s - loss: 1.2918 - auc: 0.9730 - val_loss: 1.0446 - val_auc: 0.9884\n",
      "Epoch 85/200\n",
      " - 30s - loss: 1.3337 - auc: 0.9701 - val_loss: 0.9688 - val_auc: 0.9899\n",
      "Epoch 86/200\n",
      " - 30s - loss: 1.3198 - auc: 0.9720 - val_loss: 1.0143 - val_auc: 0.9891\n",
      "Epoch 87/200\n",
      " - 30s - loss: 1.3340 - auc: 0.9707 - val_loss: 0.9766 - val_auc: 0.9896\n",
      "Epoch 88/200\n",
      " - 30s - loss: 1.2995 - auc: 0.9728 - val_loss: 0.9618 - val_auc: 0.9893\n",
      "Epoch 89/200\n",
      " - 30s - loss: 1.3282 - auc: 0.9722 - val_loss: 1.0070 - val_auc: 0.9889\n",
      "Epoch 90/200\n",
      " - 30s - loss: 1.3111 - auc: 0.9731 - val_loss: 0.9849 - val_auc: 0.9898\n",
      "Epoch 91/200\n",
      " - 30s - loss: 1.3141 - auc: 0.9720 - val_loss: 1.0383 - val_auc: 0.9883\n",
      "Epoch 92/200\n",
      " - 30s - loss: 1.3129 - auc: 0.9719 - val_loss: 1.0488 - val_auc: 0.9876\n",
      "Epoch 93/200\n",
      " - 30s - loss: 1.3061 - auc: 0.9729 - val_loss: 0.9444 - val_auc: 0.9902\n",
      "Epoch 94/200\n",
      " - 30s - loss: 1.3100 - auc: 0.9715 - val_loss: 0.9068 - val_auc: 0.9916\n",
      "Epoch 95/200\n",
      " - 30s - loss: 1.2867 - auc: 0.9727 - val_loss: 0.9751 - val_auc: 0.9902\n",
      "Epoch 96/200\n",
      " - 30s - loss: 1.3154 - auc: 0.9721 - val_loss: 0.9455 - val_auc: 0.9904\n",
      "Epoch 97/200\n",
      " - 30s - loss: 1.3150 - auc: 0.9719 - val_loss: 0.9960 - val_auc: 0.9895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/200\n",
      " - 30s - loss: 1.3078 - auc: 0.9725 - val_loss: 0.9442 - val_auc: 0.9905\n",
      "Epoch 99/200\n",
      " - 30s - loss: 1.3088 - auc: 0.9732 - val_loss: 1.0716 - val_auc: 0.9866\n",
      "Epoch 100/200\n",
      " - 30s - loss: 1.2950 - auc: 0.9729 - val_loss: 1.0617 - val_auc: 0.9869\n",
      "Epoch 101/200\n",
      " - 30s - loss: 1.2917 - auc: 0.9723 - val_loss: 1.0034 - val_auc: 0.9893\n",
      "Epoch 102/200\n",
      " - 30s - loss: 1.3295 - auc: 0.9707 - val_loss: 0.9589 - val_auc: 0.9900\n",
      "Epoch 103/200\n",
      " - 30s - loss: 1.2803 - auc: 0.9734 - val_loss: 1.0387 - val_auc: 0.9877\n",
      "Epoch 104/200\n",
      " - 30s - loss: 1.2923 - auc: 0.9729 - val_loss: 1.0214 - val_auc: 0.9884\n",
      "Epoch 105/200\n",
      " - 30s - loss: 1.3314 - auc: 0.9718 - val_loss: 1.0479 - val_auc: 0.9870\n",
      "Epoch 106/200\n",
      " - 30s - loss: 1.2885 - auc: 0.9727 - val_loss: 0.9369 - val_auc: 0.9907\n",
      "Epoch 107/200\n",
      " - 30s - loss: 1.3011 - auc: 0.9725 - val_loss: 0.9923 - val_auc: 0.9888\n",
      "Epoch 108/200\n",
      " - 30s - loss: 1.3055 - auc: 0.9714 - val_loss: 0.9998 - val_auc: 0.9885\n",
      "Epoch 109/200\n",
      " - 30s - loss: 1.3022 - auc: 0.9719 - val_loss: 0.9834 - val_auc: 0.9895\n",
      "Epoch 110/200\n",
      " - 30s - loss: 1.2853 - auc: 0.9733 - val_loss: 0.9472 - val_auc: 0.9905\n",
      "Epoch 111/200\n",
      " - 30s - loss: 1.2814 - auc: 0.9740 - val_loss: 0.9512 - val_auc: 0.9891\n",
      "Epoch 112/200\n",
      " - 30s - loss: 1.2995 - auc: 0.9717 - val_loss: 0.9695 - val_auc: 0.9888\n",
      "Epoch 113/200\n",
      " - 30s - loss: 1.3004 - auc: 0.9708 - val_loss: 1.0372 - val_auc: 0.9883\n",
      "Epoch 114/200\n",
      " - 30s - loss: 1.3006 - auc: 0.9721 - val_loss: 0.9753 - val_auc: 0.9895\n",
      "Epoch 115/200\n",
      " - 30s - loss: 1.2834 - auc: 0.9721 - val_loss: 0.9214 - val_auc: 0.9904\n",
      "Epoch 116/200\n",
      " - 30s - loss: 1.2884 - auc: 0.9731 - val_loss: 1.0764 - val_auc: 0.9859\n",
      "Epoch 117/200\n",
      " - 30s - loss: 1.2833 - auc: 0.9731 - val_loss: 0.9725 - val_auc: 0.9893\n",
      "Epoch 118/200\n",
      " - 30s - loss: 1.2836 - auc: 0.9736 - val_loss: 0.9227 - val_auc: 0.9908\n",
      "Epoch 119/200\n",
      " - 30s - loss: 1.2589 - auc: 0.9737 - val_loss: 0.9293 - val_auc: 0.9908\n",
      "Epoch 120/200\n",
      " - 30s - loss: 1.2778 - auc: 0.9738 - val_loss: 0.9074 - val_auc: 0.9911\n",
      "Epoch 121/200\n",
      " - 30s - loss: 1.3355 - auc: 0.9708 - val_loss: 1.0167 - val_auc: 0.9891\n",
      "Epoch 122/200\n",
      " - 30s - loss: 1.2584 - auc: 0.9748 - val_loss: 1.0400 - val_auc: 0.9873\n",
      "Epoch 123/200\n",
      " - 30s - loss: 1.3466 - auc: 0.9698 - val_loss: 1.0452 - val_auc: 0.9873\n",
      "Epoch 124/200\n",
      " - 30s - loss: 1.2936 - auc: 0.9740 - val_loss: 1.0135 - val_auc: 0.9890\n",
      "Epoch 125/200\n",
      " - 30s - loss: 1.2737 - auc: 0.9738 - val_loss: 0.9847 - val_auc: 0.9895\n",
      "Epoch 126/200\n",
      " - 30s - loss: 1.2846 - auc: 0.9729 - val_loss: 0.9599 - val_auc: 0.9902\n",
      "Epoch 127/200\n",
      " - 30s - loss: 1.2607 - auc: 0.9753 - val_loss: 0.8970 - val_auc: 0.9902\n",
      "Epoch 128/200\n",
      " - 30s - loss: 1.2475 - auc: 0.9755 - val_loss: 0.9407 - val_auc: 0.9904\n",
      "Epoch 129/200\n",
      " - 30s - loss: 1.3148 - auc: 0.9708 - val_loss: 0.9334 - val_auc: 0.9908\n",
      "Epoch 130/200\n",
      " - 30s - loss: 1.2838 - auc: 0.9735 - val_loss: 0.9622 - val_auc: 0.9895\n",
      "Epoch 131/200\n",
      " - 30s - loss: 1.3103 - auc: 0.9716 - val_loss: 1.0189 - val_auc: 0.9884\n",
      "Epoch 132/200\n",
      " - 30s - loss: 1.2726 - auc: 0.9753 - val_loss: 0.9770 - val_auc: 0.9878\n",
      "Epoch 133/200\n",
      " - 30s - loss: 1.2773 - auc: 0.9738 - val_loss: 1.0009 - val_auc: 0.9884\n",
      "Epoch 134/200\n",
      " - 30s - loss: 1.2908 - auc: 0.9720 - val_loss: 0.9977 - val_auc: 0.9888\n",
      "Epoch 135/200\n",
      " - 30s - loss: 1.2631 - auc: 0.9735 - val_loss: 0.9290 - val_auc: 0.9902\n",
      "Epoch 136/200\n",
      " - 30s - loss: 1.2561 - auc: 0.9740 - val_loss: 1.0252 - val_auc: 0.9879\n",
      "Epoch 137/200\n",
      " - 30s - loss: 1.2959 - auc: 0.9708 - val_loss: 1.0304 - val_auc: 0.9884\n",
      "Epoch 138/200\n",
      " - 30s - loss: 1.2746 - auc: 0.9728 - val_loss: 0.8931 - val_auc: 0.9905\n",
      "Epoch 139/200\n",
      " - 30s - loss: 1.2925 - auc: 0.9729 - val_loss: 0.9607 - val_auc: 0.9899\n",
      "Epoch 140/200\n",
      " - 30s - loss: 1.2397 - auc: 0.9757 - val_loss: 0.8958 - val_auc: 0.9910\n",
      "Epoch 141/200\n",
      " - 30s - loss: 1.2787 - auc: 0.9746 - val_loss: 0.9090 - val_auc: 0.9909\n",
      "Epoch 142/200\n",
      " - 30s - loss: 1.2707 - auc: 0.9737 - val_loss: 0.9628 - val_auc: 0.9894\n",
      "Epoch 143/200\n",
      " - 30s - loss: 1.2536 - auc: 0.9756 - val_loss: 0.9125 - val_auc: 0.9908\n",
      "Epoch 144/200\n",
      " - 30s - loss: 1.3131 - auc: 0.9713 - val_loss: 1.0410 - val_auc: 0.9880\n",
      "Epoch 145/200\n",
      " - 30s - loss: 1.2804 - auc: 0.9731 - val_loss: 0.9812 - val_auc: 0.9895\n",
      "Epoch 146/200\n",
      " - 30s - loss: 1.2830 - auc: 0.9722 - val_loss: 0.9411 - val_auc: 0.9903\n",
      "Epoch 147/200\n",
      " - 30s - loss: 1.2865 - auc: 0.9731 - val_loss: 0.9304 - val_auc: 0.9908\n",
      "Epoch 148/200\n",
      " - 30s - loss: 1.2599 - auc: 0.9744 - val_loss: 0.8731 - val_auc: 0.9915\n",
      "Epoch 149/200\n",
      " - 30s - loss: 1.2866 - auc: 0.9729 - val_loss: 0.9169 - val_auc: 0.9911\n",
      "Epoch 150/200\n",
      " - 30s - loss: 1.2793 - auc: 0.9733 - val_loss: 0.9085 - val_auc: 0.9913\n",
      "Epoch 151/200\n",
      " - 30s - loss: 1.2534 - auc: 0.9733 - val_loss: 0.9421 - val_auc: 0.9900\n",
      "Epoch 152/200\n",
      " - 30s - loss: 1.2623 - auc: 0.9749 - val_loss: 0.9630 - val_auc: 0.9898\n",
      "Epoch 153/200\n",
      " - 30s - loss: 1.2609 - auc: 0.9741 - val_loss: 0.9722 - val_auc: 0.9893\n",
      "Epoch 154/200\n",
      " - 30s - loss: 1.2725 - auc: 0.9742 - val_loss: 0.9063 - val_auc: 0.9908\n",
      "Epoch 155/200\n",
      " - 30s - loss: 1.3011 - auc: 0.9728 - val_loss: 0.9448 - val_auc: 0.9902\n",
      "Epoch 156/200\n",
      " - 30s - loss: 1.2901 - auc: 0.9718 - val_loss: 0.9390 - val_auc: 0.9901\n",
      "Epoch 157/200\n",
      " - 30s - loss: 1.2667 - auc: 0.9733 - val_loss: 0.8874 - val_auc: 0.9914\n",
      "Epoch 158/200\n",
      " - 30s - loss: 1.2758 - auc: 0.9733 - val_loss: 1.0380 - val_auc: 0.9874\n",
      "Epoch 159/200\n",
      " - 30s - loss: 1.2501 - auc: 0.9735 - val_loss: 1.0019 - val_auc: 0.9885\n",
      "Epoch 160/200\n",
      " - 30s - loss: 1.2714 - auc: 0.9735 - val_loss: 0.9759 - val_auc: 0.9892\n",
      "Epoch 161/200\n",
      " - 30s - loss: 1.2474 - auc: 0.9759 - val_loss: 0.9456 - val_auc: 0.9913\n",
      "Epoch 162/200\n",
      " - 30s - loss: 1.2337 - auc: 0.9759 - val_loss: 0.9738 - val_auc: 0.9894\n",
      "Epoch 163/200\n",
      " - 30s - loss: 1.2793 - auc: 0.9743 - val_loss: 0.9445 - val_auc: 0.9907\n",
      "Epoch 164/200\n",
      " - 30s - loss: 1.2629 - auc: 0.9728 - val_loss: 0.9025 - val_auc: 0.9914\n",
      "Epoch 165/200\n",
      " - 30s - loss: 1.2163 - auc: 0.9778 - val_loss: 1.0194 - val_auc: 0.9861\n",
      "Epoch 166/200\n",
      " - 30s - loss: 1.2590 - auc: 0.9740 - val_loss: 0.8717 - val_auc: 0.9916\n",
      "Epoch 167/200\n",
      " - 30s - loss: 1.2771 - auc: 0.9727 - val_loss: 0.9775 - val_auc: 0.9894\n",
      "Epoch 168/200\n",
      " - 30s - loss: 1.2829 - auc: 0.9734 - val_loss: 0.9048 - val_auc: 0.9914\n",
      "Epoch 169/200\n",
      " - 30s - loss: 1.2490 - auc: 0.9745 - val_loss: 0.9380 - val_auc: 0.9908\n",
      "Epoch 170/200\n",
      " - 30s - loss: 1.2384 - auc: 0.9750 - val_loss: 0.8632 - val_auc: 0.9914\n",
      "Epoch 171/200\n",
      " - 30s - loss: 1.2403 - auc: 0.9753 - val_loss: 0.8861 - val_auc: 0.9917\n",
      "Epoch 172/200\n",
      " - 30s - loss: 1.2796 - auc: 0.9717 - val_loss: 0.9209 - val_auc: 0.9911\n",
      "Epoch 173/200\n",
      " - 30s - loss: 1.2646 - auc: 0.9738 - val_loss: 0.8286 - val_auc: 0.9924\n",
      "Epoch 174/200\n",
      " - 30s - loss: 1.2571 - auc: 0.9736 - val_loss: 0.8836 - val_auc: 0.9917\n",
      "Epoch 175/200\n",
      " - 30s - loss: 1.2681 - auc: 0.9744 - val_loss: 0.8994 - val_auc: 0.9914\n",
      "Epoch 176/200\n",
      " - 30s - loss: 1.2496 - auc: 0.9747 - val_loss: 0.8858 - val_auc: 0.9915\n",
      "Epoch 177/200\n",
      " - 30s - loss: 1.2619 - auc: 0.9740 - val_loss: 0.9024 - val_auc: 0.9917\n",
      "Epoch 178/200\n",
      " - 30s - loss: 1.2574 - auc: 0.9722 - val_loss: 0.9955 - val_auc: 0.9892\n",
      "Epoch 179/200\n",
      " - 30s - loss: 1.2678 - auc: 0.9738 - val_loss: 0.9215 - val_auc: 0.9919\n",
      "Epoch 180/200\n",
      " - 30s - loss: 1.2623 - auc: 0.9750 - val_loss: 0.9728 - val_auc: 0.9906\n",
      "Epoch 181/200\n",
      " - 30s - loss: 1.2819 - auc: 0.9735 - val_loss: 0.9064 - val_auc: 0.9912\n",
      "Epoch 182/200\n",
      " - 30s - loss: 1.2490 - auc: 0.9750 - val_loss: 0.8616 - val_auc: 0.9918\n",
      "Epoch 183/200\n",
      " - 30s - loss: 1.2333 - auc: 0.9747 - val_loss: 1.0682 - val_auc: 0.9860\n",
      "Epoch 184/200\n",
      " - 30s - loss: 1.2261 - auc: 0.9761 - val_loss: 0.9124 - val_auc: 0.9910\n",
      "Epoch 185/200\n",
      " - 30s - loss: 1.2424 - auc: 0.9734 - val_loss: 0.9005 - val_auc: 0.9906\n",
      "Epoch 186/200\n",
      " - 30s - loss: 1.2097 - auc: 0.9751 - val_loss: 0.8520 - val_auc: 0.9920\n",
      "Epoch 187/200\n",
      " - 30s - loss: 1.2692 - auc: 0.9736 - val_loss: 0.9811 - val_auc: 0.9891\n",
      "Epoch 188/200\n",
      " - 30s - loss: 1.2488 - auc: 0.9747 - val_loss: 0.8780 - val_auc: 0.9913\n",
      "Epoch 189/200\n",
      " - 30s - loss: 1.2615 - auc: 0.9730 - val_loss: 0.8578 - val_auc: 0.9922\n",
      "Epoch 190/200\n",
      " - 30s - loss: 1.2205 - auc: 0.9754 - val_loss: 0.9633 - val_auc: 0.9890\n",
      "Epoch 191/200\n",
      " - 30s - loss: 1.2334 - auc: 0.9732 - val_loss: 0.9834 - val_auc: 0.9888\n",
      "Epoch 192/200\n",
      " - 30s - loss: 1.2563 - auc: 0.9737 - val_loss: 1.0159 - val_auc: 0.9888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/200\n",
      " - 30s - loss: 1.2320 - auc: 0.9753 - val_loss: 0.9612 - val_auc: 0.9890\n",
      "Epoch 194/200\n",
      " - 30s - loss: 1.2495 - auc: 0.9742 - val_loss: 0.8881 - val_auc: 0.9914\n",
      "Epoch 195/200\n",
      " - 30s - loss: 1.2454 - auc: 0.9752 - val_loss: 0.8982 - val_auc: 0.9910\n",
      "Epoch 196/200\n",
      " - 30s - loss: 1.2465 - auc: 0.9739 - val_loss: 1.0304 - val_auc: 0.9890\n",
      "Epoch 197/200\n",
      " - 30s - loss: 1.2535 - auc: 0.9744 - val_loss: 0.8690 - val_auc: 0.9920\n",
      "Epoch 198/200\n",
      " - 30s - loss: 1.2354 - auc: 0.9759 - val_loss: 0.8962 - val_auc: 0.9912\n",
      "Epoch 199/200\n",
      " - 30s - loss: 1.2478 - auc: 0.9752 - val_loss: 0.9492 - val_auc: 0.9907\n",
      "Epoch 200/200\n",
      " - 30s - loss: 1.2689 - auc: 0.9721 - val_loss: 0.9820 - val_auc: 0.9894\n",
      "ROS,AUSAIC Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keg/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:80: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5800 samples, validate on 871 samples\n",
      "Epoch 1/200\n",
      " - 61s - loss: 2.4642 - auc: 0.8809 - val_loss: 1.6482 - val_auc: 0.9700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keg/anaconda3/lib/python3.6/site-packages/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `roc_accuracy` which is not available. Available metrics are: val_loss,val_auc,loss,auc,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200\n",
      " - 30s - loss: 1.9974 - auc: 0.9345 - val_loss: 1.5526 - val_auc: 0.9707\n",
      "Epoch 3/200\n",
      " - 30s - loss: 1.8658 - auc: 0.9432 - val_loss: 1.4424 - val_auc: 0.9736\n",
      "Epoch 4/200\n",
      " - 30s - loss: 1.8146 - auc: 0.9467 - val_loss: 1.3578 - val_auc: 0.9761\n",
      "Epoch 5/200\n",
      " - 30s - loss: 1.7660 - auc: 0.9483 - val_loss: 1.4118 - val_auc: 0.9752\n",
      "Epoch 6/200\n",
      " - 30s - loss: 1.7117 - auc: 0.9529 - val_loss: 1.4045 - val_auc: 0.9754\n",
      "Epoch 7/200\n",
      " - 30s - loss: 1.6766 - auc: 0.9533 - val_loss: 1.3569 - val_auc: 0.9775\n",
      "Epoch 8/200\n",
      " - 30s - loss: 1.6699 - auc: 0.9546 - val_loss: 1.3777 - val_auc: 0.9751\n",
      "Epoch 9/200\n",
      " - 30s - loss: 1.6526 - auc: 0.9567 - val_loss: 1.4526 - val_auc: 0.9732\n",
      "Epoch 10/200\n",
      " - 30s - loss: 1.6243 - auc: 0.9580 - val_loss: 1.3891 - val_auc: 0.9759\n",
      "Epoch 11/200\n",
      " - 30s - loss: 1.6171 - auc: 0.9584 - val_loss: 1.3651 - val_auc: 0.9739\n",
      "Epoch 12/200\n",
      " - 30s - loss: 1.5713 - auc: 0.9596 - val_loss: 1.3059 - val_auc: 0.9759\n",
      "Epoch 13/200\n",
      " - 30s - loss: 1.5842 - auc: 0.9595 - val_loss: 1.2979 - val_auc: 0.9761\n",
      "Epoch 14/200\n",
      " - 30s - loss: 1.5566 - auc: 0.9616 - val_loss: 1.3330 - val_auc: 0.9771\n",
      "Epoch 15/200\n",
      " - 30s - loss: 1.5424 - auc: 0.9632 - val_loss: 1.3920 - val_auc: 0.9754\n",
      "Epoch 16/200\n",
      " - 30s - loss: 1.5356 - auc: 0.9625 - val_loss: 1.3233 - val_auc: 0.9755\n",
      "Epoch 17/200\n",
      " - 29s - loss: 1.4963 - auc: 0.9634 - val_loss: 1.3346 - val_auc: 0.9760\n",
      "Epoch 18/200\n",
      " - 30s - loss: 1.5137 - auc: 0.9629 - val_loss: 1.3271 - val_auc: 0.9749\n",
      "Epoch 19/200\n",
      " - 30s - loss: 1.5020 - auc: 0.9641 - val_loss: 1.3119 - val_auc: 0.9746\n",
      "Epoch 20/200\n",
      " - 30s - loss: 1.5124 - auc: 0.9641 - val_loss: 1.3504 - val_auc: 0.9742\n",
      "Epoch 21/200\n",
      " - 30s - loss: 1.4975 - auc: 0.9646 - val_loss: 1.2893 - val_auc: 0.9774\n",
      "Epoch 22/200\n",
      " - 30s - loss: 1.5246 - auc: 0.9632 - val_loss: 1.3467 - val_auc: 0.9752\n",
      "Epoch 23/200\n",
      " - 30s - loss: 1.4799 - auc: 0.9653 - val_loss: 1.2775 - val_auc: 0.9760\n",
      "Epoch 24/200\n",
      " - 30s - loss: 1.4763 - auc: 0.9657 - val_loss: 1.2680 - val_auc: 0.9781\n",
      "Epoch 25/200\n",
      " - 30s - loss: 1.4487 - auc: 0.9667 - val_loss: 1.2790 - val_auc: 0.9786\n",
      "Epoch 26/200\n",
      " - 30s - loss: 1.4679 - auc: 0.9652 - val_loss: 1.3318 - val_auc: 0.9755\n",
      "Epoch 27/200\n",
      " - 30s - loss: 1.4210 - auc: 0.9664 - val_loss: 1.3143 - val_auc: 0.9759\n",
      "Epoch 28/200\n",
      " - 30s - loss: 1.4580 - auc: 0.9656 - val_loss: 1.2759 - val_auc: 0.9775\n",
      "Epoch 29/200\n",
      " - 30s - loss: 1.4465 - auc: 0.9661 - val_loss: 1.2557 - val_auc: 0.9774\n",
      "Epoch 30/200\n",
      " - 30s - loss: 1.4218 - auc: 0.9680 - val_loss: 1.3563 - val_auc: 0.9744\n",
      "Epoch 31/200\n",
      " - 30s - loss: 1.4455 - auc: 0.9666 - val_loss: 1.3639 - val_auc: 0.9737\n",
      "Epoch 32/200\n",
      " - 30s - loss: 1.4150 - auc: 0.9681 - val_loss: 1.2347 - val_auc: 0.9782\n",
      "Epoch 33/200\n",
      " - 30s - loss: 1.4281 - auc: 0.9681 - val_loss: 1.2977 - val_auc: 0.9774\n",
      "Epoch 34/200\n",
      " - 30s - loss: 1.4076 - auc: 0.9687 - val_loss: 1.2646 - val_auc: 0.9780\n",
      "Epoch 35/200\n",
      " - 30s - loss: 1.4331 - auc: 0.9665 - val_loss: 1.3507 - val_auc: 0.9739\n",
      "Epoch 36/200\n",
      " - 30s - loss: 1.4086 - auc: 0.9684 - val_loss: 1.2976 - val_auc: 0.9769\n",
      "Epoch 37/200\n",
      " - 30s - loss: 1.4183 - auc: 0.9674 - val_loss: 1.3410 - val_auc: 0.9744\n",
      "Epoch 38/200\n",
      " - 30s - loss: 1.4172 - auc: 0.9681 - val_loss: 1.2919 - val_auc: 0.9763\n",
      "Epoch 39/200\n",
      " - 30s - loss: 1.4060 - auc: 0.9677 - val_loss: 1.3581 - val_auc: 0.9744\n",
      "Epoch 40/200\n",
      " - 30s - loss: 1.4101 - auc: 0.9678 - val_loss: 1.2913 - val_auc: 0.9772\n",
      "Epoch 41/200\n",
      " - 30s - loss: 1.3940 - auc: 0.9687 - val_loss: 1.2989 - val_auc: 0.9759\n",
      "Epoch 42/200\n",
      " - 30s - loss: 1.3789 - auc: 0.9692 - val_loss: 1.2615 - val_auc: 0.9784\n",
      "Epoch 43/200\n",
      " - 30s - loss: 1.3998 - auc: 0.9687 - val_loss: 1.3893 - val_auc: 0.9749\n",
      "Epoch 44/200\n",
      " - 30s - loss: 1.3991 - auc: 0.9687 - val_loss: 1.3184 - val_auc: 0.9757\n",
      "Epoch 45/200\n",
      " - 30s - loss: 1.3935 - auc: 0.9684 - val_loss: 1.2178 - val_auc: 0.9779\n",
      "Epoch 46/200\n",
      " - 30s - loss: 1.3633 - auc: 0.9708 - val_loss: 1.3262 - val_auc: 0.9737\n",
      "Epoch 47/200\n",
      " - 30s - loss: 1.3804 - auc: 0.9698 - val_loss: 1.2571 - val_auc: 0.9755\n",
      "Epoch 48/200\n",
      " - 30s - loss: 1.3737 - auc: 0.9703 - val_loss: 1.2287 - val_auc: 0.9792\n",
      "Epoch 49/200\n",
      " - 30s - loss: 1.3954 - auc: 0.9690 - val_loss: 1.2575 - val_auc: 0.9768\n",
      "Epoch 50/200\n",
      " - 30s - loss: 1.3942 - auc: 0.9688 - val_loss: 1.3308 - val_auc: 0.9746\n",
      "Epoch 51/200\n",
      " - 30s - loss: 1.3450 - auc: 0.9709 - val_loss: 1.2977 - val_auc: 0.9759\n",
      "Epoch 52/200\n",
      " - 30s - loss: 1.3601 - auc: 0.9714 - val_loss: 1.1749 - val_auc: 0.9801\n",
      "Epoch 53/200\n",
      " - 30s - loss: 1.3845 - auc: 0.9699 - val_loss: 1.3302 - val_auc: 0.9751\n",
      "Epoch 54/200\n",
      " - 30s - loss: 1.3390 - auc: 0.9719 - val_loss: 1.3133 - val_auc: 0.9760\n",
      "Epoch 55/200\n",
      " - 30s - loss: 1.3954 - auc: 0.9690 - val_loss: 1.3582 - val_auc: 0.9760\n",
      "Epoch 56/200\n",
      " - 30s - loss: 1.3476 - auc: 0.9699 - val_loss: 1.3919 - val_auc: 0.9736\n",
      "Epoch 57/200\n",
      " - 30s - loss: 1.3471 - auc: 0.9712 - val_loss: 1.3789 - val_auc: 0.9747\n",
      "Epoch 58/200\n",
      " - 30s - loss: 1.3607 - auc: 0.9697 - val_loss: 1.2037 - val_auc: 0.9792\n",
      "Epoch 59/200\n",
      " - 30s - loss: 1.3821 - auc: 0.9689 - val_loss: 1.2709 - val_auc: 0.9776\n",
      "Epoch 60/200\n",
      " - 30s - loss: 1.3413 - auc: 0.9722 - val_loss: 1.2522 - val_auc: 0.9789\n",
      "Epoch 61/200\n",
      " - 30s - loss: 1.3444 - auc: 0.9715 - val_loss: 1.3064 - val_auc: 0.9766\n",
      "Epoch 62/200\n",
      " - 30s - loss: 1.3793 - auc: 0.9698 - val_loss: 1.2447 - val_auc: 0.9776\n",
      "Epoch 63/200\n",
      " - 30s - loss: 1.3675 - auc: 0.9697 - val_loss: 1.2615 - val_auc: 0.9774\n",
      "Epoch 64/200\n",
      " - 30s - loss: 1.3472 - auc: 0.9710 - val_loss: 1.3014 - val_auc: 0.9767\n",
      "Epoch 65/200\n",
      " - 30s - loss: 1.3530 - auc: 0.9704 - val_loss: 1.2976 - val_auc: 0.9779\n",
      "Epoch 66/200\n",
      " - 30s - loss: 1.3551 - auc: 0.9714 - val_loss: 1.3581 - val_auc: 0.9731\n",
      "Epoch 67/200\n",
      " - 30s - loss: 1.3470 - auc: 0.9719 - val_loss: 1.2619 - val_auc: 0.9776\n",
      "Epoch 68/200\n",
      " - 30s - loss: 1.3380 - auc: 0.9719 - val_loss: 1.2644 - val_auc: 0.9775\n",
      "Epoch 69/200\n",
      " - 30s - loss: 1.3304 - auc: 0.9724 - val_loss: 1.1984 - val_auc: 0.9798\n",
      "Epoch 70/200\n",
      " - 30s - loss: 1.3239 - auc: 0.9709 - val_loss: 1.2111 - val_auc: 0.9781\n",
      "Epoch 71/200\n",
      " - 30s - loss: 1.3271 - auc: 0.9724 - val_loss: 1.2878 - val_auc: 0.9745\n",
      "Epoch 72/200\n",
      " - 30s - loss: 1.3256 - auc: 0.9724 - val_loss: 1.2327 - val_auc: 0.9791\n",
      "Epoch 73/200\n",
      " - 30s - loss: 1.3234 - auc: 0.9717 - val_loss: 1.3163 - val_auc: 0.9766\n",
      "Epoch 74/200\n",
      " - 30s - loss: 1.3783 - auc: 0.9682 - val_loss: 1.3147 - val_auc: 0.9762\n",
      "Epoch 75/200\n",
      " - 30s - loss: 1.3504 - auc: 0.9708 - val_loss: 1.2708 - val_auc: 0.9777\n",
      "Epoch 76/200\n",
      " - 30s - loss: 1.3142 - auc: 0.9740 - val_loss: 1.3033 - val_auc: 0.9759\n",
      "Epoch 77/200\n",
      " - 30s - loss: 1.3382 - auc: 0.9713 - val_loss: 1.2541 - val_auc: 0.9773\n",
      "Epoch 78/200\n",
      " - 30s - loss: 1.3229 - auc: 0.9715 - val_loss: 1.2289 - val_auc: 0.9794\n",
      "Epoch 79/200\n",
      " - 30s - loss: 1.2838 - auc: 0.9742 - val_loss: 1.2558 - val_auc: 0.9780\n",
      "Epoch 80/200\n",
      " - 30s - loss: 1.3516 - auc: 0.9702 - val_loss: 1.2590 - val_auc: 0.9781\n",
      "Epoch 81/200\n",
      " - 30s - loss: 1.3403 - auc: 0.9713 - val_loss: 1.3479 - val_auc: 0.9768\n",
      "Epoch 82/200\n",
      " - 30s - loss: 1.3401 - auc: 0.9712 - val_loss: 1.3628 - val_auc: 0.9757\n",
      "Epoch 83/200\n",
      " - 30s - loss: 1.3133 - auc: 0.9733 - val_loss: 1.2960 - val_auc: 0.9772\n",
      "Epoch 84/200\n",
      " - 30s - loss: 1.3252 - auc: 0.9728 - val_loss: 1.3291 - val_auc: 0.9761\n",
      "Epoch 85/200\n",
      " - 30s - loss: 1.3349 - auc: 0.9706 - val_loss: 1.2487 - val_auc: 0.9794\n",
      "Epoch 86/200\n",
      " - 30s - loss: 1.3379 - auc: 0.9707 - val_loss: 1.2784 - val_auc: 0.9769\n",
      "Epoch 87/200\n",
      " - 30s - loss: 1.2948 - auc: 0.9734 - val_loss: 1.2604 - val_auc: 0.9775\n",
      "Epoch 88/200\n",
      " - 30s - loss: 1.3195 - auc: 0.9721 - val_loss: 1.3940 - val_auc: 0.9724\n",
      "Epoch 89/200\n",
      " - 30s - loss: 1.3753 - auc: 0.9693 - val_loss: 1.2476 - val_auc: 0.9763\n",
      "Epoch 90/200\n",
      " - 30s - loss: 1.3356 - auc: 0.9716 - val_loss: 1.2507 - val_auc: 0.9776\n",
      "Epoch 91/200\n",
      " - 30s - loss: 1.3006 - auc: 0.9744 - val_loss: 1.1815 - val_auc: 0.9791\n",
      "Epoch 92/200\n",
      " - 30s - loss: 1.3095 - auc: 0.9721 - val_loss: 1.2383 - val_auc: 0.9772\n",
      "Epoch 93/200\n",
      " - 30s - loss: 1.3386 - auc: 0.9712 - val_loss: 1.2579 - val_auc: 0.9767\n",
      "Epoch 94/200\n",
      " - 30s - loss: 1.3293 - auc: 0.9730 - val_loss: 1.1941 - val_auc: 0.9786\n",
      "Epoch 95/200\n",
      " - 30s - loss: 1.3067 - auc: 0.9724 - val_loss: 1.2486 - val_auc: 0.9765\n",
      "Epoch 96/200\n",
      " - 30s - loss: 1.2993 - auc: 0.9726 - val_loss: 1.2838 - val_auc: 0.9748\n",
      "Epoch 97/200\n",
      " - 30s - loss: 1.3000 - auc: 0.9732 - val_loss: 1.1819 - val_auc: 0.9793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/200\n",
      " - 30s - loss: 1.3145 - auc: 0.9717 - val_loss: 1.2826 - val_auc: 0.9770\n",
      "Epoch 99/200\n",
      " - 30s - loss: 1.2982 - auc: 0.9731 - val_loss: 1.3965 - val_auc: 0.9708\n",
      "Epoch 100/200\n",
      " - 30s - loss: 1.2926 - auc: 0.9730 - val_loss: 1.2670 - val_auc: 0.9768\n",
      "Epoch 101/200\n",
      " - 30s - loss: 1.2966 - auc: 0.9728 - val_loss: 1.3061 - val_auc: 0.9735\n",
      "Epoch 102/200\n",
      " - 30s - loss: 1.3143 - auc: 0.9718 - val_loss: 1.2740 - val_auc: 0.9781\n",
      "Epoch 103/200\n",
      " - 30s - loss: 1.2953 - auc: 0.9733 - val_loss: 1.3307 - val_auc: 0.9758\n",
      "Epoch 104/200\n",
      " - 30s - loss: 1.3132 - auc: 0.9728 - val_loss: 1.3480 - val_auc: 0.9742\n",
      "Epoch 105/200\n",
      " - 30s - loss: 1.3162 - auc: 0.9721 - val_loss: 1.2358 - val_auc: 0.9766\n",
      "Epoch 106/200\n",
      " - 30s - loss: 1.2850 - auc: 0.9742 - val_loss: 1.3284 - val_auc: 0.9755\n",
      "Epoch 107/200\n",
      " - 30s - loss: 1.2706 - auc: 0.9745 - val_loss: 1.3714 - val_auc: 0.9731\n",
      "Epoch 108/200\n",
      " - 30s - loss: 1.2812 - auc: 0.9738 - val_loss: 1.2993 - val_auc: 0.9757\n",
      "Epoch 109/200\n",
      " - 30s - loss: 1.3126 - auc: 0.9725 - val_loss: 1.2751 - val_auc: 0.9773\n",
      "Epoch 110/200\n",
      " - 30s - loss: 1.2944 - auc: 0.9741 - val_loss: 1.3386 - val_auc: 0.9730\n",
      "Epoch 111/200\n",
      " - 30s - loss: 1.3037 - auc: 0.9727 - val_loss: 1.3033 - val_auc: 0.9743\n",
      "Epoch 112/200\n",
      " - 30s - loss: 1.3065 - auc: 0.9724 - val_loss: 1.3504 - val_auc: 0.9734\n",
      "Epoch 113/200\n",
      " - 30s - loss: 1.3408 - auc: 0.9705 - val_loss: 1.2657 - val_auc: 0.9769\n",
      "Epoch 114/200\n",
      " - 30s - loss: 1.2772 - auc: 0.9731 - val_loss: 1.3168 - val_auc: 0.9745\n",
      "Epoch 115/200\n",
      " - 30s - loss: 1.3116 - auc: 0.9732 - val_loss: 1.4323 - val_auc: 0.9680\n",
      "Epoch 116/200\n",
      " - 30s - loss: 1.2918 - auc: 0.9737 - val_loss: 1.2845 - val_auc: 0.9774\n",
      "Epoch 117/200\n",
      " - 30s - loss: 1.2846 - auc: 0.9747 - val_loss: 1.3212 - val_auc: 0.9746\n",
      "Epoch 118/200\n",
      " - 30s - loss: 1.2934 - auc: 0.9733 - val_loss: 1.3148 - val_auc: 0.9746\n",
      "Epoch 119/200\n",
      " - 30s - loss: 1.3040 - auc: 0.9715 - val_loss: 1.3299 - val_auc: 0.9745\n",
      "Epoch 120/200\n",
      " - 30s - loss: 1.2924 - auc: 0.9724 - val_loss: 1.3435 - val_auc: 0.9754\n",
      "Epoch 121/200\n",
      " - 30s - loss: 1.2992 - auc: 0.9728 - val_loss: 1.3027 - val_auc: 0.9766\n",
      "Epoch 122/200\n",
      " - 30s - loss: 1.3106 - auc: 0.9723 - val_loss: 1.3252 - val_auc: 0.9759\n",
      "Epoch 123/200\n",
      " - 30s - loss: 1.2970 - auc: 0.9732 - val_loss: 1.3155 - val_auc: 0.9765\n",
      "Epoch 124/200\n",
      " - 30s - loss: 1.3150 - auc: 0.9730 - val_loss: 1.3581 - val_auc: 0.9737\n",
      "Epoch 125/200\n",
      " - 30s - loss: 1.3074 - auc: 0.9727 - val_loss: 1.2773 - val_auc: 0.9781\n",
      "Epoch 126/200\n",
      " - 30s - loss: 1.2976 - auc: 0.9727 - val_loss: 1.2769 - val_auc: 0.9770\n",
      "Epoch 127/200\n",
      " - 30s - loss: 1.2953 - auc: 0.9738 - val_loss: 1.1656 - val_auc: 0.9795\n",
      "Epoch 128/200\n",
      " - 30s - loss: 1.2680 - auc: 0.9740 - val_loss: 1.2805 - val_auc: 0.9774\n",
      "Epoch 129/200\n",
      " - 30s - loss: 1.2741 - auc: 0.9752 - val_loss: 1.3035 - val_auc: 0.9771\n",
      "Epoch 130/200\n",
      " - 30s - loss: 1.2609 - auc: 0.9739 - val_loss: 1.2461 - val_auc: 0.9786\n",
      "Epoch 131/200\n",
      " - 30s - loss: 1.3139 - auc: 0.9726 - val_loss: 1.2719 - val_auc: 0.9751\n",
      "Epoch 132/200\n",
      " - 30s - loss: 1.2844 - auc: 0.9738 - val_loss: 1.2743 - val_auc: 0.9771\n",
      "Epoch 133/200\n",
      " - 30s - loss: 1.2770 - auc: 0.9741 - val_loss: 1.3294 - val_auc: 0.9735\n",
      "Epoch 134/200\n",
      " - 30s - loss: 1.2662 - auc: 0.9743 - val_loss: 1.3094 - val_auc: 0.9753\n",
      "Epoch 135/200\n",
      " - 30s - loss: 1.2770 - auc: 0.9738 - val_loss: 1.2765 - val_auc: 0.9767\n",
      "Epoch 136/200\n",
      " - 30s - loss: 1.2526 - auc: 0.9751 - val_loss: 1.3114 - val_auc: 0.9764\n",
      "Epoch 137/200\n",
      " - 30s - loss: 1.2543 - auc: 0.9756 - val_loss: 1.2370 - val_auc: 0.9777\n",
      "Epoch 138/200\n",
      " - 30s - loss: 1.2727 - auc: 0.9732 - val_loss: 1.1827 - val_auc: 0.9794\n",
      "Epoch 139/200\n",
      " - 30s - loss: 1.2797 - auc: 0.9729 - val_loss: 1.2594 - val_auc: 0.9751\n",
      "Epoch 140/200\n",
      " - 30s - loss: 1.2942 - auc: 0.9729 - val_loss: 1.3085 - val_auc: 0.9754\n",
      "Epoch 141/200\n",
      " - 30s - loss: 1.3024 - auc: 0.9726 - val_loss: 1.2520 - val_auc: 0.9772\n",
      "Epoch 142/200\n",
      " - 30s - loss: 1.2460 - auc: 0.9750 - val_loss: 1.2681 - val_auc: 0.9756\n",
      "Epoch 143/200\n",
      " - 30s - loss: 1.2404 - auc: 0.9760 - val_loss: 1.2170 - val_auc: 0.9769\n",
      "Epoch 144/200\n",
      " - 30s - loss: 1.2419 - auc: 0.9749 - val_loss: 1.2125 - val_auc: 0.9788\n",
      "Epoch 145/200\n",
      " - 30s - loss: 1.2865 - auc: 0.9730 - val_loss: 1.2697 - val_auc: 0.9784\n",
      "Epoch 146/200\n",
      " - 30s - loss: 1.2538 - auc: 0.9754 - val_loss: 1.2074 - val_auc: 0.9778\n",
      "Epoch 147/200\n",
      " - 30s - loss: 1.2779 - auc: 0.9748 - val_loss: 1.3504 - val_auc: 0.9739\n",
      "Epoch 148/200\n",
      " - 30s - loss: 1.2828 - auc: 0.9739 - val_loss: 1.2227 - val_auc: 0.9780\n",
      "Epoch 149/200\n",
      " - 30s - loss: 1.2554 - auc: 0.9750 - val_loss: 1.2197 - val_auc: 0.9790\n",
      "Epoch 150/200\n",
      " - 30s - loss: 1.2468 - auc: 0.9755 - val_loss: 1.2131 - val_auc: 0.9780\n",
      "Epoch 151/200\n",
      " - 30s - loss: 1.2646 - auc: 0.9753 - val_loss: 1.2382 - val_auc: 0.9748\n",
      "Epoch 152/200\n",
      " - 30s - loss: 1.2462 - auc: 0.9752 - val_loss: 1.2009 - val_auc: 0.9774\n",
      "Epoch 153/200\n",
      " - 30s - loss: 1.2833 - auc: 0.9734 - val_loss: 1.2840 - val_auc: 0.9743\n",
      "Epoch 154/200\n",
      " - 30s - loss: 1.3018 - auc: 0.9731 - val_loss: 1.3008 - val_auc: 0.9764\n",
      "Epoch 155/200\n",
      " - 30s - loss: 1.2836 - auc: 0.9728 - val_loss: 1.2906 - val_auc: 0.9760\n",
      "Epoch 156/200\n",
      " - 30s - loss: 1.2453 - auc: 0.9742 - val_loss: 1.2386 - val_auc: 0.9772\n",
      "Epoch 157/200\n",
      " - 30s - loss: 1.3067 - auc: 0.9727 - val_loss: 1.3034 - val_auc: 0.9750\n",
      "Epoch 158/200\n",
      " - 30s - loss: 1.2804 - auc: 0.9732 - val_loss: 1.2354 - val_auc: 0.9772\n",
      "Epoch 159/200\n",
      " - 30s - loss: 1.2549 - auc: 0.9744 - val_loss: 1.2734 - val_auc: 0.9723\n",
      "Epoch 160/200\n",
      " - 30s - loss: 1.2531 - auc: 0.9754 - val_loss: 1.1721 - val_auc: 0.9783\n",
      "Epoch 161/200\n",
      " - 30s - loss: 1.2452 - auc: 0.9748 - val_loss: 1.2764 - val_auc: 0.9738\n",
      "Epoch 162/200\n",
      " - 30s - loss: 1.2903 - auc: 0.9725 - val_loss: 1.3515 - val_auc: 0.9730\n",
      "Epoch 163/200\n",
      " - 30s - loss: 1.2526 - auc: 0.9744 - val_loss: 1.2597 - val_auc: 0.9754\n",
      "Epoch 164/200\n",
      " - 30s - loss: 1.2265 - auc: 0.9757 - val_loss: 1.2935 - val_auc: 0.9736\n",
      "Epoch 165/200\n",
      " - 30s - loss: 1.2469 - auc: 0.9756 - val_loss: 1.3150 - val_auc: 0.9757\n",
      "Epoch 166/200\n",
      " - 30s - loss: 1.2616 - auc: 0.9746 - val_loss: 1.1705 - val_auc: 0.9781\n",
      "Epoch 167/200\n",
      " - 30s - loss: 1.2849 - auc: 0.9731 - val_loss: 1.3115 - val_auc: 0.9754\n",
      "Epoch 168/200\n",
      " - 30s - loss: 1.2888 - auc: 0.9725 - val_loss: 1.2467 - val_auc: 0.9781\n",
      "Epoch 169/200\n",
      " - 30s - loss: 1.2609 - auc: 0.9743 - val_loss: 1.2883 - val_auc: 0.9738\n",
      "Epoch 170/200\n",
      " - 30s - loss: 1.2564 - auc: 0.9758 - val_loss: 1.3671 - val_auc: 0.9717\n",
      "Epoch 171/200\n",
      " - 30s - loss: 1.2504 - auc: 0.9740 - val_loss: 1.2915 - val_auc: 0.9743\n",
      "Epoch 172/200\n",
      " - 30s - loss: 1.2543 - auc: 0.9743 - val_loss: 1.2617 - val_auc: 0.9738\n",
      "Epoch 173/200\n",
      " - 30s - loss: 1.2708 - auc: 0.9743 - val_loss: 1.3510 - val_auc: 0.9716\n",
      "Epoch 174/200\n",
      " - 30s - loss: 1.2707 - auc: 0.9745 - val_loss: 1.2690 - val_auc: 0.9745\n",
      "Epoch 175/200\n",
      " - 30s - loss: 1.2314 - auc: 0.9761 - val_loss: 1.2758 - val_auc: 0.9748\n",
      "Epoch 176/200\n",
      " - 30s - loss: 1.2603 - auc: 0.9757 - val_loss: 1.2540 - val_auc: 0.9763\n",
      "Epoch 177/200\n",
      " - 30s - loss: 1.2479 - auc: 0.9743 - val_loss: 1.2172 - val_auc: 0.9772\n",
      "Epoch 178/200\n",
      " - 30s - loss: 1.2564 - auc: 0.9750 - val_loss: 1.3240 - val_auc: 0.9728\n",
      "Epoch 179/200\n",
      " - 30s - loss: 1.2515 - auc: 0.9754 - val_loss: 1.4011 - val_auc: 0.9725\n",
      "Epoch 180/200\n",
      " - 30s - loss: 1.2661 - auc: 0.9744 - val_loss: 1.2981 - val_auc: 0.9745\n",
      "Epoch 181/200\n",
      " - 29s - loss: 1.2644 - auc: 0.9743 - val_loss: 1.3140 - val_auc: 0.9743\n",
      "Epoch 182/200\n",
      " - 30s - loss: 1.2098 - auc: 0.9773 - val_loss: 1.2780 - val_auc: 0.9744\n",
      "Epoch 183/200\n",
      " - 30s - loss: 1.2764 - auc: 0.9731 - val_loss: 1.3008 - val_auc: 0.9755\n",
      "Epoch 184/200\n",
      " - 29s - loss: 1.2696 - auc: 0.9744 - val_loss: 1.2756 - val_auc: 0.9767\n",
      "Epoch 185/200\n",
      " - 30s - loss: 1.2745 - auc: 0.9740 - val_loss: 1.3046 - val_auc: 0.9744\n",
      "Epoch 186/200\n",
      " - 30s - loss: 1.2712 - auc: 0.9729 - val_loss: 1.3265 - val_auc: 0.9761\n",
      "Epoch 187/200\n",
      " - 30s - loss: 1.2394 - auc: 0.9763 - val_loss: 1.3149 - val_auc: 0.9749\n",
      "Epoch 188/200\n",
      " - 30s - loss: 1.2342 - auc: 0.9754 - val_loss: 1.2905 - val_auc: 0.9772\n",
      "Epoch 189/200\n",
      " - 30s - loss: 1.2343 - auc: 0.9763 - val_loss: 1.2636 - val_auc: 0.9766\n",
      "Epoch 190/200\n",
      " - 30s - loss: 1.2194 - auc: 0.9765 - val_loss: 1.2649 - val_auc: 0.9774\n",
      "Epoch 191/200\n",
      " - 30s - loss: 1.2672 - auc: 0.9745 - val_loss: 1.1675 - val_auc: 0.9788\n",
      "Epoch 192/200\n",
      " - 30s - loss: 1.2687 - auc: 0.9739 - val_loss: 1.3147 - val_auc: 0.9748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/200\n",
      " - 30s - loss: 1.2863 - auc: 0.9726 - val_loss: 1.2763 - val_auc: 0.9754\n",
      "Epoch 194/200\n",
      " - 30s - loss: 1.2445 - auc: 0.9756 - val_loss: 1.2395 - val_auc: 0.9737\n",
      "Epoch 195/200\n",
      " - 30s - loss: 1.2733 - auc: 0.9734 - val_loss: 1.2035 - val_auc: 0.9759\n",
      "Epoch 196/200\n",
      " - 30s - loss: 1.2616 - auc: 0.9748 - val_loss: 1.2291 - val_auc: 0.9764\n",
      "Epoch 197/200\n",
      " - 30s - loss: 1.2436 - auc: 0.9749 - val_loss: 1.2574 - val_auc: 0.9767\n",
      "Epoch 198/200\n",
      " - 30s - loss: 1.2519 - auc: 0.9752 - val_loss: 1.3007 - val_auc: 0.9749\n",
      "Epoch 199/200\n",
      " - 30s - loss: 1.2437 - auc: 0.9750 - val_loss: 1.2392 - val_auc: 0.9772\n",
      "Epoch 200/200\n",
      " - 30s - loss: 1.2394 - auc: 0.9755 - val_loss: 1.2494 - val_auc: 0.9784\n",
      "BorderlineSMOTE,AUSAIC Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keg/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:80: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5984 samples, validate on 871 samples\n",
      "Epoch 1/200\n",
      " - 63s - loss: 2.3637 - auc: 0.8907 - val_loss: 1.6439 - val_auc: 0.9644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keg/anaconda3/lib/python3.6/site-packages/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `roc_accuracy` which is not available. Available metrics are: val_loss,val_auc,loss,auc,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200\n",
      " - 31s - loss: 1.8437 - auc: 0.9439 - val_loss: 1.4636 - val_auc: 0.9705\n",
      "Epoch 3/200\n",
      " - 31s - loss: 1.7556 - auc: 0.9485 - val_loss: 1.3623 - val_auc: 0.9740\n",
      "Epoch 4/200\n",
      " - 31s - loss: 1.6755 - auc: 0.9536 - val_loss: 1.3612 - val_auc: 0.9754\n",
      "Epoch 5/200\n",
      " - 31s - loss: 1.6482 - auc: 0.9562 - val_loss: 1.3479 - val_auc: 0.9769\n",
      "Epoch 6/200\n",
      " - 31s - loss: 1.6208 - auc: 0.9551 - val_loss: 1.3805 - val_auc: 0.9720\n",
      "Epoch 7/200\n",
      " - 31s - loss: 1.6046 - auc: 0.9585 - val_loss: 1.2966 - val_auc: 0.9784\n",
      "Epoch 8/200\n",
      " - 31s - loss: 1.6164 - auc: 0.9552 - val_loss: 1.3423 - val_auc: 0.9764\n",
      "Epoch 9/200\n",
      " - 31s - loss: 1.5186 - auc: 0.9624 - val_loss: 1.2677 - val_auc: 0.9780\n",
      "Epoch 10/200\n",
      " - 31s - loss: 1.5565 - auc: 0.9601 - val_loss: 1.2775 - val_auc: 0.9766\n",
      "Epoch 11/200\n",
      " - 31s - loss: 1.5138 - auc: 0.9617 - val_loss: 1.2834 - val_auc: 0.9767\n",
      "Epoch 12/200\n",
      " - 31s - loss: 1.4887 - auc: 0.9627 - val_loss: 1.2416 - val_auc: 0.9784\n",
      "Epoch 13/200\n",
      " - 31s - loss: 1.4741 - auc: 0.9644 - val_loss: 1.2594 - val_auc: 0.9786\n",
      "Epoch 14/200\n",
      " - 31s - loss: 1.4719 - auc: 0.9641 - val_loss: 1.2500 - val_auc: 0.9782\n",
      "Epoch 15/200\n",
      " - 31s - loss: 1.4782 - auc: 0.9630 - val_loss: 1.2065 - val_auc: 0.9795\n",
      "Epoch 16/200\n",
      " - 31s - loss: 1.4798 - auc: 0.9636 - val_loss: 1.2049 - val_auc: 0.9800\n",
      "Epoch 17/200\n",
      " - 31s - loss: 1.4605 - auc: 0.9648 - val_loss: 1.2158 - val_auc: 0.9794\n",
      "Epoch 18/200\n",
      " - 30s - loss: 1.4840 - auc: 0.9623 - val_loss: 1.2174 - val_auc: 0.9785\n",
      "Epoch 19/200\n",
      " - 30s - loss: 1.4532 - auc: 0.9645 - val_loss: 1.2280 - val_auc: 0.9790\n",
      "Epoch 20/200\n",
      " - 30s - loss: 1.4068 - auc: 0.9671 - val_loss: 1.1516 - val_auc: 0.9813\n",
      "Epoch 21/200\n",
      " - 30s - loss: 1.4885 - auc: 0.9622 - val_loss: 1.1950 - val_auc: 0.9810\n",
      "Epoch 22/200\n",
      " - 31s - loss: 1.4017 - auc: 0.9666 - val_loss: 1.1452 - val_auc: 0.9809\n",
      "Epoch 23/200\n",
      " - 31s - loss: 1.4175 - auc: 0.9651 - val_loss: 1.1809 - val_auc: 0.9820\n",
      "Epoch 24/200\n",
      " - 31s - loss: 1.3893 - auc: 0.9673 - val_loss: 1.1780 - val_auc: 0.9800\n",
      "Epoch 25/200\n",
      " - 31s - loss: 1.3976 - auc: 0.9673 - val_loss: 1.1676 - val_auc: 0.9818\n",
      "Epoch 26/200\n",
      " - 30s - loss: 1.3900 - auc: 0.9688 - val_loss: 1.1291 - val_auc: 0.9845\n",
      "Epoch 27/200\n",
      " - 31s - loss: 1.4053 - auc: 0.9669 - val_loss: 1.1516 - val_auc: 0.9828\n",
      "Epoch 28/200\n",
      " - 31s - loss: 1.3808 - auc: 0.9678 - val_loss: 1.1543 - val_auc: 0.9799\n",
      "Epoch 29/200\n",
      " - 30s - loss: 1.3960 - auc: 0.9681 - val_loss: 1.1187 - val_auc: 0.9821\n",
      "Epoch 30/200\n",
      " - 31s - loss: 1.3748 - auc: 0.9683 - val_loss: 1.1358 - val_auc: 0.9825\n",
      "Epoch 31/200\n",
      " - 31s - loss: 1.3745 - auc: 0.9690 - val_loss: 1.1732 - val_auc: 0.9810\n",
      "Epoch 32/200\n",
      " - 30s - loss: 1.3777 - auc: 0.9685 - val_loss: 1.1115 - val_auc: 0.9831\n",
      "Epoch 33/200\n",
      " - 31s - loss: 1.3717 - auc: 0.9690 - val_loss: 1.1278 - val_auc: 0.9827\n",
      "Epoch 34/200\n",
      " - 31s - loss: 1.3569 - auc: 0.9702 - val_loss: 1.1302 - val_auc: 0.9824\n",
      "Epoch 35/200\n",
      " - 31s - loss: 1.3464 - auc: 0.9696 - val_loss: 1.1105 - val_auc: 0.9836\n",
      "Epoch 36/200\n",
      " - 31s - loss: 1.3763 - auc: 0.9688 - val_loss: 1.1420 - val_auc: 0.9823\n",
      "Epoch 37/200\n",
      " - 31s - loss: 1.3280 - auc: 0.9706 - val_loss: 1.1876 - val_auc: 0.9805\n",
      "Epoch 38/200\n",
      " - 31s - loss: 1.3464 - auc: 0.9698 - val_loss: 1.0953 - val_auc: 0.9831\n",
      "Epoch 39/200\n",
      " - 31s - loss: 1.3399 - auc: 0.9708 - val_loss: 1.1132 - val_auc: 0.9826\n",
      "Epoch 40/200\n",
      " - 31s - loss: 1.3634 - auc: 0.9691 - val_loss: 1.1305 - val_auc: 0.9820\n",
      "Epoch 41/200\n",
      " - 30s - loss: 1.3818 - auc: 0.9678 - val_loss: 1.1388 - val_auc: 0.9825\n",
      "Epoch 42/200\n",
      " - 31s - loss: 1.3520 - auc: 0.9703 - val_loss: 1.0915 - val_auc: 0.9851\n",
      "Epoch 43/200\n",
      " - 31s - loss: 1.3343 - auc: 0.9705 - val_loss: 1.1195 - val_auc: 0.9828\n",
      "Epoch 44/200\n",
      " - 31s - loss: 1.3058 - auc: 0.9712 - val_loss: 1.1025 - val_auc: 0.9825\n",
      "Epoch 45/200\n",
      " - 30s - loss: 1.3304 - auc: 0.9698 - val_loss: 1.0976 - val_auc: 0.9834\n",
      "Epoch 46/200\n",
      " - 30s - loss: 1.3558 - auc: 0.9682 - val_loss: 1.0871 - val_auc: 0.9835\n",
      "Epoch 47/200\n",
      " - 31s - loss: 1.3284 - auc: 0.9696 - val_loss: 1.1202 - val_auc: 0.9822\n",
      "Epoch 48/200\n",
      " - 31s - loss: 1.3299 - auc: 0.9695 - val_loss: 1.0889 - val_auc: 0.9846\n",
      "Epoch 49/200\n",
      " - 31s - loss: 1.3227 - auc: 0.9709 - val_loss: 1.0768 - val_auc: 0.9833\n",
      "Epoch 50/200\n",
      " - 31s - loss: 1.2818 - auc: 0.9722 - val_loss: 1.1386 - val_auc: 0.9823\n",
      "Epoch 51/200\n",
      " - 31s - loss: 1.2844 - auc: 0.9733 - val_loss: 1.0954 - val_auc: 0.9830\n",
      "Epoch 52/200\n",
      " - 30s - loss: 1.3030 - auc: 0.9723 - val_loss: 1.1172 - val_auc: 0.9830\n",
      "Epoch 53/200\n",
      " - 31s - loss: 1.2995 - auc: 0.9713 - val_loss: 1.0870 - val_auc: 0.9834\n",
      "Epoch 54/200\n",
      " - 31s - loss: 1.2854 - auc: 0.9725 - val_loss: 1.0788 - val_auc: 0.9846\n",
      "Epoch 55/200\n",
      " - 31s - loss: 1.3063 - auc: 0.9712 - val_loss: 1.0987 - val_auc: 0.9816\n",
      "Epoch 56/200\n",
      " - 31s - loss: 1.2819 - auc: 0.9729 - val_loss: 1.0957 - val_auc: 0.9835\n",
      "Epoch 57/200\n",
      " - 31s - loss: 1.3071 - auc: 0.9723 - val_loss: 1.1518 - val_auc: 0.9831\n",
      "Epoch 58/200\n",
      " - 30s - loss: 1.3019 - auc: 0.9712 - val_loss: 1.1018 - val_auc: 0.9831\n",
      "Epoch 59/200\n",
      " - 31s - loss: 1.3006 - auc: 0.9712 - val_loss: 1.1096 - val_auc: 0.9822\n",
      "Epoch 60/200\n",
      " - 31s - loss: 1.2983 - auc: 0.9718 - val_loss: 1.0921 - val_auc: 0.9831\n",
      "Epoch 61/200\n",
      " - 31s - loss: 1.2965 - auc: 0.9717 - val_loss: 1.0697 - val_auc: 0.9840\n",
      "Epoch 62/200\n",
      " - 31s - loss: 1.2865 - auc: 0.9720 - val_loss: 1.0873 - val_auc: 0.9833\n",
      "Epoch 63/200\n",
      " - 31s - loss: 1.2550 - auc: 0.9741 - val_loss: 1.0489 - val_auc: 0.9844\n",
      "Epoch 64/200\n",
      " - 31s - loss: 1.2929 - auc: 0.9722 - val_loss: 1.2638 - val_auc: 0.9769\n",
      "Epoch 65/200\n",
      " - 31s - loss: 1.2763 - auc: 0.9732 - val_loss: 1.0701 - val_auc: 0.9839\n",
      "Epoch 66/200\n",
      " - 30s - loss: 1.2378 - auc: 0.9743 - val_loss: 1.0956 - val_auc: 0.9826\n",
      "Epoch 67/200\n",
      " - 31s - loss: 1.2690 - auc: 0.9736 - val_loss: 1.0173 - val_auc: 0.9850\n",
      "Epoch 68/200\n",
      " - 31s - loss: 1.2879 - auc: 0.9708 - val_loss: 1.1131 - val_auc: 0.9825\n",
      "Epoch 69/200\n",
      " - 31s - loss: 1.2841 - auc: 0.9729 - val_loss: 1.0732 - val_auc: 0.9840\n",
      "Epoch 70/200\n",
      " - 31s - loss: 1.2627 - auc: 0.9737 - val_loss: 1.1668 - val_auc: 0.9815\n",
      "Epoch 71/200\n",
      " - 30s - loss: 1.2660 - auc: 0.9731 - val_loss: 1.0801 - val_auc: 0.9822\n",
      "Epoch 72/200\n",
      " - 31s - loss: 1.2768 - auc: 0.9731 - val_loss: 1.0654 - val_auc: 0.9846\n",
      "Epoch 73/200\n",
      " - 31s - loss: 1.2692 - auc: 0.9731 - val_loss: 1.1186 - val_auc: 0.9833\n",
      "Epoch 74/200\n",
      " - 30s - loss: 1.2669 - auc: 0.9738 - val_loss: 0.9798 - val_auc: 0.9866\n",
      "Epoch 75/200\n",
      " - 31s - loss: 1.2760 - auc: 0.9731 - val_loss: 1.1461 - val_auc: 0.9804\n",
      "Epoch 76/200\n",
      " - 31s - loss: 1.3119 - auc: 0.9689 - val_loss: 1.0370 - val_auc: 0.9851\n",
      "Epoch 77/200\n",
      " - 31s - loss: 1.2576 - auc: 0.9728 - val_loss: 1.0266 - val_auc: 0.9854\n",
      "Epoch 78/200\n",
      " - 31s - loss: 1.2620 - auc: 0.9749 - val_loss: 1.1077 - val_auc: 0.9836\n",
      "Epoch 79/200\n",
      " - 31s - loss: 1.2676 - auc: 0.9725 - val_loss: 1.0463 - val_auc: 0.9849\n",
      "Epoch 80/200\n",
      " - 31s - loss: 1.2710 - auc: 0.9714 - val_loss: 1.1298 - val_auc: 0.9822\n",
      "Epoch 81/200\n",
      " - 30s - loss: 1.2502 - auc: 0.9732 - val_loss: 1.0516 - val_auc: 0.9849\n",
      "Epoch 82/200\n",
      " - 31s - loss: 1.2453 - auc: 0.9730 - val_loss: 1.0831 - val_auc: 0.9833\n",
      "Epoch 83/200\n",
      " - 31s - loss: 1.2410 - auc: 0.9735 - val_loss: 1.0130 - val_auc: 0.9851\n",
      "Epoch 84/200\n",
      " - 31s - loss: 1.2541 - auc: 0.9737 - val_loss: 1.0482 - val_auc: 0.9834\n",
      "Epoch 85/200\n",
      " - 31s - loss: 1.2739 - auc: 0.9729 - val_loss: 1.1155 - val_auc: 0.9830\n",
      "Epoch 86/200\n",
      " - 31s - loss: 1.2600 - auc: 0.9735 - val_loss: 1.0659 - val_auc: 0.9845\n",
      "Epoch 87/200\n",
      " - 31s - loss: 1.2644 - auc: 0.9721 - val_loss: 1.1581 - val_auc: 0.9811\n",
      "Epoch 88/200\n",
      " - 31s - loss: 1.2405 - auc: 0.9738 - val_loss: 1.1006 - val_auc: 0.9826\n",
      "Epoch 89/200\n",
      " - 30s - loss: 1.2421 - auc: 0.9734 - val_loss: 1.1179 - val_auc: 0.9821\n",
      "Epoch 90/200\n",
      " - 30s - loss: 1.2239 - auc: 0.9751 - val_loss: 1.0255 - val_auc: 0.9854\n",
      "Epoch 91/200\n",
      " - 30s - loss: 1.2476 - auc: 0.9746 - val_loss: 1.1339 - val_auc: 0.9824\n",
      "Epoch 92/200\n",
      " - 31s - loss: 1.2383 - auc: 0.9743 - val_loss: 0.9934 - val_auc: 0.9859\n",
      "Epoch 93/200\n",
      " - 31s - loss: 1.2797 - auc: 0.9718 - val_loss: 1.0288 - val_auc: 0.9858\n",
      "Epoch 94/200\n",
      " - 31s - loss: 1.2397 - auc: 0.9738 - val_loss: 1.0877 - val_auc: 0.9830\n",
      "Epoch 95/200\n",
      " - 31s - loss: 1.2389 - auc: 0.9743 - val_loss: 1.0623 - val_auc: 0.9851\n",
      "Epoch 96/200\n",
      " - 31s - loss: 1.2507 - auc: 0.9751 - val_loss: 1.1317 - val_auc: 0.9830\n",
      "Epoch 97/200\n",
      " - 31s - loss: 1.2447 - auc: 0.9740 - val_loss: 1.0977 - val_auc: 0.9836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/200\n",
      " - 31s - loss: 1.2356 - auc: 0.9742 - val_loss: 0.9984 - val_auc: 0.9859\n",
      "Epoch 99/200\n",
      " - 31s - loss: 1.2384 - auc: 0.9751 - val_loss: 1.0577 - val_auc: 0.9843\n",
      "Epoch 100/200\n",
      " - 31s - loss: 1.2569 - auc: 0.9746 - val_loss: 1.1292 - val_auc: 0.9821\n",
      "Epoch 101/200\n",
      " - 31s - loss: 1.2212 - auc: 0.9743 - val_loss: 1.0826 - val_auc: 0.9830\n",
      "Epoch 102/200\n",
      " - 31s - loss: 1.2460 - auc: 0.9740 - val_loss: 1.0678 - val_auc: 0.9834\n",
      "Epoch 103/200\n",
      " - 31s - loss: 1.2095 - auc: 0.9753 - val_loss: 1.0374 - val_auc: 0.9848\n",
      "Epoch 104/200\n",
      " - 31s - loss: 1.2411 - auc: 0.9741 - val_loss: 1.0409 - val_auc: 0.9852\n",
      "Epoch 105/200\n",
      " - 31s - loss: 1.2151 - auc: 0.9756 - val_loss: 1.0563 - val_auc: 0.9851\n",
      "Epoch 106/200\n",
      " - 31s - loss: 1.2195 - auc: 0.9751 - val_loss: 1.1164 - val_auc: 0.9822\n",
      "Epoch 107/200\n",
      " - 31s - loss: 1.2169 - auc: 0.9754 - val_loss: 1.0446 - val_auc: 0.9842\n",
      "Epoch 108/200\n",
      " - 30s - loss: 1.2374 - auc: 0.9737 - val_loss: 1.1114 - val_auc: 0.9826\n",
      "Epoch 109/200\n",
      " - 31s - loss: 1.2088 - auc: 0.9771 - val_loss: 1.0236 - val_auc: 0.9849\n",
      "Epoch 110/200\n",
      " - 31s - loss: 1.2319 - auc: 0.9750 - val_loss: 1.0587 - val_auc: 0.9838\n",
      "Epoch 111/200\n",
      " - 31s - loss: 1.2317 - auc: 0.9754 - val_loss: 1.1193 - val_auc: 0.9828\n",
      "Epoch 112/200\n",
      " - 31s - loss: 1.1998 - auc: 0.9764 - val_loss: 0.9847 - val_auc: 0.9862\n",
      "Epoch 113/200\n",
      " - 31s - loss: 1.2301 - auc: 0.9737 - val_loss: 1.0443 - val_auc: 0.9852\n",
      "Epoch 114/200\n",
      " - 31s - loss: 1.2179 - auc: 0.9745 - val_loss: 1.0158 - val_auc: 0.9852\n",
      "Epoch 115/200\n",
      " - 31s - loss: 1.1919 - auc: 0.9768 - val_loss: 0.9883 - val_auc: 0.9862\n",
      "Epoch 116/200\n",
      " - 30s - loss: 1.2324 - auc: 0.9743 - val_loss: 1.0393 - val_auc: 0.9845\n",
      "Epoch 117/200\n",
      " - 31s - loss: 1.1965 - auc: 0.9768 - val_loss: 1.0197 - val_auc: 0.9849\n",
      "Epoch 118/200\n",
      " - 31s - loss: 1.2374 - auc: 0.9744 - val_loss: 1.0037 - val_auc: 0.9865\n",
      "Epoch 119/200\n",
      " - 31s - loss: 1.2022 - auc: 0.9753 - val_loss: 1.0399 - val_auc: 0.9849\n",
      "Epoch 120/200\n",
      " - 31s - loss: 1.2136 - auc: 0.9764 - val_loss: 1.1165 - val_auc: 0.9815\n",
      "Epoch 121/200\n",
      " - 30s - loss: 1.2144 - auc: 0.9758 - val_loss: 1.0170 - val_auc: 0.9860\n",
      "Epoch 122/200\n",
      " - 31s - loss: 1.2224 - auc: 0.9754 - val_loss: 1.0267 - val_auc: 0.9855\n",
      "Epoch 123/200\n",
      " - 30s - loss: 1.2077 - auc: 0.9759 - val_loss: 1.0065 - val_auc: 0.9852\n",
      "Epoch 124/200\n",
      " - 30s - loss: 1.2435 - auc: 0.9733 - val_loss: 1.1159 - val_auc: 0.9808\n",
      "Epoch 125/200\n",
      " - 31s - loss: 1.2227 - auc: 0.9754 - val_loss: 1.0576 - val_auc: 0.9845\n",
      "Epoch 126/200\n",
      " - 31s - loss: 1.2268 - auc: 0.9752 - val_loss: 1.0465 - val_auc: 0.9841\n",
      "Epoch 127/200\n",
      " - 31s - loss: 1.2370 - auc: 0.9741 - val_loss: 1.0764 - val_auc: 0.9833\n",
      "Epoch 128/200\n",
      " - 31s - loss: 1.1994 - auc: 0.9765 - val_loss: 0.9564 - val_auc: 0.9868\n",
      "Epoch 129/200\n",
      " - 31s - loss: 1.1907 - auc: 0.9758 - val_loss: 1.0144 - val_auc: 0.9852\n",
      "Epoch 130/200\n",
      " - 31s - loss: 1.2121 - auc: 0.9740 - val_loss: 1.0267 - val_auc: 0.9851\n",
      "Epoch 131/200\n",
      " - 31s - loss: 1.1870 - auc: 0.9772 - val_loss: 1.0268 - val_auc: 0.9850\n",
      "Epoch 132/200\n",
      " - 31s - loss: 1.1928 - auc: 0.9754 - val_loss: 1.0404 - val_auc: 0.9847\n",
      "Epoch 133/200\n",
      " - 31s - loss: 1.2023 - auc: 0.9763 - val_loss: 1.0709 - val_auc: 0.9835\n",
      "Epoch 134/200\n",
      " - 31s - loss: 1.2442 - auc: 0.9735 - val_loss: 1.0566 - val_auc: 0.9835\n",
      "Epoch 135/200\n",
      " - 31s - loss: 1.2049 - auc: 0.9754 - val_loss: 0.9807 - val_auc: 0.9862\n",
      "Epoch 136/200\n",
      " - 31s - loss: 1.2189 - auc: 0.9747 - val_loss: 0.9978 - val_auc: 0.9866\n",
      "Epoch 137/200\n",
      " - 31s - loss: 1.1907 - auc: 0.9762 - val_loss: 1.0126 - val_auc: 0.9853\n",
      "Epoch 138/200\n",
      " - 31s - loss: 1.1844 - auc: 0.9768 - val_loss: 1.0150 - val_auc: 0.9850\n",
      "Epoch 139/200\n",
      " - 30s - loss: 1.2219 - auc: 0.9747 - val_loss: 1.0836 - val_auc: 0.9831\n",
      "Epoch 140/200\n",
      " - 31s - loss: 1.1855 - auc: 0.9770 - val_loss: 1.0116 - val_auc: 0.9850\n",
      "Epoch 141/200\n",
      " - 30s - loss: 1.2049 - auc: 0.9759 - val_loss: 1.0479 - val_auc: 0.9840\n",
      "Epoch 142/200\n",
      " - 31s - loss: 1.2152 - auc: 0.9751 - val_loss: 0.9693 - val_auc: 0.9856\n",
      "Epoch 143/200\n",
      " - 31s - loss: 1.1934 - auc: 0.9765 - val_loss: 0.9910 - val_auc: 0.9850\n",
      "Epoch 144/200\n",
      " - 31s - loss: 1.1766 - auc: 0.9759 - val_loss: 0.9653 - val_auc: 0.9861\n",
      "Epoch 145/200\n",
      " - 31s - loss: 1.1948 - auc: 0.9761 - val_loss: 0.9919 - val_auc: 0.9858\n",
      "Epoch 146/200\n",
      " - 31s - loss: 1.1912 - auc: 0.9766 - val_loss: 1.0122 - val_auc: 0.9853\n",
      "Epoch 147/200\n",
      " - 31s - loss: 1.1969 - auc: 0.9757 - val_loss: 1.0295 - val_auc: 0.9843\n",
      "Epoch 148/200\n",
      " - 30s - loss: 1.1743 - auc: 0.9765 - val_loss: 1.0862 - val_auc: 0.9827\n",
      "Epoch 149/200\n",
      " - 31s - loss: 1.2228 - auc: 0.9754 - val_loss: 1.0277 - val_auc: 0.9846\n",
      "Epoch 150/200\n",
      " - 30s - loss: 1.2148 - auc: 0.9747 - val_loss: 1.0757 - val_auc: 0.9834\n",
      "Epoch 151/200\n",
      " - 30s - loss: 1.1972 - auc: 0.9753 - val_loss: 1.1032 - val_auc: 0.9827\n",
      "Epoch 152/200\n",
      " - 31s - loss: 1.2372 - auc: 0.9744 - val_loss: 1.0033 - val_auc: 0.9864\n",
      "Epoch 153/200\n",
      " - 31s - loss: 1.1852 - auc: 0.9765 - val_loss: 1.0061 - val_auc: 0.9862\n",
      "Epoch 154/200\n",
      " - 31s - loss: 1.1867 - auc: 0.9779 - val_loss: 0.9861 - val_auc: 0.9854\n",
      "Epoch 155/200\n",
      " - 31s - loss: 1.2000 - auc: 0.9756 - val_loss: 0.9899 - val_auc: 0.9862\n",
      "Epoch 156/200\n",
      " - 31s - loss: 1.1890 - auc: 0.9769 - val_loss: 0.9860 - val_auc: 0.9845\n",
      "Epoch 157/200\n",
      " - 31s - loss: 1.1794 - auc: 0.9766 - val_loss: 1.0191 - val_auc: 0.9860\n",
      "Epoch 158/200\n",
      " - 30s - loss: 1.1597 - auc: 0.9762 - val_loss: 0.9686 - val_auc: 0.9866\n",
      "Epoch 159/200\n",
      " - 31s - loss: 1.2252 - auc: 0.9752 - val_loss: 1.0206 - val_auc: 0.9859\n",
      "Epoch 160/200\n",
      " - 31s - loss: 1.2037 - auc: 0.9753 - val_loss: 1.0312 - val_auc: 0.9855\n",
      "Epoch 161/200\n",
      " - 31s - loss: 1.1706 - auc: 0.9788 - val_loss: 1.0799 - val_auc: 0.9838\n",
      "Epoch 162/200\n",
      " - 31s - loss: 1.2139 - auc: 0.9753 - val_loss: 1.0173 - val_auc: 0.9849\n",
      "Epoch 163/200\n",
      " - 31s - loss: 1.1946 - auc: 0.9762 - val_loss: 1.0971 - val_auc: 0.9833\n",
      "Epoch 164/200\n",
      " - 31s - loss: 1.2210 - auc: 0.9731 - val_loss: 0.9549 - val_auc: 0.9880\n",
      "Epoch 165/200\n",
      " - 31s - loss: 1.1837 - auc: 0.9772 - val_loss: 1.0110 - val_auc: 0.9859\n",
      "Epoch 166/200\n",
      " - 31s - loss: 1.2320 - auc: 0.9731 - val_loss: 1.0389 - val_auc: 0.9855\n",
      "Epoch 167/200\n",
      " - 31s - loss: 1.1961 - auc: 0.9756 - val_loss: 1.0005 - val_auc: 0.9857\n",
      "Epoch 168/200\n",
      " - 31s - loss: 1.2159 - auc: 0.9759 - val_loss: 1.0819 - val_auc: 0.9831\n",
      "Epoch 169/200\n",
      " - 31s - loss: 1.1756 - auc: 0.9764 - val_loss: 1.0603 - val_auc: 0.9835\n",
      "Epoch 170/200\n",
      " - 31s - loss: 1.2141 - auc: 0.9764 - val_loss: 1.0449 - val_auc: 0.9842\n",
      "Epoch 171/200\n",
      " - 30s - loss: 1.1810 - auc: 0.9760 - val_loss: 0.9701 - val_auc: 0.9862\n",
      "Epoch 172/200\n",
      " - 30s - loss: 1.2252 - auc: 0.9730 - val_loss: 0.9893 - val_auc: 0.9865\n",
      "Epoch 173/200\n",
      " - 30s - loss: 1.1798 - auc: 0.9768 - val_loss: 1.0109 - val_auc: 0.9852\n",
      "Epoch 174/200\n",
      " - 30s - loss: 1.1804 - auc: 0.9772 - val_loss: 0.9651 - val_auc: 0.9860\n",
      "Epoch 175/200\n",
      " - 31s - loss: 1.1647 - auc: 0.9792 - val_loss: 1.0828 - val_auc: 0.9825\n",
      "Epoch 176/200\n",
      " - 31s - loss: 1.1501 - auc: 0.9772 - val_loss: 1.0059 - val_auc: 0.9843\n",
      "Epoch 177/200\n",
      " - 31s - loss: 1.2383 - auc: 0.9744 - val_loss: 1.0479 - val_auc: 0.9850\n",
      "Epoch 178/200\n",
      " - 31s - loss: 1.1959 - auc: 0.9762 - val_loss: 1.0109 - val_auc: 0.9853\n",
      "Epoch 179/200\n",
      " - 31s - loss: 1.1445 - auc: 0.9790 - val_loss: 1.0001 - val_auc: 0.9854\n",
      "Epoch 180/200\n",
      " - 30s - loss: 1.1936 - auc: 0.9763 - val_loss: 1.0661 - val_auc: 0.9841\n",
      "Epoch 181/200\n",
      " - 30s - loss: 1.1758 - auc: 0.9768 - val_loss: 1.0011 - val_auc: 0.9860\n",
      "Epoch 182/200\n",
      " - 31s - loss: 1.1557 - auc: 0.9780 - val_loss: 1.0368 - val_auc: 0.9839\n",
      "Epoch 183/200\n",
      " - 31s - loss: 1.1466 - auc: 0.9773 - val_loss: 1.0334 - val_auc: 0.9853\n",
      "Epoch 184/200\n",
      " - 30s - loss: 1.1755 - auc: 0.9774 - val_loss: 1.0306 - val_auc: 0.9854\n",
      "Epoch 185/200\n",
      " - 31s - loss: 1.2053 - auc: 0.9764 - val_loss: 1.0445 - val_auc: 0.9849\n",
      "Epoch 186/200\n",
      " - 31s - loss: 1.1744 - auc: 0.9764 - val_loss: 1.0160 - val_auc: 0.9855\n",
      "Epoch 187/200\n",
      " - 31s - loss: 1.1776 - auc: 0.9765 - val_loss: 1.0391 - val_auc: 0.9855\n",
      "Epoch 188/200\n",
      " - 30s - loss: 1.1765 - auc: 0.9769 - val_loss: 0.9294 - val_auc: 0.9880\n",
      "Epoch 189/200\n",
      " - 31s - loss: 1.1962 - auc: 0.9754 - val_loss: 1.0097 - val_auc: 0.9866\n",
      "Epoch 190/200\n",
      " - 31s - loss: 1.1908 - auc: 0.9758 - val_loss: 1.0494 - val_auc: 0.9841\n",
      "Epoch 191/200\n",
      " - 31s - loss: 1.1783 - auc: 0.9777 - val_loss: 0.9734 - val_auc: 0.9866\n",
      "Epoch 192/200\n",
      " - 31s - loss: 1.1725 - auc: 0.9765 - val_loss: 0.9243 - val_auc: 0.9870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/200\n",
      " - 31s - loss: 1.1987 - auc: 0.9759 - val_loss: 0.9843 - val_auc: 0.9852\n",
      "Epoch 194/200\n",
      " - 30s - loss: 1.1944 - auc: 0.9762 - val_loss: 0.9753 - val_auc: 0.9870\n",
      "Epoch 195/200\n",
      " - 31s - loss: 1.1760 - auc: 0.9771 - val_loss: 1.0227 - val_auc: 0.9848\n",
      "Epoch 196/200\n",
      " - 30s - loss: 1.1787 - auc: 0.9761 - val_loss: 1.0890 - val_auc: 0.9829\n",
      "Epoch 197/200\n",
      " - 31s - loss: 1.1660 - auc: 0.9778 - val_loss: 0.9925 - val_auc: 0.9862\n",
      "Epoch 198/200\n",
      " - 31s - loss: 1.1843 - auc: 0.9759 - val_loss: 1.0168 - val_auc: 0.9848\n",
      "Epoch 199/200\n",
      " - 31s - loss: 1.1761 - auc: 0.9779 - val_loss: 0.9951 - val_auc: 0.9863\n",
      "Epoch 200/200\n",
      " - 30s - loss: 1.1559 - auc: 0.9785 - val_loss: 1.0439 - val_auc: 0.9845\n",
      "SMOTETomek,AUSAIC Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keg/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:80: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2858 samples, validate on 715 samples\n",
      "Epoch 1/200\n",
      " - 49s - loss: 2.2088 - auc: 0.8903 - val_loss: 1.9451 - val_auc: 0.9614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keg/anaconda3/lib/python3.6/site-packages/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `roc_accuracy` which is not available. Available metrics are: val_loss,val_auc,loss,auc,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200\n",
      " - 16s - loss: 1.5009 - auc: 0.9625 - val_loss: 0.9555 - val_auc: 0.9843\n",
      "Epoch 3/200\n",
      " - 16s - loss: 1.3458 - auc: 0.9692 - val_loss: 0.8007 - val_auc: 0.9884\n",
      "Epoch 4/200\n",
      " - 16s - loss: 1.2834 - auc: 0.9702 - val_loss: 0.7500 - val_auc: 0.9884\n",
      "Epoch 5/200\n",
      " - 16s - loss: 1.2211 - auc: 0.9729 - val_loss: 0.7811 - val_auc: 0.9879\n",
      "Epoch 6/200\n",
      " - 16s - loss: 1.1443 - auc: 0.9743 - val_loss: 0.6656 - val_auc: 0.9911\n",
      "Epoch 7/200\n",
      " - 16s - loss: 1.1283 - auc: 0.9761 - val_loss: 0.7014 - val_auc: 0.9901\n",
      "Epoch 8/200\n",
      " - 16s - loss: 1.0821 - auc: 0.9781 - val_loss: 0.6444 - val_auc: 0.9916\n",
      "Epoch 9/200\n",
      " - 16s - loss: 1.0759 - auc: 0.9784 - val_loss: 0.6578 - val_auc: 0.9918\n",
      "Epoch 10/200\n",
      " - 16s - loss: 1.0748 - auc: 0.9786 - val_loss: 0.6149 - val_auc: 0.9920\n",
      "Epoch 11/200\n",
      " - 16s - loss: 1.0039 - auc: 0.9821 - val_loss: 0.5947 - val_auc: 0.9928\n",
      "Epoch 12/200\n",
      " - 16s - loss: 1.0082 - auc: 0.9807 - val_loss: 0.5894 - val_auc: 0.9925\n",
      "Epoch 13/200\n",
      " - 16s - loss: 1.0040 - auc: 0.9803 - val_loss: 0.5496 - val_auc: 0.9939\n",
      "Epoch 14/200\n",
      " - 16s - loss: 0.9699 - auc: 0.9813 - val_loss: 0.5849 - val_auc: 0.9928\n",
      "Epoch 15/200\n",
      " - 16s - loss: 0.9849 - auc: 0.9814 - val_loss: 0.5353 - val_auc: 0.9936\n",
      "Epoch 16/200\n",
      " - 16s - loss: 0.9545 - auc: 0.9833 - val_loss: 0.5675 - val_auc: 0.9929\n",
      "Epoch 17/200\n",
      " - 16s - loss: 0.9944 - auc: 0.9808 - val_loss: 0.5448 - val_auc: 0.9937\n",
      "Epoch 18/200\n",
      " - 16s - loss: 0.9699 - auc: 0.9799 - val_loss: 0.5452 - val_auc: 0.9938\n",
      "Epoch 19/200\n",
      " - 16s - loss: 0.9604 - auc: 0.9824 - val_loss: 0.5910 - val_auc: 0.9929\n",
      "Epoch 20/200\n",
      " - 16s - loss: 0.9388 - auc: 0.9820 - val_loss: 0.5385 - val_auc: 0.9936\n",
      "Epoch 21/200\n",
      " - 16s - loss: 0.9176 - auc: 0.9837 - val_loss: 0.5497 - val_auc: 0.9934\n",
      "Epoch 22/200\n",
      " - 16s - loss: 0.8784 - auc: 0.9850 - val_loss: 0.5619 - val_auc: 0.9928\n",
      "Epoch 23/200\n",
      " - 16s - loss: 0.8935 - auc: 0.9833 - val_loss: 0.5179 - val_auc: 0.9940\n",
      "Epoch 24/200\n",
      " - 16s - loss: 0.9552 - auc: 0.9818 - val_loss: 0.5121 - val_auc: 0.9944\n",
      "Epoch 25/200\n",
      " - 16s - loss: 0.8932 - auc: 0.9835 - val_loss: 0.5190 - val_auc: 0.9941\n",
      "Epoch 26/200\n",
      " - 16s - loss: 0.8328 - auc: 0.9867 - val_loss: 0.4883 - val_auc: 0.9944\n",
      "Epoch 27/200\n",
      " - 16s - loss: 0.9132 - auc: 0.9835 - val_loss: 0.5107 - val_auc: 0.9940\n",
      "Epoch 28/200\n",
      " - 16s - loss: 0.9145 - auc: 0.9828 - val_loss: 0.4736 - val_auc: 0.9948\n",
      "Epoch 29/200\n",
      " - 16s - loss: 0.9268 - auc: 0.9828 - val_loss: 0.5086 - val_auc: 0.9944\n",
      "Epoch 30/200\n",
      " - 16s - loss: 0.9050 - auc: 0.9838 - val_loss: 0.4845 - val_auc: 0.9947\n",
      "Epoch 31/200\n",
      " - 16s - loss: 0.8743 - auc: 0.9859 - val_loss: 0.5136 - val_auc: 0.9938\n",
      "Epoch 32/200\n",
      " - 16s - loss: 0.8568 - auc: 0.9850 - val_loss: 0.5104 - val_auc: 0.9942\n",
      "Epoch 33/200\n",
      " - 16s - loss: 0.8576 - auc: 0.9854 - val_loss: 0.4794 - val_auc: 0.9948\n",
      "Epoch 34/200\n",
      " - 16s - loss: 0.8488 - auc: 0.9866 - val_loss: 0.4937 - val_auc: 0.9944\n",
      "Epoch 35/200\n",
      " - 16s - loss: 0.8374 - auc: 0.9864 - val_loss: 0.4578 - val_auc: 0.9951\n",
      "Epoch 36/200\n",
      " - 16s - loss: 0.8595 - auc: 0.9858 - val_loss: 0.4876 - val_auc: 0.9944\n",
      "Epoch 37/200\n",
      " - 16s - loss: 0.8210 - auc: 0.9875 - val_loss: 0.4875 - val_auc: 0.9944\n",
      "Epoch 38/200\n",
      " - 16s - loss: 0.8314 - auc: 0.9848 - val_loss: 0.4774 - val_auc: 0.9944\n",
      "Epoch 39/200\n",
      " - 16s - loss: 0.8405 - auc: 0.9860 - val_loss: 0.4765 - val_auc: 0.9944\n",
      "Epoch 40/200\n",
      " - 16s - loss: 0.8374 - auc: 0.9865 - val_loss: 0.4931 - val_auc: 0.9941\n",
      "Epoch 41/200\n",
      " - 16s - loss: 0.8104 - auc: 0.9856 - val_loss: 0.4857 - val_auc: 0.9942\n",
      "Epoch 42/200\n",
      " - 16s - loss: 0.8056 - auc: 0.9850 - val_loss: 0.4808 - val_auc: 0.9945\n",
      "Epoch 43/200\n",
      " - 16s - loss: 0.8045 - auc: 0.9852 - val_loss: 0.4700 - val_auc: 0.9947\n",
      "Epoch 44/200\n",
      " - 16s - loss: 0.8357 - auc: 0.9856 - val_loss: 0.4829 - val_auc: 0.9952\n",
      "Epoch 45/200\n",
      " - 16s - loss: 0.7719 - auc: 0.9880 - val_loss: 0.4882 - val_auc: 0.9942\n",
      "Epoch 46/200\n",
      " - 16s - loss: 0.7949 - auc: 0.9878 - val_loss: 0.5083 - val_auc: 0.9939\n",
      "Epoch 47/200\n",
      " - 16s - loss: 0.7797 - auc: 0.9881 - val_loss: 0.4156 - val_auc: 0.9963\n",
      "Epoch 48/200\n",
      " - 16s - loss: 0.8028 - auc: 0.9883 - val_loss: 0.4402 - val_auc: 0.9960\n",
      "Epoch 49/200\n",
      " - 16s - loss: 0.7912 - auc: 0.9869 - val_loss: 0.4881 - val_auc: 0.9943\n",
      "Epoch 50/200\n",
      " - 16s - loss: 0.7695 - auc: 0.9880 - val_loss: 0.4561 - val_auc: 0.9957\n",
      "Epoch 51/200\n",
      " - 16s - loss: 0.7741 - auc: 0.9884 - val_loss: 0.4361 - val_auc: 0.9948\n",
      "Epoch 52/200\n",
      " - 16s - loss: 0.7962 - auc: 0.9869 - val_loss: 0.4512 - val_auc: 0.9959\n",
      "Epoch 53/200\n",
      " - 16s - loss: 0.7685 - auc: 0.9883 - val_loss: 0.4887 - val_auc: 0.9953\n",
      "Epoch 54/200\n",
      " - 16s - loss: 0.7120 - auc: 0.9907 - val_loss: 0.4235 - val_auc: 0.9952\n",
      "Epoch 55/200\n",
      " - 16s - loss: 0.7744 - auc: 0.9867 - val_loss: 0.4564 - val_auc: 0.9948\n",
      "Epoch 56/200\n",
      " - 16s - loss: 0.7728 - auc: 0.9861 - val_loss: 0.4533 - val_auc: 0.9947\n",
      "Epoch 57/200\n",
      " - 16s - loss: 0.7447 - auc: 0.9881 - val_loss: 0.4646 - val_auc: 0.9947\n",
      "Epoch 58/200\n",
      " - 16s - loss: 0.7949 - auc: 0.9861 - val_loss: 0.4197 - val_auc: 0.9954\n",
      "Epoch 59/200\n",
      " - 16s - loss: 0.8087 - auc: 0.9855 - val_loss: 0.4454 - val_auc: 0.9962\n",
      "Epoch 60/200\n",
      " - 16s - loss: 0.7390 - auc: 0.9870 - val_loss: 0.4356 - val_auc: 0.9962\n",
      "Epoch 61/200\n",
      " - 16s - loss: 0.7953 - auc: 0.9864 - val_loss: 0.4215 - val_auc: 0.9964\n",
      "Epoch 62/200\n",
      " - 16s - loss: 0.7565 - auc: 0.9882 - val_loss: 0.4720 - val_auc: 0.9957\n",
      "Epoch 63/200\n",
      " - 16s - loss: 0.7263 - auc: 0.9896 - val_loss: 0.4826 - val_auc: 0.9957\n",
      "Epoch 64/200\n",
      " - 16s - loss: 0.7415 - auc: 0.9893 - val_loss: 0.4352 - val_auc: 0.9963\n",
      "Epoch 65/200\n",
      " - 16s - loss: 0.7627 - auc: 0.9866 - val_loss: 0.4353 - val_auc: 0.9963\n",
      "Epoch 66/200\n",
      " - 16s - loss: 0.7710 - auc: 0.9876 - val_loss: 0.4429 - val_auc: 0.9963\n",
      "Epoch 67/200\n",
      " - 16s - loss: 0.7464 - auc: 0.9889 - val_loss: 0.4456 - val_auc: 0.9958\n",
      "Epoch 68/200\n",
      " - 16s - loss: 0.7606 - auc: 0.9887 - val_loss: 0.4662 - val_auc: 0.9956\n",
      "Epoch 69/200\n",
      " - 16s - loss: 0.7446 - auc: 0.9892 - val_loss: 0.4582 - val_auc: 0.9959\n",
      "Epoch 70/200\n",
      " - 16s - loss: 0.7359 - auc: 0.9888 - val_loss: 0.4168 - val_auc: 0.9964\n",
      "Epoch 71/200\n",
      " - 16s - loss: 0.7720 - auc: 0.9869 - val_loss: 0.4186 - val_auc: 0.9964\n",
      "Epoch 72/200\n",
      " - 16s - loss: 0.7615 - auc: 0.9870 - val_loss: 0.4410 - val_auc: 0.9959\n",
      "Epoch 73/200\n",
      " - 16s - loss: 0.7667 - auc: 0.9868 - val_loss: 0.4325 - val_auc: 0.9962\n",
      "Epoch 74/200\n",
      " - 16s - loss: 0.7375 - auc: 0.9892 - val_loss: 0.4753 - val_auc: 0.9958\n",
      "Epoch 75/200\n",
      " - 16s - loss: 0.7655 - auc: 0.9863 - val_loss: 0.4267 - val_auc: 0.9962\n",
      "Epoch 76/200\n",
      " - 16s - loss: 0.7848 - auc: 0.9865 - val_loss: 0.4327 - val_auc: 0.9962\n",
      "Epoch 77/200\n",
      " - 16s - loss: 0.7519 - auc: 0.9886 - val_loss: 0.4232 - val_auc: 0.9964\n",
      "Epoch 78/200\n",
      " - 16s - loss: 0.7401 - auc: 0.9887 - val_loss: 0.4396 - val_auc: 0.9963\n",
      "Epoch 79/200\n",
      " - 16s - loss: 0.6932 - auc: 0.9896 - val_loss: 0.4740 - val_auc: 0.9953\n",
      "Epoch 80/200\n",
      " - 16s - loss: 0.7264 - auc: 0.9891 - val_loss: 0.4163 - val_auc: 0.9966\n",
      "Epoch 81/200\n",
      " - 16s - loss: 0.6735 - auc: 0.9912 - val_loss: 0.4423 - val_auc: 0.9960\n",
      "Epoch 82/200\n",
      " - 16s - loss: 0.7364 - auc: 0.9894 - val_loss: 0.4273 - val_auc: 0.9964\n",
      "Epoch 83/200\n",
      " - 16s - loss: 0.7352 - auc: 0.9889 - val_loss: 0.4475 - val_auc: 0.9959\n",
      "Epoch 84/200\n",
      " - 16s - loss: 0.7263 - auc: 0.9894 - val_loss: 0.4339 - val_auc: 0.9962\n",
      "Epoch 85/200\n",
      " - 16s - loss: 0.6794 - auc: 0.9900 - val_loss: 0.4317 - val_auc: 0.9960\n",
      "Epoch 86/200\n",
      " - 16s - loss: 0.7276 - auc: 0.9899 - val_loss: 0.3878 - val_auc: 0.9968\n",
      "Epoch 87/200\n",
      " - 16s - loss: 0.7442 - auc: 0.9877 - val_loss: 0.4228 - val_auc: 0.9964\n",
      "Epoch 88/200\n",
      " - 16s - loss: 0.6981 - auc: 0.9900 - val_loss: 0.4380 - val_auc: 0.9960\n",
      "Epoch 89/200\n",
      " - 16s - loss: 0.7496 - auc: 0.9895 - val_loss: 0.4114 - val_auc: 0.9963\n",
      "Epoch 90/200\n",
      " - 16s - loss: 0.7702 - auc: 0.9866 - val_loss: 0.4350 - val_auc: 0.9963\n",
      "Epoch 91/200\n",
      " - 16s - loss: 0.7315 - auc: 0.9901 - val_loss: 0.4173 - val_auc: 0.9966\n",
      "Epoch 92/200\n",
      " - 16s - loss: 0.7244 - auc: 0.9899 - val_loss: 0.4539 - val_auc: 0.9959\n",
      "Epoch 93/200\n",
      " - 16s - loss: 0.7298 - auc: 0.9882 - val_loss: 0.3977 - val_auc: 0.9970\n",
      "Epoch 94/200\n",
      " - 16s - loss: 0.7148 - auc: 0.9897 - val_loss: 0.4514 - val_auc: 0.9960\n",
      "Epoch 95/200\n",
      " - 16s - loss: 0.7192 - auc: 0.9896 - val_loss: 0.4128 - val_auc: 0.9964\n",
      "Epoch 96/200\n",
      " - 16s - loss: 0.7453 - auc: 0.9883 - val_loss: 0.4045 - val_auc: 0.9966\n",
      "Epoch 97/200\n",
      " - 16s - loss: 0.7241 - auc: 0.9891 - val_loss: 0.4358 - val_auc: 0.9959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/200\n",
      " - 16s - loss: 0.7140 - auc: 0.9892 - val_loss: 0.4338 - val_auc: 0.9962\n",
      "Epoch 99/200\n",
      " - 16s - loss: 0.6874 - auc: 0.9892 - val_loss: 0.3867 - val_auc: 0.9968\n",
      "Epoch 100/200\n",
      " - 16s - loss: 0.7177 - auc: 0.9886 - val_loss: 0.3950 - val_auc: 0.9968\n",
      "Epoch 101/200\n",
      " - 16s - loss: 0.7357 - auc: 0.9887 - val_loss: 0.3853 - val_auc: 0.9969\n",
      "Epoch 102/200\n",
      " - 16s - loss: 0.7318 - auc: 0.9899 - val_loss: 0.4120 - val_auc: 0.9963\n",
      "Epoch 103/200\n",
      " - 16s - loss: 0.7115 - auc: 0.9887 - val_loss: 0.4306 - val_auc: 0.9962\n",
      "Epoch 104/200\n",
      " - 16s - loss: 0.6881 - auc: 0.9901 - val_loss: 0.4081 - val_auc: 0.9965\n",
      "Epoch 105/200\n",
      " - 16s - loss: 0.7019 - auc: 0.9895 - val_loss: 0.3952 - val_auc: 0.9964\n",
      "Epoch 106/200\n",
      " - 16s - loss: 0.6675 - auc: 0.9897 - val_loss: 0.4236 - val_auc: 0.9962\n",
      "Epoch 107/200\n",
      " - 16s - loss: 0.6886 - auc: 0.9909 - val_loss: 0.3944 - val_auc: 0.9967\n",
      "Epoch 108/200\n",
      " - 16s - loss: 0.6948 - auc: 0.9886 - val_loss: 0.4373 - val_auc: 0.9960\n",
      "Epoch 109/200\n",
      " - 16s - loss: 0.7023 - auc: 0.9899 - val_loss: 0.4223 - val_auc: 0.9963\n",
      "Epoch 110/200\n",
      " - 16s - loss: 0.6712 - auc: 0.9907 - val_loss: 0.3942 - val_auc: 0.9968\n",
      "Epoch 111/200\n",
      " - 16s - loss: 0.7016 - auc: 0.9898 - val_loss: 0.4173 - val_auc: 0.9963\n",
      "Epoch 112/200\n",
      " - 16s - loss: 0.6888 - auc: 0.9885 - val_loss: 0.3976 - val_auc: 0.9966\n",
      "Epoch 113/200\n",
      " - 16s - loss: 0.6941 - auc: 0.9905 - val_loss: 0.3760 - val_auc: 0.9969\n",
      "Epoch 114/200\n",
      " - 16s - loss: 0.6847 - auc: 0.9899 - val_loss: 0.4055 - val_auc: 0.9963\n",
      "Epoch 115/200\n",
      " - 16s - loss: 0.7086 - auc: 0.9902 - val_loss: 0.4048 - val_auc: 0.9966\n",
      "Epoch 116/200\n",
      " - 16s - loss: 0.7034 - auc: 0.9907 - val_loss: 0.4366 - val_auc: 0.9961\n",
      "Epoch 117/200\n",
      " - 16s - loss: 0.6985 - auc: 0.9892 - val_loss: 0.4008 - val_auc: 0.9966\n",
      "Epoch 118/200\n",
      " - 16s - loss: 0.6734 - auc: 0.9901 - val_loss: 0.4065 - val_auc: 0.9966\n",
      "Epoch 119/200\n",
      " - 16s - loss: 0.6791 - auc: 0.9908 - val_loss: 0.3957 - val_auc: 0.9966\n",
      "Epoch 120/200\n",
      " - 16s - loss: 0.6884 - auc: 0.9909 - val_loss: 0.3905 - val_auc: 0.9966\n",
      "Epoch 121/200\n",
      " - 16s - loss: 0.7146 - auc: 0.9894 - val_loss: 0.4037 - val_auc: 0.9964\n",
      "Epoch 122/200\n",
      " - 16s - loss: 0.6745 - auc: 0.9902 - val_loss: 0.3910 - val_auc: 0.9967\n",
      "Epoch 123/200\n",
      " - 16s - loss: 0.6731 - auc: 0.9915 - val_loss: 0.4229 - val_auc: 0.9964\n",
      "Epoch 124/200\n",
      " - 16s - loss: 0.6571 - auc: 0.9912 - val_loss: 0.4192 - val_auc: 0.9965\n",
      "Epoch 125/200\n",
      " - 16s - loss: 0.6874 - auc: 0.9906 - val_loss: 0.4254 - val_auc: 0.9964\n",
      "Epoch 126/200\n",
      " - 16s - loss: 0.6572 - auc: 0.9909 - val_loss: 0.3962 - val_auc: 0.9967\n",
      "Epoch 127/200\n",
      " - 16s - loss: 0.6356 - auc: 0.9915 - val_loss: 0.4351 - val_auc: 0.9961\n",
      "Epoch 128/200\n",
      " - 16s - loss: 0.6580 - auc: 0.9906 - val_loss: 0.3922 - val_auc: 0.9967\n",
      "Epoch 129/200\n",
      " - 16s - loss: 0.6713 - auc: 0.9893 - val_loss: 0.3949 - val_auc: 0.9969\n",
      "Epoch 130/200\n",
      " - 16s - loss: 0.6630 - auc: 0.9905 - val_loss: 0.4193 - val_auc: 0.9964\n",
      "Epoch 131/200\n",
      " - 16s - loss: 0.6669 - auc: 0.9903 - val_loss: 0.3890 - val_auc: 0.9969\n",
      "Epoch 132/200\n",
      " - 16s - loss: 0.6870 - auc: 0.9897 - val_loss: 0.4095 - val_auc: 0.9966\n",
      "Epoch 133/200\n",
      " - 16s - loss: 0.6735 - auc: 0.9906 - val_loss: 0.3910 - val_auc: 0.9969\n",
      "Epoch 134/200\n",
      " - 16s - loss: 0.6620 - auc: 0.9912 - val_loss: 0.4105 - val_auc: 0.9963\n",
      "Epoch 135/200\n",
      " - 16s - loss: 0.6737 - auc: 0.9895 - val_loss: 0.3889 - val_auc: 0.9969\n",
      "Epoch 136/200\n",
      " - 16s - loss: 0.6306 - auc: 0.9918 - val_loss: 0.3862 - val_auc: 0.9968\n",
      "Epoch 137/200\n",
      " - 16s - loss: 0.6894 - auc: 0.9905 - val_loss: 0.3847 - val_auc: 0.9968\n",
      "Epoch 138/200\n",
      " - 16s - loss: 0.6872 - auc: 0.9908 - val_loss: 0.3937 - val_auc: 0.9967\n",
      "Epoch 139/200\n",
      " - 16s - loss: 0.6803 - auc: 0.9910 - val_loss: 0.3927 - val_auc: 0.9965\n",
      "Epoch 140/200\n",
      " - 16s - loss: 0.7076 - auc: 0.9886 - val_loss: 0.3723 - val_auc: 0.9970\n",
      "Epoch 141/200\n",
      " - 16s - loss: 0.6713 - auc: 0.9894 - val_loss: 0.3881 - val_auc: 0.9968\n",
      "Epoch 142/200\n",
      " - 16s - loss: 0.6565 - auc: 0.9897 - val_loss: 0.3956 - val_auc: 0.9965\n",
      "Epoch 143/200\n",
      " - 16s - loss: 0.6874 - auc: 0.9891 - val_loss: 0.3980 - val_auc: 0.9968\n",
      "Epoch 144/200\n",
      " - 16s - loss: 0.6376 - auc: 0.9918 - val_loss: 0.3831 - val_auc: 0.9970\n",
      "Epoch 145/200\n",
      " - 16s - loss: 0.6730 - auc: 0.9908 - val_loss: 0.3731 - val_auc: 0.9971\n",
      "Epoch 146/200\n",
      " - 16s - loss: 0.6511 - auc: 0.9909 - val_loss: 0.4160 - val_auc: 0.9962\n",
      "Epoch 147/200\n",
      " - 16s - loss: 0.6991 - auc: 0.9898 - val_loss: 0.3981 - val_auc: 0.9967\n",
      "Epoch 148/200\n",
      " - 16s - loss: 0.6381 - auc: 0.9914 - val_loss: 0.4038 - val_auc: 0.9964\n",
      "Epoch 149/200\n",
      " - 16s - loss: 0.6701 - auc: 0.9906 - val_loss: 0.3728 - val_auc: 0.9969\n",
      "Epoch 150/200\n",
      " - 16s - loss: 0.6367 - auc: 0.9913 - val_loss: 0.3899 - val_auc: 0.9966\n",
      "Epoch 151/200\n",
      " - 16s - loss: 0.6446 - auc: 0.9909 - val_loss: 0.3910 - val_auc: 0.9966\n",
      "Epoch 152/200\n",
      " - 16s - loss: 0.6521 - auc: 0.9909 - val_loss: 0.3986 - val_auc: 0.9965\n",
      "Epoch 153/200\n",
      " - 16s - loss: 0.6951 - auc: 0.9897 - val_loss: 0.3801 - val_auc: 0.9968\n",
      "Epoch 154/200\n",
      " - 16s - loss: 0.6339 - auc: 0.9920 - val_loss: 0.3905 - val_auc: 0.9967\n",
      "Epoch 155/200\n",
      " - 16s - loss: 0.6665 - auc: 0.9909 - val_loss: 0.3783 - val_auc: 0.9968\n",
      "Epoch 156/200\n",
      " - 16s - loss: 0.6447 - auc: 0.9909 - val_loss: 0.3722 - val_auc: 0.9970\n",
      "Epoch 157/200\n",
      " - 16s - loss: 0.6555 - auc: 0.9911 - val_loss: 0.3869 - val_auc: 0.9968\n",
      "Epoch 158/200\n",
      " - 16s - loss: 0.6713 - auc: 0.9896 - val_loss: 0.4193 - val_auc: 0.9963\n",
      "Epoch 159/200\n",
      " - 16s - loss: 0.6378 - auc: 0.9922 - val_loss: 0.3789 - val_auc: 0.9968\n",
      "Epoch 160/200\n",
      " - 16s - loss: 0.6694 - auc: 0.9898 - val_loss: 0.3834 - val_auc: 0.9967\n",
      "Epoch 161/200\n",
      " - 16s - loss: 0.6433 - auc: 0.9904 - val_loss: 0.3800 - val_auc: 0.9968\n",
      "Epoch 162/200\n",
      " - 16s - loss: 0.6535 - auc: 0.9907 - val_loss: 0.4211 - val_auc: 0.9964\n",
      "Epoch 163/200\n",
      " - 16s - loss: 0.6599 - auc: 0.9899 - val_loss: 0.4015 - val_auc: 0.9965\n",
      "Epoch 164/200\n",
      " - 16s - loss: 0.6535 - auc: 0.9902 - val_loss: 0.3719 - val_auc: 0.9970\n",
      "Epoch 165/200\n",
      " - 16s - loss: 0.6774 - auc: 0.9895 - val_loss: 0.3948 - val_auc: 0.9969\n",
      "Epoch 166/200\n",
      " - 16s - loss: 0.6155 - auc: 0.9927 - val_loss: 0.3884 - val_auc: 0.9966\n",
      "Epoch 167/200\n",
      " - 16s - loss: 0.6540 - auc: 0.9894 - val_loss: 0.3781 - val_auc: 0.9969\n",
      "Epoch 168/200\n",
      " - 16s - loss: 0.6553 - auc: 0.9899 - val_loss: 0.3636 - val_auc: 0.9971\n",
      "Epoch 169/200\n",
      " - 16s - loss: 0.5969 - auc: 0.9926 - val_loss: 0.3648 - val_auc: 0.9970\n",
      "Epoch 170/200\n",
      " - 16s - loss: 0.6484 - auc: 0.9922 - val_loss: 0.3754 - val_auc: 0.9970\n",
      "Epoch 171/200\n",
      " - 16s - loss: 0.6677 - auc: 0.9898 - val_loss: 0.3704 - val_auc: 0.9970\n",
      "Epoch 172/200\n",
      " - 16s - loss: 0.6427 - auc: 0.9907 - val_loss: 0.3710 - val_auc: 0.9970\n",
      "Epoch 173/200\n",
      " - 16s - loss: 0.6608 - auc: 0.9907 - val_loss: 0.3866 - val_auc: 0.9968\n",
      "Epoch 174/200\n",
      " - 16s - loss: 0.6587 - auc: 0.9909 - val_loss: 0.4234 - val_auc: 0.9964\n",
      "Epoch 175/200\n",
      " - 16s - loss: 0.6520 - auc: 0.9918 - val_loss: 0.3906 - val_auc: 0.9967\n",
      "Epoch 176/200\n",
      " - 16s - loss: 0.6516 - auc: 0.9902 - val_loss: 0.3834 - val_auc: 0.9967\n",
      "Epoch 177/200\n",
      " - 16s - loss: 0.6525 - auc: 0.9905 - val_loss: 0.3752 - val_auc: 0.9970\n",
      "Epoch 178/200\n",
      " - 16s - loss: 0.6393 - auc: 0.9914 - val_loss: 0.3667 - val_auc: 0.9970\n",
      "Epoch 179/200\n",
      " - 16s - loss: 0.6744 - auc: 0.9904 - val_loss: 0.3713 - val_auc: 0.9969\n",
      "Epoch 180/200\n",
      " - 16s - loss: 0.6663 - auc: 0.9894 - val_loss: 0.3712 - val_auc: 0.9969\n",
      "Epoch 181/200\n",
      " - 16s - loss: 0.6526 - auc: 0.9905 - val_loss: 0.3819 - val_auc: 0.9967\n",
      "Epoch 182/200\n",
      " - 16s - loss: 0.6505 - auc: 0.9910 - val_loss: 0.3767 - val_auc: 0.9969\n",
      "Epoch 183/200\n",
      " - 16s - loss: 0.6559 - auc: 0.9914 - val_loss: 0.3608 - val_auc: 0.9972\n",
      "Epoch 184/200\n",
      " - 16s - loss: 0.6198 - auc: 0.9927 - val_loss: 0.3618 - val_auc: 0.9971\n",
      "Epoch 185/200\n",
      " - 16s - loss: 0.6280 - auc: 0.9920 - val_loss: 0.3934 - val_auc: 0.9968\n",
      "Epoch 186/200\n",
      " - 16s - loss: 0.6534 - auc: 0.9902 - val_loss: 0.3668 - val_auc: 0.9972\n",
      "Epoch 187/200\n",
      " - 16s - loss: 0.6537 - auc: 0.9903 - val_loss: 0.3828 - val_auc: 0.9970\n",
      "Epoch 188/200\n",
      " - 16s - loss: 0.6757 - auc: 0.9887 - val_loss: 0.3949 - val_auc: 0.9968\n",
      "Epoch 189/200\n",
      " - 16s - loss: 0.6308 - auc: 0.9926 - val_loss: 0.3746 - val_auc: 0.9970\n",
      "Epoch 190/200\n",
      " - 16s - loss: 0.6979 - auc: 0.9904 - val_loss: 0.3804 - val_auc: 0.9970\n",
      "Epoch 191/200\n",
      " - 16s - loss: 0.6565 - auc: 0.9919 - val_loss: 0.3886 - val_auc: 0.9968\n",
      "Epoch 192/200\n",
      " - 16s - loss: 0.6346 - auc: 0.9921 - val_loss: 0.3812 - val_auc: 0.9970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/200\n",
      " - 16s - loss: 0.6678 - auc: 0.9898 - val_loss: 0.3882 - val_auc: 0.9969\n",
      "Epoch 194/200\n",
      " - 16s - loss: 0.6646 - auc: 0.9905 - val_loss: 0.3785 - val_auc: 0.9970\n",
      "Epoch 195/200\n",
      " - 16s - loss: 0.6317 - auc: 0.9910 - val_loss: 0.3725 - val_auc: 0.9968\n",
      "Epoch 196/200\n",
      " - 16s - loss: 0.6615 - auc: 0.9919 - val_loss: 0.3667 - val_auc: 0.9968\n",
      "Epoch 197/200\n",
      " - 16s - loss: 0.6379 - auc: 0.9925 - val_loss: 0.3659 - val_auc: 0.9971\n",
      "Epoch 198/200\n",
      " - 16s - loss: 0.6315 - auc: 0.9920 - val_loss: 0.3981 - val_auc: 0.9964\n",
      "Epoch 199/200\n",
      " - 16s - loss: 0.6301 - auc: 0.9915 - val_loss: 0.3384 - val_auc: 0.9974\n",
      "Epoch 200/200\n",
      " - 16s - loss: 0.6498 - auc: 0.9917 - val_loss: 0.3603 - val_auc: 0.9971\n",
      "Original,MIT-BIH Arrhythmia Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keg/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:80: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5957 samples, validate on 715 samples\n",
      "Epoch 1/200\n",
      " - 64s - loss: 1.9501 - auc: 0.9194 - val_loss: 0.9165 - val_auc: 0.9838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keg/anaconda3/lib/python3.6/site-packages/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `roc_accuracy` which is not available. Available metrics are: val_loss,val_auc,loss,auc,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200\n",
      " - 30s - loss: 1.3217 - auc: 0.9696 - val_loss: 0.7137 - val_auc: 0.9896\n",
      "Epoch 3/200\n",
      " - 30s - loss: 1.2321 - auc: 0.9708 - val_loss: 0.6868 - val_auc: 0.9890\n",
      "Epoch 4/200\n",
      " - 30s - loss: 1.1534 - auc: 0.9755 - val_loss: 0.6150 - val_auc: 0.9912\n",
      "Epoch 5/200\n",
      " - 30s - loss: 1.1086 - auc: 0.9762 - val_loss: 0.6185 - val_auc: 0.9902\n",
      "Epoch 6/200\n",
      " - 30s - loss: 1.0721 - auc: 0.9776 - val_loss: 0.6072 - val_auc: 0.9912\n",
      "Epoch 7/200\n",
      " - 30s - loss: 1.0510 - auc: 0.9804 - val_loss: 0.5989 - val_auc: 0.9892\n",
      "Epoch 8/200\n",
      " - 30s - loss: 1.0156 - auc: 0.9812 - val_loss: 0.5457 - val_auc: 0.9923\n",
      "Epoch 9/200\n",
      " - 30s - loss: 0.9860 - auc: 0.9808 - val_loss: 0.5631 - val_auc: 0.9898\n",
      "Epoch 10/200\n",
      " - 30s - loss: 0.9638 - auc: 0.9826 - val_loss: 0.5208 - val_auc: 0.9939\n",
      "Epoch 11/200\n",
      " - 30s - loss: 0.9569 - auc: 0.9833 - val_loss: 0.5235 - val_auc: 0.9927\n",
      "Epoch 12/200\n",
      " - 30s - loss: 0.9435 - auc: 0.9833 - val_loss: 0.5404 - val_auc: 0.9913\n",
      "Epoch 13/200\n",
      " - 30s - loss: 0.9580 - auc: 0.9811 - val_loss: 0.5102 - val_auc: 0.9927\n",
      "Epoch 14/200\n",
      " - 30s - loss: 0.9299 - auc: 0.9831 - val_loss: 0.5131 - val_auc: 0.9916\n",
      "Epoch 15/200\n",
      " - 30s - loss: 0.9286 - auc: 0.9833 - val_loss: 0.4772 - val_auc: 0.9935\n",
      "Epoch 16/200\n",
      " - 29s - loss: 0.9396 - auc: 0.9828 - val_loss: 0.5118 - val_auc: 0.9938\n",
      "Epoch 17/200\n",
      " - 29s - loss: 0.9066 - auc: 0.9841 - val_loss: 0.4895 - val_auc: 0.9932\n",
      "Epoch 18/200\n",
      " - 29s - loss: 0.9158 - auc: 0.9837 - val_loss: 0.4981 - val_auc: 0.9930\n",
      "Epoch 19/200\n",
      " - 30s - loss: 0.8826 - auc: 0.9856 - val_loss: 0.4814 - val_auc: 0.9933\n",
      "Epoch 20/200\n",
      " - 29s - loss: 0.8672 - auc: 0.9854 - val_loss: 0.5231 - val_auc: 0.9924\n",
      "Epoch 21/200\n",
      " - 30s - loss: 0.8700 - auc: 0.9847 - val_loss: 0.4895 - val_auc: 0.9921\n",
      "Epoch 22/200\n",
      " - 30s - loss: 0.8357 - auc: 0.9859 - val_loss: 0.4802 - val_auc: 0.9933\n",
      "Epoch 23/200\n",
      " - 30s - loss: 0.8036 - auc: 0.9877 - val_loss: 0.4419 - val_auc: 0.9939\n",
      "Epoch 24/200\n",
      " - 30s - loss: 0.8518 - auc: 0.9865 - val_loss: 0.4811 - val_auc: 0.9933\n",
      "Epoch 25/200\n",
      " - 30s - loss: 0.8469 - auc: 0.9853 - val_loss: 0.4617 - val_auc: 0.9934\n",
      "Epoch 26/200\n",
      " - 30s - loss: 0.8127 - auc: 0.9866 - val_loss: 0.4292 - val_auc: 0.9943\n",
      "Epoch 27/200\n",
      " - 30s - loss: 0.8361 - auc: 0.9861 - val_loss: 0.4360 - val_auc: 0.9938\n",
      "Epoch 28/200\n",
      " - 30s - loss: 0.8179 - auc: 0.9869 - val_loss: 0.4340 - val_auc: 0.9939\n",
      "Epoch 29/200\n",
      " - 30s - loss: 0.8316 - auc: 0.9853 - val_loss: 0.4501 - val_auc: 0.9938\n",
      "Epoch 30/200\n",
      " - 30s - loss: 0.8375 - auc: 0.9866 - val_loss: 0.4374 - val_auc: 0.9941\n",
      "Epoch 31/200\n",
      " - 30s - loss: 0.8211 - auc: 0.9862 - val_loss: 0.4453 - val_auc: 0.9936\n",
      "Epoch 32/200\n",
      " - 30s - loss: 0.8176 - auc: 0.9863 - val_loss: 0.4495 - val_auc: 0.9935\n",
      "Epoch 33/200\n",
      " - 30s - loss: 0.7914 - auc: 0.9869 - val_loss: 0.3962 - val_auc: 0.9942\n",
      "Epoch 34/200\n",
      " - 30s - loss: 0.7963 - auc: 0.9880 - val_loss: 0.4321 - val_auc: 0.9928\n",
      "Epoch 35/200\n",
      " - 30s - loss: 0.8014 - auc: 0.9874 - val_loss: 0.4410 - val_auc: 0.9937\n",
      "Epoch 36/200\n",
      " - 30s - loss: 0.7678 - auc: 0.9890 - val_loss: 0.4162 - val_auc: 0.9941\n",
      "Epoch 37/200\n",
      " - 30s - loss: 0.7774 - auc: 0.9876 - val_loss: 0.4239 - val_auc: 0.9939\n",
      "Epoch 38/200\n",
      " - 30s - loss: 0.7752 - auc: 0.9879 - val_loss: 0.4286 - val_auc: 0.9938\n",
      "Epoch 39/200\n",
      " - 30s - loss: 0.7741 - auc: 0.9882 - val_loss: 0.4304 - val_auc: 0.9940\n",
      "Epoch 40/200\n",
      " - 30s - loss: 0.8024 - auc: 0.9872 - val_loss: 0.4384 - val_auc: 0.9936\n",
      "Epoch 41/200\n",
      " - 30s - loss: 0.7808 - auc: 0.9877 - val_loss: 0.4757 - val_auc: 0.9935\n",
      "Epoch 42/200\n",
      " - 30s - loss: 0.7816 - auc: 0.9883 - val_loss: 0.4236 - val_auc: 0.9939\n",
      "Epoch 43/200\n",
      " - 30s - loss: 0.7583 - auc: 0.9884 - val_loss: 0.4088 - val_auc: 0.9944\n",
      "Epoch 44/200\n",
      " - 30s - loss: 0.7736 - auc: 0.9885 - val_loss: 0.3963 - val_auc: 0.9941\n",
      "Epoch 45/200\n",
      " - 30s - loss: 0.7519 - auc: 0.9879 - val_loss: 0.4115 - val_auc: 0.9943\n",
      "Epoch 46/200\n",
      " - 30s - loss: 0.7571 - auc: 0.9891 - val_loss: 0.4015 - val_auc: 0.9941\n",
      "Epoch 47/200\n",
      " - 30s - loss: 0.7666 - auc: 0.9885 - val_loss: 0.4485 - val_auc: 0.9938\n",
      "Epoch 48/200\n",
      " - 30s - loss: 0.7622 - auc: 0.9881 - val_loss: 0.3992 - val_auc: 0.9943\n",
      "Epoch 49/200\n",
      " - 30s - loss: 0.7521 - auc: 0.9889 - val_loss: 0.4445 - val_auc: 0.9938\n",
      "Epoch 50/200\n",
      " - 30s - loss: 0.7544 - auc: 0.9877 - val_loss: 0.4137 - val_auc: 0.9941\n",
      "Epoch 51/200\n",
      " - 30s - loss: 0.7479 - auc: 0.9894 - val_loss: 0.4116 - val_auc: 0.9941\n",
      "Epoch 52/200\n",
      " - 30s - loss: 0.7713 - auc: 0.9871 - val_loss: 0.4306 - val_auc: 0.9938\n",
      "Epoch 53/200\n",
      " - 30s - loss: 0.7339 - auc: 0.9885 - val_loss: 0.4140 - val_auc: 0.9940\n",
      "Epoch 54/200\n",
      " - 30s - loss: 0.7555 - auc: 0.9890 - val_loss: 0.4416 - val_auc: 0.9936\n",
      "Epoch 55/200\n",
      " - 30s - loss: 0.7340 - auc: 0.9892 - val_loss: 0.3976 - val_auc: 0.9943\n",
      "Epoch 56/200\n",
      " - 30s - loss: 0.7328 - auc: 0.9895 - val_loss: 0.4158 - val_auc: 0.9942\n",
      "Epoch 57/200\n",
      " - 30s - loss: 0.7330 - auc: 0.9893 - val_loss: 0.4120 - val_auc: 0.9942\n",
      "Epoch 58/200\n",
      " - 30s - loss: 0.7125 - auc: 0.9895 - val_loss: 0.4396 - val_auc: 0.9936\n",
      "Epoch 59/200\n",
      " - 30s - loss: 0.7625 - auc: 0.9880 - val_loss: 0.4264 - val_auc: 0.9938\n",
      "Epoch 60/200\n",
      " - 30s - loss: 0.7244 - auc: 0.9894 - val_loss: 0.4031 - val_auc: 0.9943\n",
      "Epoch 61/200\n",
      " - 30s - loss: 0.7632 - auc: 0.9869 - val_loss: 0.4037 - val_auc: 0.9942\n",
      "Epoch 62/200\n",
      " - 30s - loss: 0.7443 - auc: 0.9884 - val_loss: 0.4226 - val_auc: 0.9940\n",
      "Epoch 63/200\n",
      " - 30s - loss: 0.6996 - auc: 0.9911 - val_loss: 0.4295 - val_auc: 0.9940\n",
      "Epoch 64/200\n",
      " - 30s - loss: 0.7532 - auc: 0.9888 - val_loss: 0.3732 - val_auc: 0.9946\n",
      "Epoch 65/200\n",
      " - 30s - loss: 0.7231 - auc: 0.9898 - val_loss: 0.4084 - val_auc: 0.9942\n",
      "Epoch 66/200\n",
      " - 30s - loss: 0.7322 - auc: 0.9889 - val_loss: 0.3572 - val_auc: 0.9947\n",
      "Epoch 67/200\n",
      " - 30s - loss: 0.7182 - auc: 0.9899 - val_loss: 0.4015 - val_auc: 0.9943\n",
      "Epoch 68/200\n",
      " - 30s - loss: 0.7422 - auc: 0.9878 - val_loss: 0.4039 - val_auc: 0.9943\n",
      "Epoch 69/200\n",
      " - 30s - loss: 0.7044 - auc: 0.9889 - val_loss: 0.4008 - val_auc: 0.9943\n",
      "Epoch 70/200\n",
      " - 30s - loss: 0.6990 - auc: 0.9902 - val_loss: 0.3907 - val_auc: 0.9945\n",
      "Epoch 71/200\n",
      " - 30s - loss: 0.7256 - auc: 0.9885 - val_loss: 0.4062 - val_auc: 0.9940\n",
      "Epoch 72/200\n",
      " - 30s - loss: 0.6981 - auc: 0.9896 - val_loss: 0.3845 - val_auc: 0.9956\n",
      "Epoch 73/200\n",
      " - 30s - loss: 0.7284 - auc: 0.9899 - val_loss: 0.3940 - val_auc: 0.9955\n",
      "Epoch 74/200\n",
      " - 30s - loss: 0.7165 - auc: 0.9884 - val_loss: 0.3907 - val_auc: 0.9944\n",
      "Epoch 75/200\n",
      " - 30s - loss: 0.6976 - auc: 0.9901 - val_loss: 0.3874 - val_auc: 0.9944\n",
      "Epoch 76/200\n",
      " - 30s - loss: 0.7298 - auc: 0.9890 - val_loss: 0.4103 - val_auc: 0.9941\n",
      "Epoch 77/200\n",
      " - 30s - loss: 0.6757 - auc: 0.9903 - val_loss: 0.3956 - val_auc: 0.9955\n",
      "Epoch 78/200\n",
      " - 30s - loss: 0.6896 - auc: 0.9898 - val_loss: 0.3826 - val_auc: 0.9943\n",
      "Epoch 79/200\n",
      " - 30s - loss: 0.6889 - auc: 0.9901 - val_loss: 0.4006 - val_auc: 0.9943\n",
      "Epoch 80/200\n",
      " - 30s - loss: 0.6829 - auc: 0.9900 - val_loss: 0.3535 - val_auc: 0.9957\n",
      "Epoch 81/200\n",
      " - 30s - loss: 0.6909 - auc: 0.9902 - val_loss: 0.3915 - val_auc: 0.9955\n",
      "Epoch 82/200\n",
      " - 30s - loss: 0.6810 - auc: 0.9897 - val_loss: 0.3718 - val_auc: 0.9944\n",
      "Epoch 83/200\n",
      " - 30s - loss: 0.6992 - auc: 0.9890 - val_loss: 0.4232 - val_auc: 0.9940\n",
      "Epoch 84/200\n",
      " - 30s - loss: 0.6826 - auc: 0.9893 - val_loss: 0.4269 - val_auc: 0.9938\n",
      "Epoch 85/200\n",
      " - 30s - loss: 0.7084 - auc: 0.9905 - val_loss: 0.3744 - val_auc: 0.9958\n",
      "Epoch 86/200\n",
      " - 30s - loss: 0.6994 - auc: 0.9895 - val_loss: 0.4191 - val_auc: 0.9940\n",
      "Epoch 87/200\n",
      " - 30s - loss: 0.6964 - auc: 0.9906 - val_loss: 0.3997 - val_auc: 0.9942\n",
      "Epoch 88/200\n",
      " - 30s - loss: 0.6908 - auc: 0.9899 - val_loss: 0.3662 - val_auc: 0.9957\n",
      "Epoch 89/200\n",
      " - 30s - loss: 0.7038 - auc: 0.9897 - val_loss: 0.3733 - val_auc: 0.9946\n",
      "Epoch 90/200\n",
      " - 30s - loss: 0.6851 - auc: 0.9904 - val_loss: 0.3649 - val_auc: 0.9957\n",
      "Epoch 91/200\n",
      " - 30s - loss: 0.7004 - auc: 0.9891 - val_loss: 0.4001 - val_auc: 0.9942\n",
      "Epoch 92/200\n",
      " - 30s - loss: 0.7060 - auc: 0.9889 - val_loss: 0.3681 - val_auc: 0.9946\n",
      "Epoch 93/200\n",
      " - 30s - loss: 0.6939 - auc: 0.9900 - val_loss: 0.3664 - val_auc: 0.9946\n",
      "Epoch 94/200\n",
      " - 30s - loss: 0.7110 - auc: 0.9888 - val_loss: 0.3701 - val_auc: 0.9946\n",
      "Epoch 95/200\n",
      " - 30s - loss: 0.6600 - auc: 0.9911 - val_loss: 0.3842 - val_auc: 0.9943\n",
      "Epoch 96/200\n",
      " - 30s - loss: 0.6567 - auc: 0.9910 - val_loss: 0.3725 - val_auc: 0.9954\n",
      "Epoch 97/200\n",
      " - 30s - loss: 0.6922 - auc: 0.9893 - val_loss: 0.3888 - val_auc: 0.9955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/200\n",
      " - 30s - loss: 0.6858 - auc: 0.9902 - val_loss: 0.3917 - val_auc: 0.9944\n",
      "Epoch 99/200\n",
      " - 30s - loss: 0.6867 - auc: 0.9899 - val_loss: 0.4051 - val_auc: 0.9941\n",
      "Epoch 100/200\n",
      " - 30s - loss: 0.6546 - auc: 0.9906 - val_loss: 0.3605 - val_auc: 0.9946\n",
      "Epoch 101/200\n",
      " - 30s - loss: 0.7051 - auc: 0.9887 - val_loss: 0.3866 - val_auc: 0.9943\n",
      "Epoch 102/200\n",
      " - 30s - loss: 0.6706 - auc: 0.9901 - val_loss: 0.3828 - val_auc: 0.9943\n",
      "Epoch 103/200\n",
      " - 30s - loss: 0.6746 - auc: 0.9905 - val_loss: 0.3582 - val_auc: 0.9946\n",
      "Epoch 104/200\n",
      " - 30s - loss: 0.6863 - auc: 0.9898 - val_loss: 0.3734 - val_auc: 0.9945\n",
      "Epoch 105/200\n",
      " - 30s - loss: 0.6978 - auc: 0.9900 - val_loss: 0.3858 - val_auc: 0.9956\n",
      "Epoch 106/200\n",
      " - 30s - loss: 0.6572 - auc: 0.9917 - val_loss: 0.3798 - val_auc: 0.9944\n",
      "Epoch 107/200\n",
      " - 30s - loss: 0.6869 - auc: 0.9895 - val_loss: 0.3745 - val_auc: 0.9958\n",
      "Epoch 108/200\n",
      " - 30s - loss: 0.6704 - auc: 0.9899 - val_loss: 0.3911 - val_auc: 0.9945\n",
      "Epoch 109/200\n",
      " - 30s - loss: 0.6540 - auc: 0.9908 - val_loss: 0.3544 - val_auc: 0.9959\n",
      "Epoch 110/200\n",
      " - 30s - loss: 0.6831 - auc: 0.9895 - val_loss: 0.3521 - val_auc: 0.9948\n",
      "Epoch 111/200\n",
      " - 30s - loss: 0.6696 - auc: 0.9907 - val_loss: 0.4235 - val_auc: 0.9940\n",
      "Epoch 112/200\n",
      " - 30s - loss: 0.6898 - auc: 0.9895 - val_loss: 0.3790 - val_auc: 0.9944\n",
      "Epoch 113/200\n",
      " - 30s - loss: 0.6793 - auc: 0.9901 - val_loss: 0.3742 - val_auc: 0.9947\n",
      "Epoch 114/200\n",
      " - 30s - loss: 0.6400 - auc: 0.9917 - val_loss: 0.3677 - val_auc: 0.9969\n",
      "Epoch 115/200\n",
      " - 30s - loss: 0.6684 - auc: 0.9899 - val_loss: 0.3661 - val_auc: 0.9956\n",
      "Epoch 116/200\n",
      " - 30s - loss: 0.6730 - auc: 0.9904 - val_loss: 0.3857 - val_auc: 0.9957\n",
      "Epoch 117/200\n",
      " - 30s - loss: 0.7102 - auc: 0.9892 - val_loss: 0.3673 - val_auc: 0.9946\n",
      "Epoch 118/200\n",
      " - 30s - loss: 0.6545 - auc: 0.9904 - val_loss: 0.4287 - val_auc: 0.9938\n",
      "Epoch 119/200\n",
      " - 30s - loss: 0.6600 - auc: 0.9906 - val_loss: 0.3837 - val_auc: 0.9944\n",
      "Epoch 120/200\n",
      " - 30s - loss: 0.6431 - auc: 0.9905 - val_loss: 0.3946 - val_auc: 0.9942\n",
      "Epoch 121/200\n",
      " - 30s - loss: 0.6931 - auc: 0.9880 - val_loss: 0.3984 - val_auc: 0.9941\n",
      "Epoch 122/200\n",
      " - 30s - loss: 0.6913 - auc: 0.9900 - val_loss: 0.4084 - val_auc: 0.9953\n",
      "Epoch 123/200\n",
      " - 30s - loss: 0.6702 - auc: 0.9899 - val_loss: 0.3799 - val_auc: 0.9954\n",
      "Epoch 124/200\n",
      " - 30s - loss: 0.6541 - auc: 0.9908 - val_loss: 0.3897 - val_auc: 0.9955\n",
      "Epoch 125/200\n",
      " - 30s - loss: 0.6304 - auc: 0.9914 - val_loss: 0.3677 - val_auc: 0.9946\n",
      "Epoch 126/200\n",
      " - 30s - loss: 0.6587 - auc: 0.9909 - val_loss: 0.3924 - val_auc: 0.9953\n",
      "Epoch 127/200\n",
      " - 30s - loss: 0.6712 - auc: 0.9900 - val_loss: 0.3673 - val_auc: 0.9969\n",
      "Epoch 128/200\n",
      " - 30s - loss: 0.6482 - auc: 0.9912 - val_loss: 0.3697 - val_auc: 0.9957\n",
      "Epoch 129/200\n",
      " - 30s - loss: 0.6601 - auc: 0.9908 - val_loss: 0.3598 - val_auc: 0.9957\n",
      "Epoch 130/200\n",
      " - 30s - loss: 0.6612 - auc: 0.9906 - val_loss: 0.3492 - val_auc: 0.9947\n",
      "Epoch 131/200\n",
      " - 30s - loss: 0.6621 - auc: 0.9911 - val_loss: 0.3963 - val_auc: 0.9942\n",
      "Epoch 132/200\n",
      " - 30s - loss: 0.6514 - auc: 0.9905 - val_loss: 0.3681 - val_auc: 0.9957\n",
      "Epoch 133/200\n",
      " - 30s - loss: 0.6639 - auc: 0.9901 - val_loss: 0.3521 - val_auc: 0.9959\n",
      "Epoch 134/200\n",
      " - 30s - loss: 0.6705 - auc: 0.9909 - val_loss: 0.3802 - val_auc: 0.9943\n",
      "Epoch 135/200\n",
      " - 30s - loss: 0.6740 - auc: 0.9896 - val_loss: 0.3638 - val_auc: 0.9958\n",
      "Epoch 136/200\n",
      " - 30s - loss: 0.6657 - auc: 0.9902 - val_loss: 0.3469 - val_auc: 0.9948\n",
      "Epoch 137/200\n",
      " - 30s - loss: 0.6484 - auc: 0.9910 - val_loss: 0.3765 - val_auc: 0.9955\n",
      "Epoch 138/200\n",
      " - 30s - loss: 0.6456 - auc: 0.9909 - val_loss: 0.3806 - val_auc: 0.9954\n",
      "Epoch 139/200\n",
      " - 30s - loss: 0.6428 - auc: 0.9910 - val_loss: 0.3660 - val_auc: 0.9957\n",
      "Epoch 140/200\n",
      " - 30s - loss: 0.6493 - auc: 0.9910 - val_loss: 0.4020 - val_auc: 0.9952\n",
      "Epoch 141/200\n",
      " - 30s - loss: 0.6345 - auc: 0.9920 - val_loss: 0.3732 - val_auc: 0.9944\n",
      "Epoch 142/200\n",
      " - 30s - loss: 0.6587 - auc: 0.9906 - val_loss: 0.3967 - val_auc: 0.9944\n",
      "Epoch 143/200\n",
      " - 30s - loss: 0.6528 - auc: 0.9920 - val_loss: 0.3642 - val_auc: 0.9958\n",
      "Epoch 144/200\n",
      " - 30s - loss: 0.6257 - auc: 0.9918 - val_loss: 0.3476 - val_auc: 0.9947\n",
      "Epoch 145/200\n",
      " - 30s - loss: 0.6635 - auc: 0.9908 - val_loss: 0.3487 - val_auc: 0.9960\n",
      "Epoch 146/200\n",
      " - 30s - loss: 0.6559 - auc: 0.9913 - val_loss: 0.3909 - val_auc: 0.9944\n",
      "Epoch 147/200\n",
      " - 30s - loss: 0.6373 - auc: 0.9918 - val_loss: 0.3571 - val_auc: 0.9946\n",
      "Epoch 148/200\n",
      " - 30s - loss: 0.6488 - auc: 0.9906 - val_loss: 0.3780 - val_auc: 0.9942\n",
      "Epoch 149/200\n",
      " - 30s - loss: 0.6552 - auc: 0.9902 - val_loss: 0.3620 - val_auc: 0.9957\n",
      "Epoch 150/200\n",
      " - 30s - loss: 0.6497 - auc: 0.9905 - val_loss: 0.3988 - val_auc: 0.9941\n",
      "Epoch 151/200\n",
      " - 30s - loss: 0.6613 - auc: 0.9902 - val_loss: 0.3621 - val_auc: 0.9970\n",
      "Epoch 152/200\n",
      " - 30s - loss: 0.6358 - auc: 0.9916 - val_loss: 0.3490 - val_auc: 0.9971\n",
      "Epoch 153/200\n",
      " - 30s - loss: 0.6471 - auc: 0.9913 - val_loss: 0.3662 - val_auc: 0.9945\n",
      "Epoch 154/200\n",
      " - 30s - loss: 0.6324 - auc: 0.9912 - val_loss: 0.3738 - val_auc: 0.9969\n",
      "Epoch 155/200\n",
      " - 30s - loss: 0.6671 - auc: 0.9905 - val_loss: 0.3568 - val_auc: 0.9969\n",
      "Epoch 156/200\n",
      " - 30s - loss: 0.6612 - auc: 0.9898 - val_loss: 0.3652 - val_auc: 0.9945\n",
      "Epoch 157/200\n",
      " - 30s - loss: 0.6358 - auc: 0.9912 - val_loss: 0.3784 - val_auc: 0.9942\n",
      "Epoch 158/200\n",
      " - 30s - loss: 0.6162 - auc: 0.9921 - val_loss: 0.3516 - val_auc: 0.9970\n",
      "Epoch 159/200\n",
      " - 30s - loss: 0.6721 - auc: 0.9907 - val_loss: 0.3699 - val_auc: 0.9971\n",
      "Epoch 160/200\n",
      " - 30s - loss: 0.6316 - auc: 0.9906 - val_loss: 0.3766 - val_auc: 0.9955\n",
      "Epoch 161/200\n",
      " - 30s - loss: 0.6249 - auc: 0.9918 - val_loss: 0.3540 - val_auc: 0.9959\n",
      "Epoch 162/200\n",
      " - 30s - loss: 0.6329 - auc: 0.9915 - val_loss: 0.3844 - val_auc: 0.9955\n",
      "Epoch 163/200\n",
      " - 30s - loss: 0.6297 - auc: 0.9910 - val_loss: 0.3780 - val_auc: 0.9968\n",
      "Epoch 164/200\n",
      " - 30s - loss: 0.6307 - auc: 0.9927 - val_loss: 0.3642 - val_auc: 0.9968\n",
      "Epoch 165/200\n",
      " - 30s - loss: 0.6283 - auc: 0.9911 - val_loss: 0.3478 - val_auc: 0.9959\n",
      "Epoch 166/200\n",
      " - 30s - loss: 0.6359 - auc: 0.9914 - val_loss: 0.3628 - val_auc: 0.9945\n",
      "Epoch 167/200\n",
      " - 30s - loss: 0.6151 - auc: 0.9921 - val_loss: 0.3497 - val_auc: 0.9948\n",
      "Epoch 168/200\n",
      " - 30s - loss: 0.6428 - auc: 0.9906 - val_loss: 0.3643 - val_auc: 0.9969\n",
      "Epoch 169/200\n",
      " - 30s - loss: 0.6549 - auc: 0.9913 - val_loss: 0.4116 - val_auc: 0.9966\n",
      "Epoch 170/200\n",
      " - 30s - loss: 0.6395 - auc: 0.9901 - val_loss: 0.3955 - val_auc: 0.9953\n",
      "Epoch 171/200\n",
      " - 30s - loss: 0.6444 - auc: 0.9902 - val_loss: 0.3635 - val_auc: 0.9971\n",
      "Epoch 172/200\n",
      " - 30s - loss: 0.6267 - auc: 0.9922 - val_loss: 0.4080 - val_auc: 0.9940\n",
      "Epoch 173/200\n",
      " - 30s - loss: 0.6293 - auc: 0.9912 - val_loss: 0.3509 - val_auc: 0.9958\n",
      "Epoch 174/200\n",
      " - 29s - loss: 0.6474 - auc: 0.9901 - val_loss: 0.3884 - val_auc: 0.9955\n",
      "Epoch 175/200\n",
      " - 29s - loss: 0.6240 - auc: 0.9923 - val_loss: 0.3804 - val_auc: 0.9955\n",
      "Epoch 176/200\n",
      " - 29s - loss: 0.6384 - auc: 0.9914 - val_loss: 0.3764 - val_auc: 0.9968\n",
      "Epoch 177/200\n",
      " - 29s - loss: 0.6095 - auc: 0.9922 - val_loss: 0.3676 - val_auc: 0.9958\n",
      "Epoch 178/200\n",
      " - 29s - loss: 0.6423 - auc: 0.9908 - val_loss: 0.3641 - val_auc: 0.9969\n",
      "Epoch 179/200\n",
      " - 30s - loss: 0.6304 - auc: 0.9902 - val_loss: 0.3416 - val_auc: 0.9959\n",
      "Epoch 180/200\n",
      " - 30s - loss: 0.6109 - auc: 0.9922 - val_loss: 0.3630 - val_auc: 0.9955\n",
      "Epoch 181/200\n",
      " - 30s - loss: 0.6674 - auc: 0.9907 - val_loss: 0.3653 - val_auc: 0.9970\n",
      "Epoch 182/200\n",
      " - 30s - loss: 0.6302 - auc: 0.9907 - val_loss: 0.3769 - val_auc: 0.9966\n",
      "Epoch 183/200\n",
      " - 30s - loss: 0.6349 - auc: 0.9907 - val_loss: 0.3785 - val_auc: 0.9955\n",
      "Epoch 184/200\n",
      " - 30s - loss: 0.6299 - auc: 0.9911 - val_loss: 0.3555 - val_auc: 0.9958\n",
      "Epoch 185/200\n",
      " - 30s - loss: 0.6003 - auc: 0.9924 - val_loss: 0.3302 - val_auc: 0.9971\n",
      "Epoch 186/200\n",
      " - 30s - loss: 0.6318 - auc: 0.9919 - val_loss: 0.3839 - val_auc: 0.9966\n",
      "Epoch 187/200\n",
      " - 30s - loss: 0.6147 - auc: 0.9922 - val_loss: 0.3140 - val_auc: 0.9963\n",
      "Epoch 188/200\n",
      " - 30s - loss: 0.6215 - auc: 0.9909 - val_loss: 0.3541 - val_auc: 0.9958\n",
      "Epoch 189/200\n",
      " - 30s - loss: 0.6308 - auc: 0.9918 - val_loss: 0.3733 - val_auc: 0.9967\n",
      "Epoch 190/200\n",
      " - 30s - loss: 0.6130 - auc: 0.9923 - val_loss: 0.3397 - val_auc: 0.9972\n",
      "Epoch 191/200\n",
      " - 30s - loss: 0.6081 - auc: 0.9921 - val_loss: 0.3722 - val_auc: 0.9956\n",
      "Epoch 192/200\n",
      " - 30s - loss: 0.6229 - auc: 0.9912 - val_loss: 0.3409 - val_auc: 0.9960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/200\n",
      " - 30s - loss: 0.6064 - auc: 0.9919 - val_loss: 0.3821 - val_auc: 0.9967\n",
      "Epoch 194/200\n",
      " - 30s - loss: 0.6002 - auc: 0.9923 - val_loss: 0.3907 - val_auc: 0.9941\n",
      "Epoch 195/200\n",
      " - 30s - loss: 0.6161 - auc: 0.9915 - val_loss: 0.3538 - val_auc: 0.9957\n",
      "Epoch 196/200\n",
      " - 30s - loss: 0.6282 - auc: 0.9907 - val_loss: 0.3597 - val_auc: 0.9968\n",
      "Epoch 197/200\n",
      " - 30s - loss: 0.6046 - auc: 0.9922 - val_loss: 0.3283 - val_auc: 0.9961\n",
      "Epoch 198/200\n",
      " - 30s - loss: 0.6282 - auc: 0.9909 - val_loss: 0.3625 - val_auc: 0.9971\n",
      "Epoch 199/200\n",
      " - 30s - loss: 0.6038 - auc: 0.9925 - val_loss: 0.3713 - val_auc: 0.9968\n",
      "Epoch 200/200\n",
      " - 30s - loss: 0.6415 - auc: 0.9901 - val_loss: 0.3679 - val_auc: 0.9969\n",
      "SMOTE,MIT-BIH Arrhythmia Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keg/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:80: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6058 samples, validate on 715 samples\n",
      "Epoch 1/200\n",
      " - 65s - loss: 1.9740 - auc: 0.9209 - val_loss: 0.9953 - val_auc: 0.9851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keg/anaconda3/lib/python3.6/site-packages/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `roc_accuracy` which is not available. Available metrics are: val_loss,val_auc,loss,auc,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200\n",
      " - 30s - loss: 1.4527 - auc: 0.9637 - val_loss: 0.7909 - val_auc: 0.9900\n",
      "Epoch 3/200\n",
      " - 30s - loss: 1.3012 - auc: 0.9706 - val_loss: 0.7520 - val_auc: 0.9912\n",
      "Epoch 4/200\n",
      " - 30s - loss: 1.2484 - auc: 0.9723 - val_loss: 0.6661 - val_auc: 0.9920\n",
      "Epoch 5/200\n",
      " - 30s - loss: 1.1884 - auc: 0.9753 - val_loss: 0.6610 - val_auc: 0.9922\n",
      "Epoch 6/200\n",
      " - 30s - loss: 1.1188 - auc: 0.9787 - val_loss: 0.6224 - val_auc: 0.9928\n",
      "Epoch 7/200\n",
      " - 30s - loss: 1.1090 - auc: 0.9784 - val_loss: 0.5849 - val_auc: 0.9937\n",
      "Epoch 8/200\n",
      " - 30s - loss: 1.0617 - auc: 0.9785 - val_loss: 0.5447 - val_auc: 0.9943\n",
      "Epoch 9/200\n",
      " - 30s - loss: 1.0790 - auc: 0.9795 - val_loss: 0.5754 - val_auc: 0.9936\n",
      "Epoch 10/200\n",
      " - 30s - loss: 1.0467 - auc: 0.9803 - val_loss: 0.5583 - val_auc: 0.9934\n",
      "Epoch 11/200\n",
      " - 30s - loss: 1.0432 - auc: 0.9810 - val_loss: 0.5532 - val_auc: 0.9938\n",
      "Epoch 12/200\n",
      " - 30s - loss: 1.0619 - auc: 0.9789 - val_loss: 0.5345 - val_auc: 0.9943\n",
      "Epoch 13/200\n",
      " - 30s - loss: 1.0022 - auc: 0.9819 - val_loss: 0.5282 - val_auc: 0.9944\n",
      "Epoch 14/200\n",
      " - 30s - loss: 0.9897 - auc: 0.9822 - val_loss: 0.5282 - val_auc: 0.9943\n",
      "Epoch 15/200\n",
      " - 31s - loss: 0.9945 - auc: 0.9818 - val_loss: 0.5095 - val_auc: 0.9947\n",
      "Epoch 16/200\n",
      " - 30s - loss: 0.9425 - auc: 0.9840 - val_loss: 0.4923 - val_auc: 0.9949\n",
      "Epoch 17/200\n",
      " - 30s - loss: 0.9626 - auc: 0.9835 - val_loss: 0.4863 - val_auc: 0.9949\n",
      "Epoch 18/200\n",
      " - 30s - loss: 0.9747 - auc: 0.9821 - val_loss: 0.4943 - val_auc: 0.9950\n",
      "Epoch 19/200\n",
      " - 30s - loss: 0.9449 - auc: 0.9839 - val_loss: 0.4692 - val_auc: 0.9948\n",
      "Epoch 20/200\n",
      " - 30s - loss: 0.9434 - auc: 0.9829 - val_loss: 0.4536 - val_auc: 0.9951\n",
      "Epoch 21/200\n",
      " - 30s - loss: 0.9540 - auc: 0.9830 - val_loss: 0.4756 - val_auc: 0.9952\n",
      "Epoch 22/200\n",
      " - 30s - loss: 0.9196 - auc: 0.9841 - val_loss: 0.4847 - val_auc: 0.9948\n",
      "Epoch 23/200\n",
      " - 30s - loss: 0.9166 - auc: 0.9841 - val_loss: 0.4813 - val_auc: 0.9958\n",
      "Epoch 24/200\n",
      " - 30s - loss: 0.9014 - auc: 0.9854 - val_loss: 0.4556 - val_auc: 0.9952\n",
      "Epoch 25/200\n",
      " - 30s - loss: 0.8881 - auc: 0.9850 - val_loss: 0.4565 - val_auc: 0.9951\n",
      "Epoch 26/200\n",
      " - 30s - loss: 0.8987 - auc: 0.9854 - val_loss: 0.4568 - val_auc: 0.9949\n",
      "Epoch 27/200\n",
      " - 30s - loss: 0.9045 - auc: 0.9842 - val_loss: 0.4541 - val_auc: 0.9952\n",
      "Epoch 28/200\n",
      " - 30s - loss: 0.8999 - auc: 0.9850 - val_loss: 0.4375 - val_auc: 0.9955\n",
      "Epoch 29/200\n",
      " - 30s - loss: 0.8697 - auc: 0.9850 - val_loss: 0.4430 - val_auc: 0.9952\n",
      "Epoch 30/200\n",
      " - 30s - loss: 0.8668 - auc: 0.9858 - val_loss: 0.4343 - val_auc: 0.9956\n",
      "Epoch 31/200\n",
      " - 30s - loss: 0.8891 - auc: 0.9852 - val_loss: 0.4589 - val_auc: 0.9960\n",
      "Epoch 32/200\n",
      " - 30s - loss: 0.8838 - auc: 0.9851 - val_loss: 0.4669 - val_auc: 0.9949\n",
      "Epoch 33/200\n",
      " - 30s - loss: 0.8595 - auc: 0.9860 - val_loss: 0.4631 - val_auc: 0.9950\n",
      "Epoch 34/200\n",
      " - 30s - loss: 0.8856 - auc: 0.9856 - val_loss: 0.4316 - val_auc: 0.9954\n",
      "Epoch 35/200\n",
      " - 31s - loss: 0.8335 - auc: 0.9873 - val_loss: 0.4544 - val_auc: 0.9949\n",
      "Epoch 36/200\n",
      " - 30s - loss: 0.8206 - auc: 0.9876 - val_loss: 0.4305 - val_auc: 0.9953\n",
      "Epoch 37/200\n",
      " - 30s - loss: 0.8139 - auc: 0.9871 - val_loss: 0.4170 - val_auc: 0.9954\n",
      "Epoch 38/200\n",
      " - 30s - loss: 0.8513 - auc: 0.9869 - val_loss: 0.4381 - val_auc: 0.9954\n",
      "Epoch 39/200\n",
      " - 30s - loss: 0.8308 - auc: 0.9871 - val_loss: 0.4093 - val_auc: 0.9955\n",
      "Epoch 40/200\n",
      " - 30s - loss: 0.8333 - auc: 0.9868 - val_loss: 0.4453 - val_auc: 0.9950\n",
      "Epoch 41/200\n",
      " - 30s - loss: 0.8377 - auc: 0.9859 - val_loss: 0.4299 - val_auc: 0.9954\n",
      "Epoch 42/200\n",
      " - 30s - loss: 0.8201 - auc: 0.9871 - val_loss: 0.4092 - val_auc: 0.9967\n",
      "Epoch 43/200\n",
      " - 31s - loss: 0.8231 - auc: 0.9869 - val_loss: 0.4251 - val_auc: 0.9953\n",
      "Epoch 44/200\n",
      " - 30s - loss: 0.7791 - auc: 0.9890 - val_loss: 0.4093 - val_auc: 0.9954\n",
      "Epoch 45/200\n",
      " - 30s - loss: 0.8268 - auc: 0.9868 - val_loss: 0.4043 - val_auc: 0.9956\n",
      "Epoch 46/200\n",
      " - 30s - loss: 0.8348 - auc: 0.9866 - val_loss: 0.4264 - val_auc: 0.9953\n",
      "Epoch 47/200\n",
      " - 30s - loss: 0.8107 - auc: 0.9870 - val_loss: 0.4575 - val_auc: 0.9948\n",
      "Epoch 48/200\n",
      " - 30s - loss: 0.8445 - auc: 0.9859 - val_loss: 0.4253 - val_auc: 0.9953\n",
      "Epoch 49/200\n",
      " - 30s - loss: 0.7973 - auc: 0.9875 - val_loss: 0.4244 - val_auc: 0.9954\n",
      "Epoch 50/200\n",
      " - 30s - loss: 0.8081 - auc: 0.9879 - val_loss: 0.4069 - val_auc: 0.9956\n",
      "Epoch 51/200\n",
      " - 30s - loss: 0.8169 - auc: 0.9866 - val_loss: 0.4328 - val_auc: 0.9953\n",
      "Epoch 52/200\n",
      " - 30s - loss: 0.8187 - auc: 0.9863 - val_loss: 0.4210 - val_auc: 0.9953\n",
      "Epoch 53/200\n",
      " - 30s - loss: 0.7878 - auc: 0.9878 - val_loss: 0.4146 - val_auc: 0.9953\n",
      "Epoch 54/200\n",
      " - 30s - loss: 0.8260 - auc: 0.9871 - val_loss: 0.4107 - val_auc: 0.9954\n",
      "Epoch 55/200\n",
      " - 30s - loss: 0.8010 - auc: 0.9879 - val_loss: 0.4022 - val_auc: 0.9955\n",
      "Epoch 56/200\n",
      " - 30s - loss: 0.7956 - auc: 0.9872 - val_loss: 0.4600 - val_auc: 0.9947\n",
      "Epoch 57/200\n",
      " - 30s - loss: 0.7962 - auc: 0.9863 - val_loss: 0.4052 - val_auc: 0.9953\n",
      "Epoch 58/200\n",
      " - 30s - loss: 0.7866 - auc: 0.9871 - val_loss: 0.4172 - val_auc: 0.9954\n",
      "Epoch 59/200\n",
      " - 30s - loss: 0.8110 - auc: 0.9859 - val_loss: 0.4288 - val_auc: 0.9961\n",
      "Epoch 60/200\n",
      " - 30s - loss: 0.7949 - auc: 0.9871 - val_loss: 0.4041 - val_auc: 0.9955\n",
      "Epoch 61/200\n",
      " - 30s - loss: 0.8074 - auc: 0.9874 - val_loss: 0.3983 - val_auc: 0.9955\n",
      "Epoch 62/200\n",
      " - 31s - loss: 0.7798 - auc: 0.9880 - val_loss: 0.4143 - val_auc: 0.9954\n",
      "Epoch 63/200\n",
      " - 30s - loss: 0.7738 - auc: 0.9876 - val_loss: 0.3952 - val_auc: 0.9958\n",
      "Epoch 64/200\n",
      " - 30s - loss: 0.7813 - auc: 0.9874 - val_loss: 0.4325 - val_auc: 0.9948\n",
      "Epoch 65/200\n",
      " - 30s - loss: 0.7863 - auc: 0.9874 - val_loss: 0.4320 - val_auc: 0.9947\n",
      "Epoch 66/200\n",
      " - 30s - loss: 0.7874 - auc: 0.9881 - val_loss: 0.3949 - val_auc: 0.9968\n",
      "Epoch 67/200\n",
      " - 30s - loss: 0.7657 - auc: 0.9882 - val_loss: 0.3818 - val_auc: 0.9957\n",
      "Epoch 68/200\n",
      " - 30s - loss: 0.7828 - auc: 0.9890 - val_loss: 0.3770 - val_auc: 0.9959\n",
      "Epoch 69/200\n",
      " - 30s - loss: 0.7916 - auc: 0.9871 - val_loss: 0.4180 - val_auc: 0.9953\n",
      "Epoch 70/200\n",
      " - 30s - loss: 0.7615 - auc: 0.9883 - val_loss: 0.3996 - val_auc: 0.9955\n",
      "Epoch 71/200\n",
      " - 30s - loss: 0.7627 - auc: 0.9885 - val_loss: 0.3806 - val_auc: 0.9958\n",
      "Epoch 72/200\n",
      " - 30s - loss: 0.7397 - auc: 0.9898 - val_loss: 0.4100 - val_auc: 0.9951\n",
      "Epoch 73/200\n",
      " - 31s - loss: 0.7399 - auc: 0.9885 - val_loss: 0.3804 - val_auc: 0.9966\n",
      "Epoch 74/200\n",
      " - 31s - loss: 0.7848 - auc: 0.9872 - val_loss: 0.4268 - val_auc: 0.9948\n",
      "Epoch 75/200\n",
      " - 30s - loss: 0.7857 - auc: 0.9875 - val_loss: 0.4163 - val_auc: 0.9948\n",
      "Epoch 76/200\n",
      " - 30s - loss: 0.7760 - auc: 0.9875 - val_loss: 0.3955 - val_auc: 0.9954\n",
      "Epoch 77/200\n",
      " - 30s - loss: 0.7719 - auc: 0.9884 - val_loss: 0.4066 - val_auc: 0.9950\n",
      "Epoch 78/200\n",
      " - 30s - loss: 0.7716 - auc: 0.9876 - val_loss: 0.3852 - val_auc: 0.9952\n",
      "Epoch 79/200\n",
      " - 30s - loss: 0.7969 - auc: 0.9866 - val_loss: 0.4122 - val_auc: 0.9950\n",
      "Epoch 80/200\n",
      " - 30s - loss: 0.7233 - auc: 0.9898 - val_loss: 0.4012 - val_auc: 0.9951\n",
      "Epoch 81/200\n",
      " - 30s - loss: 0.7289 - auc: 0.9897 - val_loss: 0.3826 - val_auc: 0.9956\n",
      "Epoch 82/200\n",
      " - 30s - loss: 0.7648 - auc: 0.9889 - val_loss: 0.4159 - val_auc: 0.9950\n",
      "Epoch 83/200\n",
      " - 30s - loss: 0.7438 - auc: 0.9892 - val_loss: 0.4138 - val_auc: 0.9952\n",
      "Epoch 84/200\n",
      " - 30s - loss: 0.7555 - auc: 0.9886 - val_loss: 0.3958 - val_auc: 0.9954\n",
      "Epoch 85/200\n",
      " - 30s - loss: 0.7624 - auc: 0.9877 - val_loss: 0.3928 - val_auc: 0.9954\n",
      "Epoch 86/200\n",
      " - 30s - loss: 0.7662 - auc: 0.9887 - val_loss: 0.4021 - val_auc: 0.9953\n",
      "Epoch 87/200\n",
      " - 30s - loss: 0.7605 - auc: 0.9887 - val_loss: 0.3916 - val_auc: 0.9955\n",
      "Epoch 88/200\n",
      " - 30s - loss: 0.7681 - auc: 0.9873 - val_loss: 0.3975 - val_auc: 0.9953\n",
      "Epoch 89/200\n",
      " - 30s - loss: 0.7613 - auc: 0.9882 - val_loss: 0.3837 - val_auc: 0.9956\n",
      "Epoch 90/200\n",
      " - 30s - loss: 0.7316 - auc: 0.9901 - val_loss: 0.3877 - val_auc: 0.9968\n",
      "Epoch 91/200\n",
      " - 30s - loss: 0.7448 - auc: 0.9886 - val_loss: 0.3947 - val_auc: 0.9964\n",
      "Epoch 92/200\n",
      " - 30s - loss: 0.7327 - auc: 0.9891 - val_loss: 0.3830 - val_auc: 0.9955\n",
      "Epoch 93/200\n",
      " - 30s - loss: 0.7634 - auc: 0.9881 - val_loss: 0.3888 - val_auc: 0.9956\n",
      "Epoch 94/200\n",
      " - 30s - loss: 0.7405 - auc: 0.9890 - val_loss: 0.3902 - val_auc: 0.9953\n",
      "Epoch 95/200\n",
      " - 30s - loss: 0.7430 - auc: 0.9892 - val_loss: 0.3879 - val_auc: 0.9957\n",
      "Epoch 96/200\n",
      " - 30s - loss: 0.7357 - auc: 0.9893 - val_loss: 0.3667 - val_auc: 0.9969\n",
      "Epoch 97/200\n",
      " - 30s - loss: 0.7241 - auc: 0.9903 - val_loss: 0.3751 - val_auc: 0.9956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/200\n",
      " - 30s - loss: 0.7290 - auc: 0.9896 - val_loss: 0.3662 - val_auc: 0.9956\n",
      "Epoch 99/200\n",
      " - 30s - loss: 0.7433 - auc: 0.9877 - val_loss: 0.3803 - val_auc: 0.9956\n",
      "Epoch 100/200\n",
      " - 30s - loss: 0.7883 - auc: 0.9871 - val_loss: 0.3848 - val_auc: 0.9976\n",
      "Epoch 101/200\n",
      " - 30s - loss: 0.7469 - auc: 0.9894 - val_loss: 0.3893 - val_auc: 0.9965\n",
      "Epoch 102/200\n",
      " - 30s - loss: 0.7558 - auc: 0.9891 - val_loss: 0.4027 - val_auc: 0.9965\n",
      "Epoch 103/200\n",
      " - 30s - loss: 0.7578 - auc: 0.9891 - val_loss: 0.3995 - val_auc: 0.9965\n",
      "Epoch 104/200\n",
      " - 31s - loss: 0.7135 - auc: 0.9887 - val_loss: 0.4153 - val_auc: 0.9961\n",
      "Epoch 105/200\n",
      " - 30s - loss: 0.7422 - auc: 0.9892 - val_loss: 0.3862 - val_auc: 0.9955\n",
      "Epoch 106/200\n",
      " - 30s - loss: 0.7678 - auc: 0.9881 - val_loss: 0.3766 - val_auc: 0.9956\n",
      "Epoch 107/200\n",
      " - 30s - loss: 0.7293 - auc: 0.9895 - val_loss: 0.3882 - val_auc: 0.9966\n",
      "Epoch 108/200\n",
      " - 30s - loss: 0.7369 - auc: 0.9893 - val_loss: 0.3817 - val_auc: 0.9953\n",
      "Epoch 109/200\n",
      " - 30s - loss: 0.7118 - auc: 0.9899 - val_loss: 0.3765 - val_auc: 0.9955\n",
      "Epoch 110/200\n",
      " - 30s - loss: 0.7306 - auc: 0.9891 - val_loss: 0.3852 - val_auc: 0.9965\n",
      "Epoch 111/200\n",
      " - 30s - loss: 0.7001 - auc: 0.9901 - val_loss: 0.3830 - val_auc: 0.9954\n",
      "Epoch 112/200\n",
      " - 30s - loss: 0.7240 - auc: 0.9887 - val_loss: 0.3850 - val_auc: 0.9965\n",
      "Epoch 113/200\n",
      " - 30s - loss: 0.7244 - auc: 0.9894 - val_loss: 0.3981 - val_auc: 0.9953\n",
      "Epoch 114/200\n",
      " - 30s - loss: 0.7068 - auc: 0.9898 - val_loss: 0.3873 - val_auc: 0.9966\n",
      "Epoch 115/200\n",
      " - 30s - loss: 0.7244 - auc: 0.9885 - val_loss: 0.3796 - val_auc: 0.9967\n",
      "Epoch 116/200\n",
      " - 30s - loss: 0.7254 - auc: 0.9886 - val_loss: 0.4024 - val_auc: 0.9936\n",
      "Epoch 117/200\n",
      " - 31s - loss: 0.7339 - auc: 0.9897 - val_loss: 0.4097 - val_auc: 0.9963\n",
      "Epoch 118/200\n",
      " - 30s - loss: 0.7210 - auc: 0.9901 - val_loss: 0.3768 - val_auc: 0.9955\n",
      "Epoch 119/200\n",
      " - 30s - loss: 0.7364 - auc: 0.9880 - val_loss: 0.3779 - val_auc: 0.9966\n",
      "Epoch 120/200\n",
      " - 30s - loss: 0.7137 - auc: 0.9892 - val_loss: 0.3853 - val_auc: 0.9966\n",
      "Epoch 121/200\n",
      " - 30s - loss: 0.7421 - auc: 0.9878 - val_loss: 0.3687 - val_auc: 0.9968\n",
      "Epoch 122/200\n",
      " - 30s - loss: 0.7252 - auc: 0.9891 - val_loss: 0.3708 - val_auc: 0.9955\n",
      "Epoch 123/200\n",
      " - 30s - loss: 0.7182 - auc: 0.9892 - val_loss: 0.4004 - val_auc: 0.9966\n",
      "Epoch 124/200\n",
      " - 30s - loss: 0.7074 - auc: 0.9903 - val_loss: 0.3519 - val_auc: 0.9969\n",
      "Epoch 125/200\n",
      " - 30s - loss: 0.7238 - auc: 0.9896 - val_loss: 0.4228 - val_auc: 0.9962\n",
      "Epoch 126/200\n",
      " - 30s - loss: 0.7376 - auc: 0.9890 - val_loss: 0.3956 - val_auc: 0.9964\n",
      "Epoch 127/200\n",
      " - 30s - loss: 0.7275 - auc: 0.9883 - val_loss: 0.3650 - val_auc: 0.9957\n",
      "Epoch 128/200\n",
      " - 31s - loss: 0.7333 - auc: 0.9896 - val_loss: 0.3955 - val_auc: 0.9964\n",
      "Epoch 129/200\n",
      " - 30s - loss: 0.6955 - auc: 0.9898 - val_loss: 0.3977 - val_auc: 0.9952\n",
      "Epoch 130/200\n",
      " - 30s - loss: 0.7223 - auc: 0.9890 - val_loss: 0.3877 - val_auc: 0.9954\n",
      "Epoch 131/200\n",
      " - 30s - loss: 0.7023 - auc: 0.9891 - val_loss: 0.3655 - val_auc: 0.9981\n",
      "Epoch 132/200\n",
      " - 30s - loss: 0.6847 - auc: 0.9906 - val_loss: 0.3822 - val_auc: 0.9955\n",
      "Epoch 133/200\n",
      " - 30s - loss: 0.7028 - auc: 0.9906 - val_loss: 0.3455 - val_auc: 0.9957\n",
      "Epoch 134/200\n",
      " - 30s - loss: 0.7116 - auc: 0.9897 - val_loss: 0.3560 - val_auc: 0.9956\n",
      "Epoch 135/200\n",
      " - 30s - loss: 0.6995 - auc: 0.9907 - val_loss: 0.3704 - val_auc: 0.9955\n",
      "Epoch 136/200\n",
      " - 30s - loss: 0.7204 - auc: 0.9897 - val_loss: 0.3782 - val_auc: 0.9966\n",
      "Epoch 137/200\n",
      " - 30s - loss: 0.7059 - auc: 0.9893 - val_loss: 0.3803 - val_auc: 0.9953\n",
      "Epoch 138/200\n",
      " - 30s - loss: 0.7076 - auc: 0.9896 - val_loss: 0.3376 - val_auc: 0.9982\n",
      "Epoch 139/200\n",
      " - 30s - loss: 0.7320 - auc: 0.9887 - val_loss: 0.3578 - val_auc: 0.9957\n",
      "Epoch 140/200\n",
      " - 30s - loss: 0.6790 - auc: 0.9906 - val_loss: 0.3807 - val_auc: 0.9976\n",
      "Epoch 141/200\n",
      " - 30s - loss: 0.7219 - auc: 0.9884 - val_loss: 0.3484 - val_auc: 0.9970\n",
      "Epoch 142/200\n",
      " - 30s - loss: 0.7365 - auc: 0.9888 - val_loss: 0.3651 - val_auc: 0.9969\n",
      "Epoch 143/200\n",
      " - 30s - loss: 0.7217 - auc: 0.9889 - val_loss: 0.3695 - val_auc: 0.9978\n",
      "Epoch 144/200\n",
      " - 30s - loss: 0.6997 - auc: 0.9909 - val_loss: 0.3523 - val_auc: 0.9970\n",
      "Epoch 145/200\n",
      " - 30s - loss: 0.6998 - auc: 0.9891 - val_loss: 0.3679 - val_auc: 0.9968\n",
      "Epoch 146/200\n",
      " - 30s - loss: 0.6897 - auc: 0.9906 - val_loss: 0.3560 - val_auc: 0.9966\n",
      "Epoch 147/200\n",
      " - 30s - loss: 0.7286 - auc: 0.9891 - val_loss: 0.3676 - val_auc: 0.9980\n",
      "Epoch 148/200\n",
      " - 30s - loss: 0.7179 - auc: 0.9883 - val_loss: 0.3428 - val_auc: 0.9971\n",
      "Epoch 149/200\n",
      " - 30s - loss: 0.7149 - auc: 0.9896 - val_loss: 0.3623 - val_auc: 0.9980\n",
      "Epoch 150/200\n",
      " - 30s - loss: 0.6875 - auc: 0.9905 - val_loss: 0.3612 - val_auc: 0.9980\n",
      "Epoch 151/200\n",
      " - 31s - loss: 0.7158 - auc: 0.9907 - val_loss: 0.3578 - val_auc: 0.9978\n",
      "Epoch 152/200\n",
      " - 30s - loss: 0.6984 - auc: 0.9891 - val_loss: 0.3693 - val_auc: 0.9955\n",
      "Epoch 153/200\n",
      " - 31s - loss: 0.7058 - auc: 0.9895 - val_loss: 0.3590 - val_auc: 0.9967\n",
      "Epoch 154/200\n",
      " - 30s - loss: 0.7018 - auc: 0.9903 - val_loss: 0.3607 - val_auc: 0.9969\n",
      "Epoch 155/200\n",
      " - 30s - loss: 0.7111 - auc: 0.9897 - val_loss: 0.3889 - val_auc: 0.9975\n",
      "Epoch 156/200\n",
      " - 31s - loss: 0.6942 - auc: 0.9896 - val_loss: 0.3756 - val_auc: 0.9977\n",
      "Epoch 157/200\n",
      " - 30s - loss: 0.6840 - auc: 0.9910 - val_loss: 0.3535 - val_auc: 0.9980\n",
      "Epoch 158/200\n",
      " - 30s - loss: 0.6935 - auc: 0.9891 - val_loss: 0.3754 - val_auc: 0.9966\n",
      "Epoch 159/200\n",
      " - 30s - loss: 0.7030 - auc: 0.9898 - val_loss: 0.3741 - val_auc: 0.9967\n",
      "Epoch 160/200\n",
      " - 30s - loss: 0.6874 - auc: 0.9901 - val_loss: 0.3579 - val_auc: 0.9978\n",
      "Epoch 161/200\n",
      " - 30s - loss: 0.7069 - auc: 0.9893 - val_loss: 0.3661 - val_auc: 0.9968\n",
      "Epoch 162/200\n",
      " - 30s - loss: 0.7060 - auc: 0.9898 - val_loss: 0.3619 - val_auc: 0.9980\n",
      "Epoch 163/200\n",
      " - 30s - loss: 0.7157 - auc: 0.9895 - val_loss: 0.3886 - val_auc: 0.9975\n",
      "Epoch 164/200\n",
      " - 30s - loss: 0.6970 - auc: 0.9909 - val_loss: 0.3465 - val_auc: 0.9981\n",
      "Epoch 165/200\n",
      " - 30s - loss: 0.6974 - auc: 0.9895 - val_loss: 0.3535 - val_auc: 0.9980\n",
      "Epoch 166/200\n",
      " - 30s - loss: 0.6985 - auc: 0.9908 - val_loss: 0.3431 - val_auc: 0.9970\n",
      "Epoch 167/200\n",
      " - 30s - loss: 0.6989 - auc: 0.9902 - val_loss: 0.3463 - val_auc: 0.9982\n",
      "Epoch 168/200\n",
      " - 30s - loss: 0.7167 - auc: 0.9892 - val_loss: 0.3996 - val_auc: 0.9977\n",
      "Epoch 169/200\n",
      " - 30s - loss: 0.6914 - auc: 0.9901 - val_loss: 0.3291 - val_auc: 0.9986\n",
      "Epoch 170/200\n",
      " - 30s - loss: 0.6815 - auc: 0.9903 - val_loss: 0.3252 - val_auc: 0.9985\n",
      "Epoch 171/200\n",
      " - 30s - loss: 0.6944 - auc: 0.9901 - val_loss: 0.3417 - val_auc: 0.9983\n",
      "Epoch 172/200\n",
      " - 30s - loss: 0.6901 - auc: 0.9903 - val_loss: 0.3489 - val_auc: 0.9982\n",
      "Epoch 173/200\n",
      " - 30s - loss: 0.7055 - auc: 0.9901 - val_loss: 0.3630 - val_auc: 0.9980\n",
      "Epoch 174/200\n",
      " - 30s - loss: 0.6883 - auc: 0.9912 - val_loss: 0.3709 - val_auc: 0.9954\n",
      "Epoch 175/200\n",
      " - 30s - loss: 0.6828 - auc: 0.9901 - val_loss: 0.3785 - val_auc: 0.9951\n",
      "Epoch 176/200\n",
      " - 30s - loss: 0.6944 - auc: 0.9905 - val_loss: 0.3839 - val_auc: 0.9975\n",
      "Epoch 177/200\n",
      " - 30s - loss: 0.6991 - auc: 0.9906 - val_loss: 0.3764 - val_auc: 0.9965\n",
      "Epoch 178/200\n",
      " - 31s - loss: 0.7068 - auc: 0.9892 - val_loss: 0.3418 - val_auc: 0.9982\n",
      "Epoch 179/200\n",
      " - 30s - loss: 0.6892 - auc: 0.9904 - val_loss: 0.3587 - val_auc: 0.9954\n",
      "Epoch 180/200\n",
      " - 30s - loss: 0.7187 - auc: 0.9892 - val_loss: 0.3401 - val_auc: 0.9983\n",
      "Epoch 181/200\n",
      " - 30s - loss: 0.7035 - auc: 0.9900 - val_loss: 0.3794 - val_auc: 0.9979\n",
      "Epoch 182/200\n",
      " - 30s - loss: 0.7009 - auc: 0.9902 - val_loss: 0.3622 - val_auc: 0.9970\n",
      "Epoch 183/200\n",
      " - 30s - loss: 0.6615 - auc: 0.9917 - val_loss: 0.3359 - val_auc: 0.9983\n",
      "Epoch 184/200\n",
      " - 30s - loss: 0.7049 - auc: 0.9896 - val_loss: 0.3372 - val_auc: 0.9982\n",
      "Epoch 185/200\n",
      " - 30s - loss: 0.6937 - auc: 0.9901 - val_loss: 0.3752 - val_auc: 0.9978\n",
      "Epoch 186/200\n",
      " - 30s - loss: 0.6718 - auc: 0.9900 - val_loss: 0.3773 - val_auc: 0.9953\n",
      "Epoch 187/200\n",
      " - 30s - loss: 0.6861 - auc: 0.9907 - val_loss: 0.3632 - val_auc: 0.9978\n",
      "Epoch 188/200\n",
      " - 30s - loss: 0.6758 - auc: 0.9898 - val_loss: 0.3452 - val_auc: 0.9956\n",
      "Epoch 189/200\n",
      " - 31s - loss: 0.6691 - auc: 0.9910 - val_loss: 0.3686 - val_auc: 0.9977\n",
      "Epoch 190/200\n",
      " - 30s - loss: 0.7011 - auc: 0.9896 - val_loss: 0.3718 - val_auc: 0.9975\n",
      "Epoch 191/200\n",
      " - 30s - loss: 0.7042 - auc: 0.9898 - val_loss: 0.3599 - val_auc: 0.9979\n",
      "Epoch 192/200\n",
      " - 30s - loss: 0.6978 - auc: 0.9894 - val_loss: 0.3820 - val_auc: 0.9973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/200\n",
      " - 30s - loss: 0.6634 - auc: 0.9899 - val_loss: 0.3504 - val_auc: 0.9970\n",
      "Epoch 194/200\n",
      " - 30s - loss: 0.7082 - auc: 0.9893 - val_loss: 0.3614 - val_auc: 0.9978\n",
      "Epoch 195/200\n",
      " - 30s - loss: 0.6938 - auc: 0.9901 - val_loss: 0.3725 - val_auc: 0.9977\n",
      "Epoch 196/200\n",
      " - 30s - loss: 0.6711 - auc: 0.9913 - val_loss: 0.3583 - val_auc: 0.9978\n",
      "Epoch 197/200\n",
      " - 30s - loss: 0.6985 - auc: 0.9908 - val_loss: 0.3409 - val_auc: 0.9981\n",
      "Epoch 198/200\n",
      " - 30s - loss: 0.6706 - auc: 0.9905 - val_loss: 0.3346 - val_auc: 0.9981\n",
      "Epoch 199/200\n",
      " - 30s - loss: 0.6747 - auc: 0.9905 - val_loss: 0.3712 - val_auc: 0.9976\n",
      "Epoch 200/200\n",
      " - 30s - loss: 0.7041 - auc: 0.9892 - val_loss: 0.3620 - val_auc: 0.9977\n",
      "SVMSMOTE,MIT-BIH Arrhythmia Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keg/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:80: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5920 samples, validate on 715 samples\n",
      "Epoch 1/200\n",
      " - 64s - loss: 1.9864 - auc: 0.9177 - val_loss: 0.9292 - val_auc: 0.9886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keg/anaconda3/lib/python3.6/site-packages/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `roc_accuracy` which is not available. Available metrics are: val_loss,val_auc,loss,auc,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200\n",
      " - 30s - loss: 1.3811 - auc: 0.9676 - val_loss: 0.7473 - val_auc: 0.9902\n",
      "Epoch 3/200\n",
      " - 30s - loss: 1.2959 - auc: 0.9702 - val_loss: 0.6607 - val_auc: 0.9926\n",
      "Epoch 4/200\n",
      " - 30s - loss: 1.2228 - auc: 0.9740 - val_loss: 0.6425 - val_auc: 0.9934\n",
      "Epoch 5/200\n",
      " - 30s - loss: 1.1757 - auc: 0.9739 - val_loss: 0.5931 - val_auc: 0.9942\n",
      "Epoch 6/200\n",
      " - 30s - loss: 1.1119 - auc: 0.9779 - val_loss: 0.6123 - val_auc: 0.9931\n",
      "Epoch 7/200\n",
      " - 30s - loss: 1.0789 - auc: 0.9779 - val_loss: 0.5289 - val_auc: 0.9964\n",
      "Epoch 8/200\n",
      " - 30s - loss: 1.0657 - auc: 0.9793 - val_loss: 0.5450 - val_auc: 0.9947\n",
      "Epoch 9/200\n",
      " - 30s - loss: 1.0720 - auc: 0.9788 - val_loss: 0.5362 - val_auc: 0.9967\n",
      "Epoch 10/200\n",
      " - 30s - loss: 1.0094 - auc: 0.9799 - val_loss: 0.5081 - val_auc: 0.9971\n",
      "Epoch 11/200\n",
      " - 30s - loss: 1.0305 - auc: 0.9808 - val_loss: 0.4948 - val_auc: 0.9973\n",
      "Epoch 12/200\n",
      " - 30s - loss: 1.0034 - auc: 0.9817 - val_loss: 0.4862 - val_auc: 0.9971\n",
      "Epoch 13/200\n",
      " - 30s - loss: 1.0064 - auc: 0.9819 - val_loss: 0.4921 - val_auc: 0.9976\n",
      "Epoch 14/200\n",
      " - 30s - loss: 0.9762 - auc: 0.9823 - val_loss: 0.4665 - val_auc: 0.9976\n",
      "Epoch 15/200\n",
      " - 30s - loss: 0.9563 - auc: 0.9825 - val_loss: 0.4821 - val_auc: 0.9974\n",
      "Epoch 16/200\n",
      " - 30s - loss: 0.9463 - auc: 0.9831 - val_loss: 0.4583 - val_auc: 0.9976\n",
      "Epoch 17/200\n",
      " - 30s - loss: 0.9550 - auc: 0.9824 - val_loss: 0.4440 - val_auc: 0.9979\n",
      "Epoch 18/200\n",
      " - 30s - loss: 0.9479 - auc: 0.9824 - val_loss: 0.4588 - val_auc: 0.9981\n",
      "Epoch 19/200\n",
      " - 30s - loss: 0.9098 - auc: 0.9848 - val_loss: 0.4330 - val_auc: 0.9978\n",
      "Epoch 20/200\n",
      " - 30s - loss: 0.9184 - auc: 0.9846 - val_loss: 0.4483 - val_auc: 0.9975\n",
      "Epoch 21/200\n",
      " - 30s - loss: 0.9222 - auc: 0.9840 - val_loss: 0.4370 - val_auc: 0.9979\n",
      "Epoch 22/200\n",
      " - 30s - loss: 0.9401 - auc: 0.9830 - val_loss: 0.4328 - val_auc: 0.9982\n",
      "Epoch 23/200\n",
      " - 30s - loss: 0.9080 - auc: 0.9843 - val_loss: 0.4608 - val_auc: 0.9978\n",
      "Epoch 24/200\n",
      " - 30s - loss: 0.8794 - auc: 0.9850 - val_loss: 0.4011 - val_auc: 0.9984\n",
      "Epoch 25/200\n",
      " - 30s - loss: 0.8974 - auc: 0.9848 - val_loss: 0.3966 - val_auc: 0.9987\n",
      "Epoch 26/200\n",
      " - 30s - loss: 0.8868 - auc: 0.9853 - val_loss: 0.4234 - val_auc: 0.9982\n",
      "Epoch 27/200\n",
      " - 30s - loss: 0.8588 - auc: 0.9853 - val_loss: 0.4206 - val_auc: 0.9982\n",
      "Epoch 28/200\n",
      " - 30s - loss: 0.8899 - auc: 0.9845 - val_loss: 0.3999 - val_auc: 0.9986\n",
      "Epoch 29/200\n",
      " - 30s - loss: 0.8916 - auc: 0.9842 - val_loss: 0.4206 - val_auc: 0.9983\n",
      "Epoch 30/200\n",
      " - 30s - loss: 0.8391 - auc: 0.9862 - val_loss: 0.3989 - val_auc: 0.9986\n",
      "Epoch 31/200\n",
      " - 30s - loss: 0.8451 - auc: 0.9872 - val_loss: 0.3770 - val_auc: 0.9987\n",
      "Epoch 32/200\n",
      " - 30s - loss: 0.8612 - auc: 0.9868 - val_loss: 0.3901 - val_auc: 0.9985\n",
      "Epoch 33/200\n",
      " - 30s - loss: 0.8785 - auc: 0.9855 - val_loss: 0.3835 - val_auc: 0.9987\n",
      "Epoch 34/200\n",
      " - 30s - loss: 0.8719 - auc: 0.9850 - val_loss: 0.3909 - val_auc: 0.9982\n",
      "Epoch 35/200\n",
      " - 30s - loss: 0.8534 - auc: 0.9859 - val_loss: 0.4090 - val_auc: 0.9982\n",
      "Epoch 36/200\n",
      " - 30s - loss: 0.8343 - auc: 0.9859 - val_loss: 0.3819 - val_auc: 0.9985\n",
      "Epoch 37/200\n",
      " - 30s - loss: 0.8567 - auc: 0.9864 - val_loss: 0.3782 - val_auc: 0.9985\n",
      "Epoch 38/200\n",
      " - 30s - loss: 0.8405 - auc: 0.9853 - val_loss: 0.3741 - val_auc: 0.9985\n",
      "Epoch 39/200\n",
      " - 30s - loss: 0.8345 - auc: 0.9859 - val_loss: 0.3707 - val_auc: 0.9990\n",
      "Epoch 40/200\n",
      " - 30s - loss: 0.8463 - auc: 0.9856 - val_loss: 0.3896 - val_auc: 0.9985\n",
      "Epoch 41/200\n",
      " - 30s - loss: 0.8353 - auc: 0.9864 - val_loss: 0.3816 - val_auc: 0.9984\n",
      "Epoch 42/200\n",
      " - 30s - loss: 0.8033 - auc: 0.9877 - val_loss: 0.3545 - val_auc: 0.9988\n",
      "Epoch 43/200\n",
      " - 30s - loss: 0.8074 - auc: 0.9865 - val_loss: 0.3571 - val_auc: 0.9989\n",
      "Epoch 44/200\n",
      " - 30s - loss: 0.7945 - auc: 0.9864 - val_loss: 0.3606 - val_auc: 0.9986\n",
      "Epoch 45/200\n",
      " - 30s - loss: 0.8291 - auc: 0.9863 - val_loss: 0.3809 - val_auc: 0.9986\n",
      "Epoch 46/200\n",
      " - 30s - loss: 0.7913 - auc: 0.9877 - val_loss: 0.3790 - val_auc: 0.9984\n",
      "Epoch 47/200\n",
      " - 30s - loss: 0.8145 - auc: 0.9869 - val_loss: 0.3805 - val_auc: 0.9986\n",
      "Epoch 48/200\n",
      " - 30s - loss: 0.8218 - auc: 0.9859 - val_loss: 0.3620 - val_auc: 0.9987\n",
      "Epoch 49/200\n",
      " - 30s - loss: 0.8122 - auc: 0.9869 - val_loss: 0.3618 - val_auc: 0.9989\n",
      "Epoch 50/200\n",
      " - 30s - loss: 0.8176 - auc: 0.9861 - val_loss: 0.3772 - val_auc: 0.9986\n",
      "Epoch 51/200\n",
      " - 30s - loss: 0.7771 - auc: 0.9880 - val_loss: 0.4133 - val_auc: 0.9981\n",
      "Epoch 52/200\n",
      " - 30s - loss: 0.7475 - auc: 0.9888 - val_loss: 0.3286 - val_auc: 0.9989\n",
      "Epoch 53/200\n",
      " - 30s - loss: 0.8054 - auc: 0.9870 - val_loss: 0.3643 - val_auc: 0.9987\n",
      "Epoch 54/200\n",
      " - 30s - loss: 0.7677 - auc: 0.9884 - val_loss: 0.3707 - val_auc: 0.9985\n",
      "Epoch 55/200\n",
      " - 30s - loss: 0.7770 - auc: 0.9880 - val_loss: 0.3672 - val_auc: 0.9985\n",
      "Epoch 56/200\n",
      " - 30s - loss: 0.8099 - auc: 0.9859 - val_loss: 0.3707 - val_auc: 0.9987\n",
      "Epoch 57/200\n",
      " - 30s - loss: 0.7654 - auc: 0.9880 - val_loss: 0.3299 - val_auc: 0.9991\n",
      "Epoch 58/200\n",
      " - 30s - loss: 0.7606 - auc: 0.9883 - val_loss: 0.3611 - val_auc: 0.9986\n",
      "Epoch 59/200\n",
      " - 30s - loss: 0.7971 - auc: 0.9872 - val_loss: 0.3693 - val_auc: 0.9986\n",
      "Epoch 60/200\n",
      " - 30s - loss: 0.7273 - auc: 0.9900 - val_loss: 0.3415 - val_auc: 0.9988\n",
      "Epoch 61/200\n",
      " - 30s - loss: 0.7610 - auc: 0.9890 - val_loss: 0.3411 - val_auc: 0.9988\n",
      "Epoch 62/200\n",
      " - 30s - loss: 0.7591 - auc: 0.9879 - val_loss: 0.3664 - val_auc: 0.9983\n",
      "Epoch 63/200\n",
      " - 30s - loss: 0.7967 - auc: 0.9866 - val_loss: 0.3576 - val_auc: 0.9986\n",
      "Epoch 64/200\n",
      " - 30s - loss: 0.7687 - auc: 0.9886 - val_loss: 0.3514 - val_auc: 0.9987\n",
      "Epoch 65/200\n",
      " - 30s - loss: 0.7676 - auc: 0.9884 - val_loss: 0.3622 - val_auc: 0.9987\n",
      "Epoch 66/200\n",
      " - 30s - loss: 0.7772 - auc: 0.9877 - val_loss: 0.3285 - val_auc: 0.9990\n",
      "Epoch 67/200\n",
      " - 30s - loss: 0.7739 - auc: 0.9875 - val_loss: 0.3304 - val_auc: 0.9989\n",
      "Epoch 68/200\n",
      " - 30s - loss: 0.7612 - auc: 0.9880 - val_loss: 0.3510 - val_auc: 0.9986\n",
      "Epoch 69/200\n",
      " - 30s - loss: 0.7749 - auc: 0.9871 - val_loss: 0.3478 - val_auc: 0.9990\n",
      "Epoch 70/200\n",
      " - 30s - loss: 0.7229 - auc: 0.9892 - val_loss: 0.3376 - val_auc: 0.9989\n",
      "Epoch 71/200\n",
      " - 30s - loss: 0.8009 - auc: 0.9847 - val_loss: 0.3786 - val_auc: 0.9984\n",
      "Epoch 72/200\n",
      " - 30s - loss: 0.7381 - auc: 0.9897 - val_loss: 0.3730 - val_auc: 0.9985\n",
      "Epoch 73/200\n",
      " - 30s - loss: 0.7643 - auc: 0.9880 - val_loss: 0.3561 - val_auc: 0.9988\n",
      "Epoch 74/200\n",
      " - 30s - loss: 0.7815 - auc: 0.9868 - val_loss: 0.3498 - val_auc: 0.9987\n",
      "Epoch 75/200\n",
      " - 30s - loss: 0.7700 - auc: 0.9881 - val_loss: 0.3585 - val_auc: 0.9986\n",
      "Epoch 76/200\n",
      " - 30s - loss: 0.7444 - auc: 0.9891 - val_loss: 0.3227 - val_auc: 0.9990\n",
      "Epoch 77/200\n",
      " - 30s - loss: 0.7570 - auc: 0.9881 - val_loss: 0.3458 - val_auc: 0.9989\n",
      "Epoch 78/200\n",
      " - 30s - loss: 0.7604 - auc: 0.9885 - val_loss: 0.3530 - val_auc: 0.9987\n",
      "Epoch 79/200\n",
      " - 30s - loss: 0.7392 - auc: 0.9891 - val_loss: 0.3135 - val_auc: 0.9991\n",
      "Epoch 80/200\n",
      " - 30s - loss: 0.7747 - auc: 0.9881 - val_loss: 0.3306 - val_auc: 0.9990\n",
      "Epoch 81/200\n",
      " - 30s - loss: 0.7483 - auc: 0.9884 - val_loss: 0.3311 - val_auc: 0.9989\n",
      "Epoch 82/200\n",
      " - 30s - loss: 0.7547 - auc: 0.9885 - val_loss: 0.3747 - val_auc: 0.9987\n",
      "Epoch 83/200\n",
      " - 30s - loss: 0.7262 - auc: 0.9896 - val_loss: 0.3618 - val_auc: 0.9987\n",
      "Epoch 84/200\n",
      " - 30s - loss: 0.7808 - auc: 0.9868 - val_loss: 0.3285 - val_auc: 0.9990\n",
      "Epoch 85/200\n",
      " - 30s - loss: 0.7438 - auc: 0.9894 - val_loss: 0.3797 - val_auc: 0.9984\n",
      "Epoch 86/200\n",
      " - 30s - loss: 0.7560 - auc: 0.9879 - val_loss: 0.3319 - val_auc: 0.9989\n",
      "Epoch 87/200\n",
      " - 30s - loss: 0.7343 - auc: 0.9897 - val_loss: 0.3533 - val_auc: 0.9987\n",
      "Epoch 88/200\n",
      " - 30s - loss: 0.7209 - auc: 0.9891 - val_loss: 0.3334 - val_auc: 0.9988\n",
      "Epoch 89/200\n",
      " - 30s - loss: 0.7388 - auc: 0.9890 - val_loss: 0.3549 - val_auc: 0.9986\n",
      "Epoch 90/200\n",
      " - 30s - loss: 0.7485 - auc: 0.9883 - val_loss: 0.3724 - val_auc: 0.9986\n",
      "Epoch 91/200\n",
      " - 30s - loss: 0.7390 - auc: 0.9884 - val_loss: 0.3609 - val_auc: 0.9985\n",
      "Epoch 92/200\n",
      " - 30s - loss: 0.7348 - auc: 0.9891 - val_loss: 0.3557 - val_auc: 0.9987\n",
      "Epoch 93/200\n",
      " - 30s - loss: 0.7280 - auc: 0.9898 - val_loss: 0.3331 - val_auc: 0.9989\n",
      "Epoch 94/200\n",
      " - 30s - loss: 0.7541 - auc: 0.9874 - val_loss: 0.3249 - val_auc: 0.9990\n",
      "Epoch 95/200\n",
      " - 30s - loss: 0.7284 - auc: 0.9900 - val_loss: 0.3350 - val_auc: 0.9987\n",
      "Epoch 96/200\n",
      " - 30s - loss: 0.7227 - auc: 0.9898 - val_loss: 0.3473 - val_auc: 0.9988\n",
      "Epoch 97/200\n",
      " - 30s - loss: 0.7439 - auc: 0.9875 - val_loss: 0.3396 - val_auc: 0.9988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/200\n",
      " - 30s - loss: 0.7267 - auc: 0.9892 - val_loss: 0.3368 - val_auc: 0.9988\n",
      "Epoch 99/200\n",
      " - 30s - loss: 0.7119 - auc: 0.9898 - val_loss: 0.3649 - val_auc: 0.9985\n",
      "Epoch 100/200\n",
      " - 30s - loss: 0.7340 - auc: 0.9898 - val_loss: 0.3355 - val_auc: 0.9987\n",
      "Epoch 101/200\n",
      " - 30s - loss: 0.7440 - auc: 0.9892 - val_loss: 0.3594 - val_auc: 0.9987\n",
      "Epoch 102/200\n",
      " - 30s - loss: 0.7128 - auc: 0.9896 - val_loss: 0.3380 - val_auc: 0.9989\n",
      "Epoch 103/200\n",
      " - 30s - loss: 0.7171 - auc: 0.9896 - val_loss: 0.3525 - val_auc: 0.9986\n",
      "Epoch 104/200\n",
      " - 30s - loss: 0.7413 - auc: 0.9887 - val_loss: 0.3602 - val_auc: 0.9985\n",
      "Epoch 105/200\n",
      " - 30s - loss: 0.7306 - auc: 0.9895 - val_loss: 0.3572 - val_auc: 0.9985\n",
      "Epoch 106/200\n",
      " - 30s - loss: 0.7018 - auc: 0.9901 - val_loss: 0.3244 - val_auc: 0.9989\n",
      "Epoch 107/200\n",
      " - 30s - loss: 0.7332 - auc: 0.9882 - val_loss: 0.3229 - val_auc: 0.9989\n",
      "Epoch 108/200\n",
      " - 30s - loss: 0.7165 - auc: 0.9894 - val_loss: 0.3306 - val_auc: 0.9989\n",
      "Epoch 109/200\n",
      " - 30s - loss: 0.6928 - auc: 0.9901 - val_loss: 0.3103 - val_auc: 0.9990\n",
      "Epoch 110/200\n",
      " - 30s - loss: 0.7177 - auc: 0.9890 - val_loss: 0.3145 - val_auc: 0.9990\n",
      "Epoch 111/200\n",
      " - 30s - loss: 0.6836 - auc: 0.9902 - val_loss: 0.3459 - val_auc: 0.9986\n",
      "Epoch 112/200\n",
      " - 30s - loss: 0.7057 - auc: 0.9891 - val_loss: 0.3455 - val_auc: 0.9989\n",
      "Epoch 113/200\n",
      " - 30s - loss: 0.6828 - auc: 0.9913 - val_loss: 0.3115 - val_auc: 0.9991\n",
      "Epoch 114/200\n",
      " - 30s - loss: 0.7123 - auc: 0.9886 - val_loss: 0.3264 - val_auc: 0.9988\n",
      "Epoch 115/200\n",
      " - 30s - loss: 0.7215 - auc: 0.9888 - val_loss: 0.3565 - val_auc: 0.9984\n",
      "Epoch 116/200\n",
      " - 30s - loss: 0.6852 - auc: 0.9900 - val_loss: 0.3314 - val_auc: 0.9988\n",
      "Epoch 117/200\n",
      " - 30s - loss: 0.6802 - auc: 0.9912 - val_loss: 0.3109 - val_auc: 0.9990\n",
      "Epoch 118/200\n",
      " - 30s - loss: 0.7108 - auc: 0.9900 - val_loss: 0.3297 - val_auc: 0.9988\n",
      "Epoch 119/200\n",
      " - 30s - loss: 0.6840 - auc: 0.9899 - val_loss: 0.3391 - val_auc: 0.9986\n",
      "Epoch 120/200\n",
      " - 30s - loss: 0.7065 - auc: 0.9890 - val_loss: 0.3390 - val_auc: 0.9986\n",
      "Epoch 121/200\n",
      " - 30s - loss: 0.7183 - auc: 0.9896 - val_loss: 0.3570 - val_auc: 0.9986\n",
      "Epoch 122/200\n",
      " - 30s - loss: 0.7057 - auc: 0.9890 - val_loss: 0.3531 - val_auc: 0.9986\n",
      "Epoch 123/200\n",
      " - 30s - loss: 0.7189 - auc: 0.9897 - val_loss: 0.3292 - val_auc: 0.9989\n",
      "Epoch 124/200\n",
      " - 30s - loss: 0.7012 - auc: 0.9902 - val_loss: 0.3267 - val_auc: 0.9989\n",
      "Epoch 125/200\n",
      " - 30s - loss: 0.7046 - auc: 0.9892 - val_loss: 0.3371 - val_auc: 0.9985\n",
      "Epoch 126/200\n",
      " - 30s - loss: 0.6808 - auc: 0.9902 - val_loss: 0.3674 - val_auc: 0.9986\n",
      "Epoch 127/200\n",
      " - 30s - loss: 0.6965 - auc: 0.9899 - val_loss: 0.3234 - val_auc: 0.9989\n",
      "Epoch 128/200\n",
      " - 30s - loss: 0.6824 - auc: 0.9909 - val_loss: 0.3083 - val_auc: 0.9992\n",
      "Epoch 129/200\n",
      " - 30s - loss: 0.7077 - auc: 0.9898 - val_loss: 0.3163 - val_auc: 0.9990\n",
      "Epoch 130/200\n",
      " - 30s - loss: 0.7224 - auc: 0.9890 - val_loss: 0.3560 - val_auc: 0.9984\n",
      "Epoch 131/200\n",
      " - 30s - loss: 0.7043 - auc: 0.9899 - val_loss: 0.3288 - val_auc: 0.9989\n",
      "Epoch 132/200\n",
      " - 30s - loss: 0.7302 - auc: 0.9884 - val_loss: 0.3070 - val_auc: 0.9991\n",
      "Epoch 133/200\n",
      " - 30s - loss: 0.6886 - auc: 0.9894 - val_loss: 0.3366 - val_auc: 0.9988\n",
      "Epoch 134/200\n",
      " - 30s - loss: 0.6706 - auc: 0.9904 - val_loss: 0.3007 - val_auc: 0.9991\n",
      "Epoch 135/200\n",
      " - 30s - loss: 0.6662 - auc: 0.9916 - val_loss: 0.3079 - val_auc: 0.9991\n",
      "Epoch 136/200\n",
      " - 30s - loss: 0.7083 - auc: 0.9896 - val_loss: 0.3582 - val_auc: 0.9985\n",
      "Epoch 137/200\n",
      " - 30s - loss: 0.6922 - auc: 0.9899 - val_loss: 0.3230 - val_auc: 0.9989\n",
      "Epoch 138/200\n",
      " - 30s - loss: 0.6946 - auc: 0.9894 - val_loss: 0.3437 - val_auc: 0.9988\n",
      "Epoch 139/200\n",
      " - 30s - loss: 0.6937 - auc: 0.9898 - val_loss: 0.2979 - val_auc: 0.9993\n",
      "Epoch 140/200\n",
      " - 30s - loss: 0.6812 - auc: 0.9911 - val_loss: 0.3124 - val_auc: 0.9990\n",
      "Epoch 141/200\n",
      " - 30s - loss: 0.6919 - auc: 0.9895 - val_loss: 0.3290 - val_auc: 0.9987\n",
      "Epoch 142/200\n",
      " - 30s - loss: 0.6914 - auc: 0.9897 - val_loss: 0.2924 - val_auc: 0.9992\n",
      "Epoch 143/200\n",
      " - 30s - loss: 0.6768 - auc: 0.9903 - val_loss: 0.3016 - val_auc: 0.9990\n",
      "Epoch 144/200\n",
      " - 30s - loss: 0.6778 - auc: 0.9907 - val_loss: 0.3070 - val_auc: 0.9990\n",
      "Epoch 145/200\n",
      " - 30s - loss: 0.6698 - auc: 0.9911 - val_loss: 0.3406 - val_auc: 0.9987\n",
      "Epoch 146/200\n",
      " - 30s - loss: 0.6669 - auc: 0.9900 - val_loss: 0.3312 - val_auc: 0.9986\n",
      "Epoch 147/200\n",
      " - 30s - loss: 0.6929 - auc: 0.9898 - val_loss: 0.3087 - val_auc: 0.9990\n",
      "Epoch 148/200\n",
      " - 30s - loss: 0.6984 - auc: 0.9902 - val_loss: 0.3333 - val_auc: 0.9989\n",
      "Epoch 149/200\n",
      " - 30s - loss: 0.7018 - auc: 0.9901 - val_loss: 0.3206 - val_auc: 0.9988\n",
      "Epoch 150/200\n",
      " - 30s - loss: 0.6566 - auc: 0.9905 - val_loss: 0.3571 - val_auc: 0.9985\n",
      "Epoch 151/200\n",
      " - 30s - loss: 0.7089 - auc: 0.9903 - val_loss: 0.3226 - val_auc: 0.9989\n",
      "Epoch 152/200\n",
      " - 30s - loss: 0.7238 - auc: 0.9890 - val_loss: 0.3335 - val_auc: 0.9989\n",
      "Epoch 153/200\n",
      " - 30s - loss: 0.7040 - auc: 0.9896 - val_loss: 0.3610 - val_auc: 0.9986\n",
      "Epoch 154/200\n",
      " - 30s - loss: 0.6763 - auc: 0.9893 - val_loss: 0.3106 - val_auc: 0.9990\n",
      "Epoch 155/200\n",
      " - 30s - loss: 0.6999 - auc: 0.9896 - val_loss: 0.3728 - val_auc: 0.9982\n",
      "Epoch 156/200\n",
      " - 30s - loss: 0.6650 - auc: 0.9906 - val_loss: 0.3273 - val_auc: 0.9989\n",
      "Epoch 157/200\n",
      " - 30s - loss: 0.6808 - auc: 0.9904 - val_loss: 0.3186 - val_auc: 0.9990\n",
      "Epoch 158/200\n",
      " - 30s - loss: 0.6951 - auc: 0.9893 - val_loss: 0.2916 - val_auc: 0.9992\n",
      "Epoch 159/200\n",
      " - 29s - loss: 0.6718 - auc: 0.9903 - val_loss: 0.3019 - val_auc: 0.9990\n",
      "Epoch 160/200\n",
      " - 29s - loss: 0.6694 - auc: 0.9905 - val_loss: 0.2945 - val_auc: 0.9991\n",
      "Epoch 161/200\n",
      " - 29s - loss: 0.6714 - auc: 0.9896 - val_loss: 0.3288 - val_auc: 0.9986\n",
      "Epoch 162/200\n",
      " - 30s - loss: 0.6893 - auc: 0.9903 - val_loss: 0.3163 - val_auc: 0.9989\n",
      "Epoch 163/200\n",
      " - 30s - loss: 0.6503 - auc: 0.9913 - val_loss: 0.3336 - val_auc: 0.9988\n",
      "Epoch 164/200\n",
      " - 30s - loss: 0.6674 - auc: 0.9909 - val_loss: 0.2967 - val_auc: 0.9991\n",
      "Epoch 165/200\n",
      " - 30s - loss: 0.6868 - auc: 0.9905 - val_loss: 0.2834 - val_auc: 0.9993\n",
      "Epoch 166/200\n",
      " - 30s - loss: 0.6847 - auc: 0.9906 - val_loss: 0.2997 - val_auc: 0.9991\n",
      "Epoch 167/200\n",
      " - 30s - loss: 0.6966 - auc: 0.9894 - val_loss: 0.3210 - val_auc: 0.9990\n",
      "Epoch 168/200\n",
      " - 30s - loss: 0.6906 - auc: 0.9899 - val_loss: 0.3359 - val_auc: 0.9987\n",
      "Epoch 169/200\n",
      " - 30s - loss: 0.6792 - auc: 0.9907 - val_loss: 0.3159 - val_auc: 0.9990\n",
      "Epoch 170/200\n",
      " - 30s - loss: 0.6704 - auc: 0.9900 - val_loss: 0.2992 - val_auc: 0.9991\n",
      "Epoch 171/200\n",
      " - 30s - loss: 0.6792 - auc: 0.9907 - val_loss: 0.3300 - val_auc: 0.9988\n",
      "Epoch 172/200\n",
      " - 30s - loss: 0.6902 - auc: 0.9893 - val_loss: 0.3295 - val_auc: 0.9987\n",
      "Epoch 173/200\n",
      " - 30s - loss: 0.6810 - auc: 0.9907 - val_loss: 0.3202 - val_auc: 0.9989\n",
      "Epoch 174/200\n",
      " - 30s - loss: 0.6849 - auc: 0.9901 - val_loss: 0.3105 - val_auc: 0.9991\n",
      "Epoch 175/200\n",
      " - 30s - loss: 0.6726 - auc: 0.9901 - val_loss: 0.3161 - val_auc: 0.9991\n",
      "Epoch 176/200\n",
      " - 30s - loss: 0.6689 - auc: 0.9900 - val_loss: 0.3054 - val_auc: 0.9991\n",
      "Epoch 177/200\n",
      " - 30s - loss: 0.6665 - auc: 0.9907 - val_loss: 0.3232 - val_auc: 0.9990\n",
      "Epoch 178/200\n",
      " - 30s - loss: 0.7110 - auc: 0.9896 - val_loss: 0.2886 - val_auc: 0.9991\n",
      "Epoch 179/200\n",
      " - 30s - loss: 0.6945 - auc: 0.9888 - val_loss: 0.3339 - val_auc: 0.9989\n",
      "Epoch 180/200\n",
      " - 30s - loss: 0.6551 - auc: 0.9904 - val_loss: 0.3181 - val_auc: 0.9989\n",
      "Epoch 181/200\n",
      " - 30s - loss: 0.6581 - auc: 0.9905 - val_loss: 0.3033 - val_auc: 0.9991\n",
      "Epoch 182/200\n",
      " - 30s - loss: 0.7139 - auc: 0.9894 - val_loss: 0.3125 - val_auc: 0.9989\n",
      "Epoch 183/200\n",
      " - 30s - loss: 0.6844 - auc: 0.9900 - val_loss: 0.3314 - val_auc: 0.9988\n",
      "Epoch 184/200\n",
      " - 30s - loss: 0.6602 - auc: 0.9909 - val_loss: 0.2984 - val_auc: 0.9990\n",
      "Epoch 185/200\n",
      " - 30s - loss: 0.6607 - auc: 0.9913 - val_loss: 0.3163 - val_auc: 0.9989\n",
      "Epoch 186/200\n",
      " - 30s - loss: 0.7055 - auc: 0.9894 - val_loss: 0.3227 - val_auc: 0.9989\n",
      "Epoch 187/200\n",
      " - 30s - loss: 0.6790 - auc: 0.9908 - val_loss: 0.3520 - val_auc: 0.9985\n",
      "Epoch 188/200\n",
      " - 30s - loss: 0.6737 - auc: 0.9900 - val_loss: 0.3193 - val_auc: 0.9988\n",
      "Epoch 189/200\n",
      " - 30s - loss: 0.6749 - auc: 0.9893 - val_loss: 0.3275 - val_auc: 0.9989\n",
      "Epoch 190/200\n",
      " - 30s - loss: 0.6768 - auc: 0.9906 - val_loss: 0.3018 - val_auc: 0.9992\n",
      "Epoch 191/200\n",
      " - 30s - loss: 0.6895 - auc: 0.9902 - val_loss: 0.3425 - val_auc: 0.9985\n",
      "Epoch 192/200\n",
      " - 30s - loss: 0.6627 - auc: 0.9912 - val_loss: 0.3042 - val_auc: 0.9990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/200\n",
      " - 30s - loss: 0.6614 - auc: 0.9907 - val_loss: 0.3083 - val_auc: 0.9990\n",
      "Epoch 194/200\n",
      " - 30s - loss: 0.6615 - auc: 0.9911 - val_loss: 0.3654 - val_auc: 0.9983\n",
      "Epoch 195/200\n",
      " - 30s - loss: 0.6639 - auc: 0.9911 - val_loss: 0.2830 - val_auc: 0.9991\n",
      "Epoch 196/200\n",
      " - 30s - loss: 0.7048 - auc: 0.9896 - val_loss: 0.3142 - val_auc: 0.9989\n",
      "Epoch 197/200\n",
      " - 30s - loss: 0.6662 - auc: 0.9905 - val_loss: 0.3113 - val_auc: 0.9989\n",
      "Epoch 198/200\n",
      " - 30s - loss: 0.6640 - auc: 0.9906 - val_loss: 0.3016 - val_auc: 0.9992\n",
      "Epoch 199/200\n",
      " - 30s - loss: 0.6793 - auc: 0.9891 - val_loss: 0.3141 - val_auc: 0.9990\n",
      "Epoch 200/200\n",
      " - 30s - loss: 0.6484 - auc: 0.9905 - val_loss: 0.2938 - val_auc: 0.9991\n",
      "ROS,MIT-BIH Arrhythmia Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keg/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:80: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5872 samples, validate on 715 samples\n",
      "Epoch 1/200\n",
      " - 65s - loss: 2.0358 - auc: 0.9144 - val_loss: 1.0283 - val_auc: 0.9856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keg/anaconda3/lib/python3.6/site-packages/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `roc_accuracy` which is not available. Available metrics are: val_loss,val_auc,loss,auc,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200\n",
      " - 30s - loss: 1.4718 - auc: 0.9651 - val_loss: 0.8280 - val_auc: 0.9889\n",
      "Epoch 3/200\n",
      " - 30s - loss: 1.3548 - auc: 0.9699 - val_loss: 0.7320 - val_auc: 0.9916\n",
      "Epoch 4/200\n",
      " - 30s - loss: 1.2266 - auc: 0.9752 - val_loss: 0.6830 - val_auc: 0.9930\n",
      "Epoch 5/200\n",
      " - 30s - loss: 1.2159 - auc: 0.9752 - val_loss: 0.6468 - val_auc: 0.9932\n",
      "Epoch 6/200\n",
      " - 30s - loss: 1.1417 - auc: 0.9773 - val_loss: 0.6414 - val_auc: 0.9915\n",
      "Epoch 7/200\n",
      " - 30s - loss: 1.1141 - auc: 0.9790 - val_loss: 0.5950 - val_auc: 0.9940\n",
      "Epoch 8/200\n",
      " - 30s - loss: 1.1008 - auc: 0.9792 - val_loss: 0.6223 - val_auc: 0.9933\n",
      "Epoch 9/200\n",
      " - 30s - loss: 1.0859 - auc: 0.9787 - val_loss: 0.5781 - val_auc: 0.9934\n",
      "Epoch 10/200\n",
      " - 30s - loss: 1.0630 - auc: 0.9804 - val_loss: 0.5399 - val_auc: 0.9948\n",
      "Epoch 11/200\n",
      " - 30s - loss: 1.0506 - auc: 0.9804 - val_loss: 0.5593 - val_auc: 0.9949\n",
      "Epoch 12/200\n",
      " - 30s - loss: 1.0228 - auc: 0.9823 - val_loss: 0.5351 - val_auc: 0.9952\n",
      "Epoch 13/200\n",
      " - 30s - loss: 1.0031 - auc: 0.9817 - val_loss: 0.5527 - val_auc: 0.9926\n",
      "Epoch 14/200\n",
      " - 30s - loss: 1.0327 - auc: 0.9809 - val_loss: 0.5412 - val_auc: 0.9950\n",
      "Epoch 15/200\n",
      " - 30s - loss: 0.9751 - auc: 0.9830 - val_loss: 0.5034 - val_auc: 0.9954\n",
      "Epoch 16/200\n",
      " - 30s - loss: 1.0118 - auc: 0.9802 - val_loss: 0.5242 - val_auc: 0.9945\n",
      "Epoch 17/200\n",
      " - 30s - loss: 0.9743 - auc: 0.9834 - val_loss: 0.4880 - val_auc: 0.9947\n",
      "Epoch 18/200\n",
      " - 30s - loss: 0.9755 - auc: 0.9829 - val_loss: 0.5049 - val_auc: 0.9936\n",
      "Epoch 19/200\n",
      " - 30s - loss: 0.9286 - auc: 0.9852 - val_loss: 0.5230 - val_auc: 0.9932\n",
      "Epoch 20/200\n",
      " - 30s - loss: 0.9452 - auc: 0.9823 - val_loss: 0.4964 - val_auc: 0.9948\n",
      "Epoch 21/200\n",
      " - 30s - loss: 0.9327 - auc: 0.9833 - val_loss: 0.4931 - val_auc: 0.9955\n",
      "Epoch 22/200\n",
      " - 30s - loss: 0.9278 - auc: 0.9847 - val_loss: 0.4655 - val_auc: 0.9949\n",
      "Epoch 23/200\n",
      " - 30s - loss: 0.9156 - auc: 0.9836 - val_loss: 0.4511 - val_auc: 0.9938\n",
      "Epoch 24/200\n",
      " - 30s - loss: 0.9247 - auc: 0.9836 - val_loss: 0.4958 - val_auc: 0.9947\n",
      "Epoch 25/200\n",
      " - 30s - loss: 0.8968 - auc: 0.9846 - val_loss: 0.4777 - val_auc: 0.9945\n",
      "Epoch 26/200\n",
      " - 30s - loss: 0.9249 - auc: 0.9826 - val_loss: 0.4758 - val_auc: 0.9951\n",
      "Epoch 27/200\n",
      " - 30s - loss: 0.9083 - auc: 0.9855 - val_loss: 0.4702 - val_auc: 0.9949\n",
      "Epoch 28/200\n",
      " - 30s - loss: 0.8786 - auc: 0.9869 - val_loss: 0.4575 - val_auc: 0.9958\n",
      "Epoch 29/200\n",
      " - 30s - loss: 0.8680 - auc: 0.9853 - val_loss: 0.4728 - val_auc: 0.9957\n",
      "Epoch 30/200\n",
      " - 30s - loss: 0.8862 - auc: 0.9850 - val_loss: 0.4482 - val_auc: 0.9951\n",
      "Epoch 31/200\n",
      " - 30s - loss: 0.8792 - auc: 0.9858 - val_loss: 0.4233 - val_auc: 0.9965\n",
      "Epoch 32/200\n",
      " - 30s - loss: 0.8734 - auc: 0.9854 - val_loss: 0.4527 - val_auc: 0.9960\n",
      "Epoch 33/200\n",
      " - 30s - loss: 0.8697 - auc: 0.9856 - val_loss: 0.4534 - val_auc: 0.9962\n",
      "Epoch 34/200\n",
      " - 30s - loss: 0.8909 - auc: 0.9850 - val_loss: 0.4572 - val_auc: 0.9963\n",
      "Epoch 35/200\n",
      " - 30s - loss: 0.8497 - auc: 0.9862 - val_loss: 0.4552 - val_auc: 0.9960\n",
      "Epoch 36/200\n",
      " - 30s - loss: 0.8357 - auc: 0.9861 - val_loss: 0.4372 - val_auc: 0.9951\n",
      "Epoch 37/200\n",
      " - 30s - loss: 0.8649 - auc: 0.9851 - val_loss: 0.4426 - val_auc: 0.9960\n",
      "Epoch 38/200\n",
      " - 30s - loss: 0.8473 - auc: 0.9868 - val_loss: 0.4338 - val_auc: 0.9962\n",
      "Epoch 39/200\n",
      " - 30s - loss: 0.8479 - auc: 0.9871 - val_loss: 0.4353 - val_auc: 0.9963\n",
      "Epoch 40/200\n",
      " - 30s - loss: 0.8198 - auc: 0.9865 - val_loss: 0.4334 - val_auc: 0.9962\n",
      "Epoch 41/200\n",
      " - 30s - loss: 0.8400 - auc: 0.9872 - val_loss: 0.4307 - val_auc: 0.9962\n",
      "Epoch 42/200\n",
      " - 30s - loss: 0.8701 - auc: 0.9860 - val_loss: 0.4161 - val_auc: 0.9966\n",
      "Epoch 43/200\n",
      " - 30s - loss: 0.8548 - auc: 0.9862 - val_loss: 0.4308 - val_auc: 0.9964\n",
      "Epoch 44/200\n",
      " - 30s - loss: 0.8262 - auc: 0.9876 - val_loss: 0.4175 - val_auc: 0.9965\n",
      "Epoch 45/200\n",
      " - 30s - loss: 0.8219 - auc: 0.9859 - val_loss: 0.4062 - val_auc: 0.9955\n",
      "Epoch 46/200\n",
      " - 30s - loss: 0.8435 - auc: 0.9861 - val_loss: 0.4327 - val_auc: 0.9963\n",
      "Epoch 47/200\n",
      " - 30s - loss: 0.8097 - auc: 0.9883 - val_loss: 0.4305 - val_auc: 0.9952\n",
      "Epoch 48/200\n",
      " - 30s - loss: 0.8318 - auc: 0.9857 - val_loss: 0.4121 - val_auc: 0.9962\n",
      "Epoch 49/200\n",
      " - 30s - loss: 0.8277 - auc: 0.9872 - val_loss: 0.4063 - val_auc: 0.9954\n",
      "Epoch 50/200\n",
      " - 30s - loss: 0.8210 - auc: 0.9873 - val_loss: 0.4375 - val_auc: 0.9963\n",
      "Epoch 51/200\n",
      " - 30s - loss: 0.8369 - auc: 0.9857 - val_loss: 0.4466 - val_auc: 0.9960\n",
      "Epoch 52/200\n",
      " - 30s - loss: 0.8055 - auc: 0.9874 - val_loss: 0.3990 - val_auc: 0.9966\n",
      "Epoch 53/200\n",
      " - 30s - loss: 0.7814 - auc: 0.9864 - val_loss: 0.4055 - val_auc: 0.9967\n",
      "Epoch 54/200\n",
      " - 30s - loss: 0.8184 - auc: 0.9860 - val_loss: 0.4145 - val_auc: 0.9964\n",
      "Epoch 55/200\n",
      " - 30s - loss: 0.7910 - auc: 0.9881 - val_loss: 0.4034 - val_auc: 0.9965\n",
      "Epoch 56/200\n",
      " - 30s - loss: 0.8270 - auc: 0.9861 - val_loss: 0.3989 - val_auc: 0.9966\n",
      "Epoch 57/200\n",
      " - 30s - loss: 0.7966 - auc: 0.9874 - val_loss: 0.3922 - val_auc: 0.9968\n",
      "Epoch 58/200\n",
      " - 30s - loss: 0.8286 - auc: 0.9862 - val_loss: 0.4041 - val_auc: 0.9966\n",
      "Epoch 59/200\n",
      " - 30s - loss: 0.7925 - auc: 0.9880 - val_loss: 0.4072 - val_auc: 0.9964\n",
      "Epoch 60/200\n",
      " - 30s - loss: 0.7806 - auc: 0.9883 - val_loss: 0.4187 - val_auc: 0.9964\n",
      "Epoch 61/200\n",
      " - 30s - loss: 0.7931 - auc: 0.9870 - val_loss: 0.4087 - val_auc: 0.9965\n",
      "Epoch 62/200\n",
      " - 30s - loss: 0.7794 - auc: 0.9887 - val_loss: 0.4189 - val_auc: 0.9963\n",
      "Epoch 63/200\n",
      " - 30s - loss: 0.7943 - auc: 0.9861 - val_loss: 0.4041 - val_auc: 0.9965\n",
      "Epoch 64/200\n",
      " - 30s - loss: 0.8003 - auc: 0.9877 - val_loss: 0.4159 - val_auc: 0.9964\n",
      "Epoch 65/200\n",
      " - 30s - loss: 0.7849 - auc: 0.9879 - val_loss: 0.3929 - val_auc: 0.9966\n",
      "Epoch 66/200\n",
      " - 30s - loss: 0.7776 - auc: 0.9880 - val_loss: 0.4096 - val_auc: 0.9965\n",
      "Epoch 67/200\n",
      " - 30s - loss: 0.7945 - auc: 0.9857 - val_loss: 0.3869 - val_auc: 0.9959\n",
      "Epoch 68/200\n",
      " - 30s - loss: 0.7834 - auc: 0.9881 - val_loss: 0.4174 - val_auc: 0.9965\n",
      "Epoch 69/200\n",
      " - 30s - loss: 0.8108 - auc: 0.9857 - val_loss: 0.4161 - val_auc: 0.9964\n",
      "Epoch 70/200\n",
      " - 30s - loss: 0.7622 - auc: 0.9895 - val_loss: 0.3868 - val_auc: 0.9968\n",
      "Epoch 71/200\n",
      " - 30s - loss: 0.7780 - auc: 0.9877 - val_loss: 0.4072 - val_auc: 0.9953\n",
      "Epoch 72/200\n",
      " - 30s - loss: 0.8001 - auc: 0.9865 - val_loss: 0.4025 - val_auc: 0.9967\n",
      "Epoch 73/200\n",
      " - 30s - loss: 0.7679 - auc: 0.9872 - val_loss: 0.4113 - val_auc: 0.9952\n",
      "Epoch 74/200\n",
      " - 30s - loss: 0.7621 - auc: 0.9879 - val_loss: 0.4001 - val_auc: 0.9966\n",
      "Epoch 75/200\n",
      " - 30s - loss: 0.7719 - auc: 0.9889 - val_loss: 0.4085 - val_auc: 0.9965\n",
      "Epoch 76/200\n",
      " - 30s - loss: 0.7666 - auc: 0.9885 - val_loss: 0.3968 - val_auc: 0.9967\n",
      "Epoch 77/200\n",
      " - 30s - loss: 0.7667 - auc: 0.9884 - val_loss: 0.3774 - val_auc: 0.9968\n",
      "Epoch 78/200\n",
      " - 30s - loss: 0.7691 - auc: 0.9887 - val_loss: 0.3945 - val_auc: 0.9955\n",
      "Epoch 79/200\n",
      " - 30s - loss: 0.7700 - auc: 0.9876 - val_loss: 0.3958 - val_auc: 0.9966\n",
      "Epoch 80/200\n",
      " - 30s - loss: 0.7573 - auc: 0.9877 - val_loss: 0.3884 - val_auc: 0.9966\n",
      "Epoch 81/200\n",
      " - 30s - loss: 0.7892 - auc: 0.9868 - val_loss: 0.3836 - val_auc: 0.9968\n",
      "Epoch 82/200\n",
      " - 30s - loss: 0.7536 - auc: 0.9881 - val_loss: 0.3863 - val_auc: 0.9968\n",
      "Epoch 83/200\n",
      " - 30s - loss: 0.7748 - auc: 0.9871 - val_loss: 0.3689 - val_auc: 0.9968\n",
      "Epoch 84/200\n",
      " - 30s - loss: 0.7541 - auc: 0.9878 - val_loss: 0.3992 - val_auc: 0.9965\n",
      "Epoch 85/200\n",
      " - 30s - loss: 0.7337 - auc: 0.9894 - val_loss: 0.4057 - val_auc: 0.9963\n",
      "Epoch 86/200\n",
      " - 30s - loss: 0.7475 - auc: 0.9893 - val_loss: 0.3721 - val_auc: 0.9980\n",
      "Epoch 87/200\n",
      " - 30s - loss: 0.7722 - auc: 0.9888 - val_loss: 0.4059 - val_auc: 0.9952\n",
      "Epoch 88/200\n",
      " - 30s - loss: 0.7508 - auc: 0.9889 - val_loss: 0.3880 - val_auc: 0.9965\n",
      "Epoch 89/200\n",
      " - 30s - loss: 0.7728 - auc: 0.9889 - val_loss: 0.3885 - val_auc: 0.9968\n",
      "Epoch 90/200\n",
      " - 30s - loss: 0.7656 - auc: 0.9867 - val_loss: 0.3920 - val_auc: 0.9967\n",
      "Epoch 91/200\n",
      " - 30s - loss: 0.7578 - auc: 0.9879 - val_loss: 0.3630 - val_auc: 0.9971\n",
      "Epoch 92/200\n",
      " - 30s - loss: 0.7682 - auc: 0.9880 - val_loss: 0.4139 - val_auc: 0.9963\n",
      "Epoch 93/200\n",
      " - 30s - loss: 0.7590 - auc: 0.9891 - val_loss: 0.3995 - val_auc: 0.9967\n",
      "Epoch 94/200\n",
      " - 30s - loss: 0.7610 - auc: 0.9890 - val_loss: 0.3716 - val_auc: 0.9967\n",
      "Epoch 95/200\n",
      " - 30s - loss: 0.7522 - auc: 0.9879 - val_loss: 0.3870 - val_auc: 0.9968\n",
      "Epoch 96/200\n",
      " - 30s - loss: 0.7388 - auc: 0.9889 - val_loss: 0.3843 - val_auc: 0.9965\n",
      "Epoch 97/200\n",
      " - 30s - loss: 0.7478 - auc: 0.9887 - val_loss: 0.3848 - val_auc: 0.9955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/200\n",
      " - 30s - loss: 0.7252 - auc: 0.9890 - val_loss: 0.3625 - val_auc: 0.9970\n",
      "Epoch 99/200\n",
      " - 30s - loss: 0.7473 - auc: 0.9877 - val_loss: 0.4029 - val_auc: 0.9966\n",
      "Epoch 100/200\n",
      " - 30s - loss: 0.7661 - auc: 0.9887 - val_loss: 0.3829 - val_auc: 0.9966\n",
      "Epoch 101/200\n",
      " - 30s - loss: 0.7509 - auc: 0.9887 - val_loss: 0.4089 - val_auc: 0.9965\n",
      "Epoch 102/200\n",
      " - 30s - loss: 0.7401 - auc: 0.9889 - val_loss: 0.3645 - val_auc: 0.9969\n",
      "Epoch 103/200\n",
      " - 30s - loss: 0.7168 - auc: 0.9887 - val_loss: 0.3957 - val_auc: 0.9965\n",
      "Epoch 104/200\n",
      " - 30s - loss: 0.7483 - auc: 0.9886 - val_loss: 0.3686 - val_auc: 0.9969\n",
      "Epoch 105/200\n",
      " - 30s - loss: 0.7458 - auc: 0.9877 - val_loss: 0.3512 - val_auc: 0.9970\n",
      "Epoch 106/200\n",
      " - 30s - loss: 0.7448 - auc: 0.9894 - val_loss: 0.3779 - val_auc: 0.9968\n",
      "Epoch 107/200\n",
      " - 29s - loss: 0.7248 - auc: 0.9902 - val_loss: 0.3553 - val_auc: 0.9971\n",
      "Epoch 108/200\n",
      " - 30s - loss: 0.7475 - auc: 0.9882 - val_loss: 0.3830 - val_auc: 0.9967\n",
      "Epoch 109/200\n",
      " - 30s - loss: 0.7285 - auc: 0.9894 - val_loss: 0.3651 - val_auc: 0.9969\n",
      "Epoch 110/200\n",
      " - 30s - loss: 0.7389 - auc: 0.9892 - val_loss: 0.3688 - val_auc: 0.9968\n",
      "Epoch 111/200\n",
      " - 30s - loss: 0.7329 - auc: 0.9879 - val_loss: 0.3724 - val_auc: 0.9967\n",
      "Epoch 112/200\n",
      " - 30s - loss: 0.7493 - auc: 0.9885 - val_loss: 0.3598 - val_auc: 0.9971\n",
      "Epoch 113/200\n",
      " - 30s - loss: 0.7442 - auc: 0.9880 - val_loss: 0.3695 - val_auc: 0.9969\n",
      "Epoch 114/200\n",
      " - 30s - loss: 0.7337 - auc: 0.9886 - val_loss: 0.3599 - val_auc: 0.9971\n",
      "Epoch 115/200\n",
      " - 30s - loss: 0.7343 - auc: 0.9898 - val_loss: 0.4032 - val_auc: 0.9977\n",
      "Epoch 116/200\n",
      " - 30s - loss: 0.7559 - auc: 0.9886 - val_loss: 0.3888 - val_auc: 0.9967\n",
      "Epoch 117/200\n",
      " - 30s - loss: 0.7347 - auc: 0.9895 - val_loss: 0.3639 - val_auc: 0.9981\n",
      "Epoch 118/200\n",
      " - 30s - loss: 0.7645 - auc: 0.9870 - val_loss: 0.3517 - val_auc: 0.9983\n",
      "Epoch 119/200\n",
      " - 30s - loss: 0.7252 - auc: 0.9894 - val_loss: 0.3585 - val_auc: 0.9983\n",
      "Epoch 120/200\n",
      " - 30s - loss: 0.7196 - auc: 0.9893 - val_loss: 0.3442 - val_auc: 0.9984\n",
      "Epoch 121/200\n",
      " - 30s - loss: 0.7487 - auc: 0.9884 - val_loss: 0.3691 - val_auc: 0.9980\n",
      "Epoch 122/200\n",
      " - 30s - loss: 0.7416 - auc: 0.9886 - val_loss: 0.3683 - val_auc: 0.9982\n",
      "Epoch 123/200\n",
      " - 30s - loss: 0.6846 - auc: 0.9915 - val_loss: 0.3570 - val_auc: 0.9971\n",
      "Epoch 124/200\n",
      " - 30s - loss: 0.7443 - auc: 0.9878 - val_loss: 0.3726 - val_auc: 0.9980\n",
      "Epoch 125/200\n",
      " - 30s - loss: 0.7122 - auc: 0.9895 - val_loss: 0.3533 - val_auc: 0.9970\n",
      "Epoch 126/200\n",
      " - 30s - loss: 0.7087 - auc: 0.9897 - val_loss: 0.3383 - val_auc: 0.9973\n",
      "Epoch 127/200\n",
      " - 30s - loss: 0.7246 - auc: 0.9884 - val_loss: 0.3442 - val_auc: 0.9983\n",
      "Epoch 128/200\n",
      " - 30s - loss: 0.7020 - auc: 0.9898 - val_loss: 0.3473 - val_auc: 0.9982\n",
      "Epoch 129/200\n",
      " - 30s - loss: 0.7283 - auc: 0.9895 - val_loss: 0.3423 - val_auc: 0.9972\n",
      "Epoch 130/200\n",
      " - 30s - loss: 0.7238 - auc: 0.9885 - val_loss: 0.3557 - val_auc: 0.9969\n",
      "Epoch 131/200\n",
      " - 29s - loss: 0.7593 - auc: 0.9877 - val_loss: 0.3449 - val_auc: 0.9982\n",
      "Epoch 132/200\n",
      " - 30s - loss: 0.7233 - auc: 0.9885 - val_loss: 0.3566 - val_auc: 0.9982\n",
      "Epoch 133/200\n",
      " - 30s - loss: 0.7329 - auc: 0.9888 - val_loss: 0.3581 - val_auc: 0.9970\n",
      "Epoch 134/200\n",
      " - 30s - loss: 0.7289 - auc: 0.9884 - val_loss: 0.3523 - val_auc: 0.9982\n",
      "Epoch 135/200\n",
      " - 30s - loss: 0.7147 - auc: 0.9883 - val_loss: 0.3897 - val_auc: 0.9978\n",
      "Epoch 136/200\n",
      " - 30s - loss: 0.6688 - auc: 0.9916 - val_loss: 0.3524 - val_auc: 0.9982\n",
      "Epoch 137/200\n",
      " - 30s - loss: 0.7508 - auc: 0.9877 - val_loss: 0.3488 - val_auc: 0.9980\n",
      "Epoch 138/200\n",
      " - 30s - loss: 0.7198 - auc: 0.9879 - val_loss: 0.3542 - val_auc: 0.9970\n",
      "Epoch 139/200\n",
      " - 30s - loss: 0.7100 - auc: 0.9886 - val_loss: 0.3684 - val_auc: 0.9970\n",
      "Epoch 140/200\n",
      " - 30s - loss: 0.7210 - auc: 0.9886 - val_loss: 0.3681 - val_auc: 0.9980\n",
      "Epoch 141/200\n",
      " - 30s - loss: 0.7219 - auc: 0.9881 - val_loss: 0.3857 - val_auc: 0.9978\n",
      "Epoch 142/200\n",
      " - 30s - loss: 0.7093 - auc: 0.9894 - val_loss: 0.3428 - val_auc: 0.9983\n",
      "Epoch 143/200\n",
      " - 29s - loss: 0.7180 - auc: 0.9886 - val_loss: 0.3866 - val_auc: 0.9978\n",
      "Epoch 144/200\n",
      " - 30s - loss: 0.7347 - auc: 0.9866 - val_loss: 0.3852 - val_auc: 0.9980\n",
      "Epoch 145/200\n",
      " - 30s - loss: 0.7252 - auc: 0.9890 - val_loss: 0.3510 - val_auc: 0.9984\n",
      "Epoch 146/200\n",
      " - 30s - loss: 0.6937 - auc: 0.9900 - val_loss: 0.3694 - val_auc: 0.9980\n",
      "Epoch 147/200\n",
      " - 30s - loss: 0.7306 - auc: 0.9889 - val_loss: 0.3754 - val_auc: 0.9969\n",
      "Epoch 148/200\n",
      " - 30s - loss: 0.6979 - auc: 0.9888 - val_loss: 0.3605 - val_auc: 0.9980\n",
      "Epoch 149/200\n",
      " - 30s - loss: 0.7213 - auc: 0.9896 - val_loss: 0.3698 - val_auc: 0.9979\n",
      "Epoch 150/200\n",
      " - 30s - loss: 0.7158 - auc: 0.9896 - val_loss: 0.3490 - val_auc: 0.9982\n",
      "Epoch 151/200\n",
      " - 30s - loss: 0.6879 - auc: 0.9901 - val_loss: 0.3537 - val_auc: 0.9981\n",
      "Epoch 152/200\n",
      " - 30s - loss: 0.7389 - auc: 0.9888 - val_loss: 0.3605 - val_auc: 0.9983\n",
      "Epoch 153/200\n",
      " - 30s - loss: 0.7069 - auc: 0.9898 - val_loss: 0.3706 - val_auc: 0.9981\n",
      "Epoch 154/200\n",
      " - 29s - loss: 0.6916 - auc: 0.9890 - val_loss: 0.3425 - val_auc: 0.9983\n",
      "Epoch 155/200\n",
      " - 29s - loss: 0.7115 - auc: 0.9892 - val_loss: 0.3497 - val_auc: 0.9983\n",
      "Epoch 156/200\n",
      " - 29s - loss: 0.7113 - auc: 0.9891 - val_loss: 0.3486 - val_auc: 0.9982\n",
      "Epoch 157/200\n",
      " - 30s - loss: 0.6923 - auc: 0.9889 - val_loss: 0.3424 - val_auc: 0.9983\n",
      "Epoch 158/200\n",
      " - 29s - loss: 0.7056 - auc: 0.9880 - val_loss: 0.3504 - val_auc: 0.9982\n",
      "Epoch 159/200\n",
      " - 30s - loss: 0.7070 - auc: 0.9898 - val_loss: 0.3385 - val_auc: 0.9985\n",
      "Epoch 160/200\n",
      " - 30s - loss: 0.6958 - auc: 0.9899 - val_loss: 0.3668 - val_auc: 0.9980\n",
      "Epoch 161/200\n",
      " - 30s - loss: 0.7416 - auc: 0.9874 - val_loss: 0.3326 - val_auc: 0.9984\n",
      "Epoch 162/200\n",
      " - 30s - loss: 0.7159 - auc: 0.9889 - val_loss: 0.3667 - val_auc: 0.9979\n",
      "Epoch 163/200\n",
      " - 30s - loss: 0.7078 - auc: 0.9888 - val_loss: 0.3509 - val_auc: 0.9984\n",
      "Epoch 164/200\n",
      " - 30s - loss: 0.6694 - auc: 0.9904 - val_loss: 0.3361 - val_auc: 0.9983\n",
      "Epoch 165/200\n",
      " - 30s - loss: 0.6968 - auc: 0.9911 - val_loss: 0.3548 - val_auc: 0.9982\n",
      "Epoch 166/200\n",
      " - 30s - loss: 0.6994 - auc: 0.9897 - val_loss: 0.3710 - val_auc: 0.9980\n",
      "Epoch 167/200\n",
      " - 30s - loss: 0.7117 - auc: 0.9901 - val_loss: 0.3516 - val_auc: 0.9982\n",
      "Epoch 168/200\n",
      " - 30s - loss: 0.6859 - auc: 0.9901 - val_loss: 0.3238 - val_auc: 0.9986\n",
      "Epoch 169/200\n",
      " - 30s - loss: 0.6917 - auc: 0.9908 - val_loss: 0.3329 - val_auc: 0.9985\n",
      "Epoch 170/200\n",
      " - 30s - loss: 0.7186 - auc: 0.9896 - val_loss: 0.3535 - val_auc: 0.9982\n",
      "Epoch 171/200\n",
      " - 30s - loss: 0.7126 - auc: 0.9894 - val_loss: 0.3542 - val_auc: 0.9981\n",
      "Epoch 172/200\n",
      " - 30s - loss: 0.6808 - auc: 0.9893 - val_loss: 0.3197 - val_auc: 0.9987\n",
      "Epoch 173/200\n",
      " - 30s - loss: 0.6953 - auc: 0.9891 - val_loss: 0.3086 - val_auc: 0.9988\n",
      "Epoch 174/200\n",
      " - 30s - loss: 0.7181 - auc: 0.9890 - val_loss: 0.3654 - val_auc: 0.9980\n",
      "Epoch 175/200\n",
      " - 30s - loss: 0.6871 - auc: 0.9914 - val_loss: 0.3603 - val_auc: 0.9982\n",
      "Epoch 176/200\n",
      " - 30s - loss: 0.6863 - auc: 0.9908 - val_loss: 0.3704 - val_auc: 0.9980\n",
      "Epoch 177/200\n",
      " - 30s - loss: 0.6968 - auc: 0.9892 - val_loss: 0.3233 - val_auc: 0.9986\n",
      "Epoch 178/200\n",
      " - 30s - loss: 0.7302 - auc: 0.9891 - val_loss: 0.3672 - val_auc: 0.9982\n",
      "Epoch 179/200\n",
      " - 30s - loss: 0.6979 - auc: 0.9889 - val_loss: 0.3302 - val_auc: 0.9984\n",
      "Epoch 180/200\n",
      " - 30s - loss: 0.7115 - auc: 0.9885 - val_loss: 0.3836 - val_auc: 0.9977\n",
      "Epoch 181/200\n",
      " - 30s - loss: 0.6723 - auc: 0.9910 - val_loss: 0.3690 - val_auc: 0.9980\n",
      "Epoch 182/200\n",
      " - 30s - loss: 0.7141 - auc: 0.9905 - val_loss: 0.3537 - val_auc: 0.9982\n",
      "Epoch 183/200\n",
      " - 30s - loss: 0.6980 - auc: 0.9900 - val_loss: 0.3752 - val_auc: 0.9981\n",
      "Epoch 184/200\n",
      " - 30s - loss: 0.6690 - auc: 0.9907 - val_loss: 0.3758 - val_auc: 0.9978\n",
      "Epoch 185/200\n",
      " - 30s - loss: 0.7236 - auc: 0.9868 - val_loss: 0.3368 - val_auc: 0.9985\n",
      "Epoch 186/200\n",
      " - 30s - loss: 0.6913 - auc: 0.9913 - val_loss: 0.3331 - val_auc: 0.9984\n",
      "Epoch 187/200\n",
      " - 30s - loss: 0.6961 - auc: 0.9903 - val_loss: 0.3346 - val_auc: 0.9985\n",
      "Epoch 188/200\n",
      " - 30s - loss: 0.7009 - auc: 0.9886 - val_loss: 0.3444 - val_auc: 0.9985\n",
      "Epoch 189/200\n",
      " - 30s - loss: 0.6809 - auc: 0.9898 - val_loss: 0.3452 - val_auc: 0.9983\n",
      "Epoch 190/200\n",
      " - 30s - loss: 0.6571 - auc: 0.9909 - val_loss: 0.3666 - val_auc: 0.9980\n",
      "Epoch 191/200\n",
      " - 30s - loss: 0.6966 - auc: 0.9881 - val_loss: 0.3765 - val_auc: 0.9980\n",
      "Epoch 192/200\n",
      " - 30s - loss: 0.6970 - auc: 0.9891 - val_loss: 0.3622 - val_auc: 0.9979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/200\n",
      " - 30s - loss: 0.7006 - auc: 0.9891 - val_loss: 0.3353 - val_auc: 0.9985\n",
      "Epoch 194/200\n",
      " - 30s - loss: 0.7079 - auc: 0.9873 - val_loss: 0.3442 - val_auc: 0.9983\n",
      "Epoch 195/200\n",
      " - 30s - loss: 0.6622 - auc: 0.9904 - val_loss: 0.3401 - val_auc: 0.9985\n",
      "Epoch 196/200\n",
      " - 30s - loss: 0.6986 - auc: 0.9890 - val_loss: 0.3448 - val_auc: 0.9983\n",
      "Epoch 197/200\n",
      " - 30s - loss: 0.7189 - auc: 0.9906 - val_loss: 0.3444 - val_auc: 0.9984\n",
      "Epoch 198/200\n",
      " - 30s - loss: 0.6818 - auc: 0.9891 - val_loss: 0.3308 - val_auc: 0.9984\n",
      "Epoch 199/200\n",
      " - 29s - loss: 0.7133 - auc: 0.9893 - val_loss: 0.3458 - val_auc: 0.9984\n",
      "Epoch 200/200\n",
      " - 30s - loss: 0.6919 - auc: 0.9911 - val_loss: 0.3402 - val_auc: 0.9984\n",
      "BorderlineSMOTE,MIT-BIH Arrhythmia Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keg/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:80: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5661 samples, validate on 715 samples\n",
      "Epoch 1/200\n",
      " - 65s - loss: 1.9411 - auc: 0.9189 - val_loss: 0.8587 - val_auc: 0.9898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keg/anaconda3/lib/python3.6/site-packages/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `roc_accuracy` which is not available. Available metrics are: val_loss,val_auc,loss,auc,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200\n",
      " - 29s - loss: 1.3626 - auc: 0.9672 - val_loss: 0.6735 - val_auc: 0.9901\n",
      "Epoch 3/200\n",
      " - 29s - loss: 1.2281 - auc: 0.9723 - val_loss: 0.6198 - val_auc: 0.9915\n",
      "Epoch 4/200\n",
      " - 29s - loss: 1.1519 - auc: 0.9758 - val_loss: 0.5709 - val_auc: 0.9936\n",
      "Epoch 5/200\n",
      " - 29s - loss: 1.0767 - auc: 0.9779 - val_loss: 0.5362 - val_auc: 0.9942\n",
      "Epoch 6/200\n",
      " - 29s - loss: 1.0577 - auc: 0.9772 - val_loss: 0.5546 - val_auc: 0.9952\n",
      "Epoch 7/200\n",
      " - 29s - loss: 1.0281 - auc: 0.9786 - val_loss: 0.5434 - val_auc: 0.9949\n",
      "Epoch 8/200\n",
      " - 29s - loss: 1.0015 - auc: 0.9807 - val_loss: 0.5327 - val_auc: 0.9951\n",
      "Epoch 9/200\n",
      " - 29s - loss: 0.9584 - auc: 0.9816 - val_loss: 0.4632 - val_auc: 0.9961\n",
      "Epoch 10/200\n",
      " - 29s - loss: 0.9961 - auc: 0.9793 - val_loss: 0.4781 - val_auc: 0.9962\n",
      "Epoch 11/200\n",
      " - 29s - loss: 0.9840 - auc: 0.9801 - val_loss: 0.4879 - val_auc: 0.9958\n",
      "Epoch 12/200\n",
      " - 29s - loss: 0.9531 - auc: 0.9818 - val_loss: 0.4890 - val_auc: 0.9957\n",
      "Epoch 13/200\n",
      " - 29s - loss: 0.9320 - auc: 0.9830 - val_loss: 0.4700 - val_auc: 0.9959\n",
      "Epoch 14/200\n",
      " - 29s - loss: 0.9270 - auc: 0.9830 - val_loss: 0.4724 - val_auc: 0.9948\n",
      "Epoch 15/200\n",
      " - 29s - loss: 0.9047 - auc: 0.9825 - val_loss: 0.4398 - val_auc: 0.9965\n",
      "Epoch 16/200\n",
      " - 29s - loss: 0.9172 - auc: 0.9836 - val_loss: 0.4365 - val_auc: 0.9956\n",
      "Epoch 17/200\n",
      " - 29s - loss: 0.8872 - auc: 0.9834 - val_loss: 0.4506 - val_auc: 0.9962\n",
      "Epoch 18/200\n",
      " - 29s - loss: 0.9003 - auc: 0.9827 - val_loss: 0.4432 - val_auc: 0.9952\n",
      "Epoch 19/200\n",
      " - 29s - loss: 0.8588 - auc: 0.9860 - val_loss: 0.4379 - val_auc: 0.9964\n",
      "Epoch 20/200\n",
      " - 29s - loss: 0.8865 - auc: 0.9836 - val_loss: 0.4148 - val_auc: 0.9966\n",
      "Epoch 21/200\n",
      " - 29s - loss: 0.8523 - auc: 0.9841 - val_loss: 0.3983 - val_auc: 0.9969\n",
      "Epoch 22/200\n",
      " - 29s - loss: 0.8667 - auc: 0.9831 - val_loss: 0.3967 - val_auc: 0.9970\n",
      "Epoch 23/200\n",
      " - 29s - loss: 0.8369 - auc: 0.9850 - val_loss: 0.4054 - val_auc: 0.9956\n",
      "Epoch 24/200\n",
      " - 29s - loss: 0.8385 - auc: 0.9839 - val_loss: 0.4477 - val_auc: 0.9963\n",
      "Epoch 25/200\n",
      " - 29s - loss: 0.8213 - auc: 0.9848 - val_loss: 0.3991 - val_auc: 0.9958\n",
      "Epoch 26/200\n",
      " - 29s - loss: 0.8243 - auc: 0.9840 - val_loss: 0.3643 - val_auc: 0.9975\n",
      "Epoch 27/200\n",
      " - 29s - loss: 0.8054 - auc: 0.9862 - val_loss: 0.3871 - val_auc: 0.9970\n",
      "Epoch 28/200\n",
      " - 29s - loss: 0.8324 - auc: 0.9856 - val_loss: 0.4013 - val_auc: 0.9968\n",
      "Epoch 29/200\n",
      " - 29s - loss: 0.8072 - auc: 0.9859 - val_loss: 0.3928 - val_auc: 0.9971\n",
      "Epoch 30/200\n",
      " - 29s - loss: 0.7962 - auc: 0.9848 - val_loss: 0.3783 - val_auc: 0.9959\n",
      "Epoch 31/200\n",
      " - 29s - loss: 0.8065 - auc: 0.9855 - val_loss: 0.3756 - val_auc: 0.9972\n",
      "Epoch 32/200\n",
      " - 29s - loss: 0.8022 - auc: 0.9861 - val_loss: 0.3683 - val_auc: 0.9971\n",
      "Epoch 33/200\n",
      " - 29s - loss: 0.7693 - auc: 0.9867 - val_loss: 0.3552 - val_auc: 0.9972\n",
      "Epoch 34/200\n",
      " - 29s - loss: 0.7760 - auc: 0.9859 - val_loss: 0.3915 - val_auc: 0.9969\n",
      "Epoch 35/200\n",
      " - 29s - loss: 0.7797 - auc: 0.9869 - val_loss: 0.3990 - val_auc: 0.9967\n",
      "Epoch 36/200\n",
      " - 29s - loss: 0.8000 - auc: 0.9854 - val_loss: 0.3718 - val_auc: 0.9971\n",
      "Epoch 37/200\n",
      " - 29s - loss: 0.8149 - auc: 0.9829 - val_loss: 0.3695 - val_auc: 0.9971\n",
      "Epoch 38/200\n",
      " - 29s - loss: 0.7853 - auc: 0.9874 - val_loss: 0.3884 - val_auc: 0.9969\n",
      "Epoch 39/200\n",
      " - 29s - loss: 0.7708 - auc: 0.9866 - val_loss: 0.3588 - val_auc: 0.9973\n",
      "Epoch 40/200\n",
      " - 29s - loss: 0.7723 - auc: 0.9854 - val_loss: 0.3879 - val_auc: 0.9971\n",
      "Epoch 41/200\n",
      " - 29s - loss: 0.7736 - auc: 0.9864 - val_loss: 0.3287 - val_auc: 0.9976\n",
      "Epoch 42/200\n",
      " - 29s - loss: 0.7814 - auc: 0.9877 - val_loss: 0.4000 - val_auc: 0.9968\n",
      "Epoch 43/200\n",
      " - 29s - loss: 0.7696 - auc: 0.9870 - val_loss: 0.3819 - val_auc: 0.9970\n",
      "Epoch 44/200\n",
      " - 29s - loss: 0.7608 - auc: 0.9884 - val_loss: 0.3934 - val_auc: 0.9971\n",
      "Epoch 45/200\n",
      " - 29s - loss: 0.7604 - auc: 0.9881 - val_loss: 0.3833 - val_auc: 0.9969\n",
      "Epoch 46/200\n",
      " - 29s - loss: 0.7612 - auc: 0.9865 - val_loss: 0.3662 - val_auc: 0.9973\n",
      "Epoch 47/200\n",
      " - 29s - loss: 0.7266 - auc: 0.9894 - val_loss: 0.3536 - val_auc: 0.9973\n",
      "Epoch 48/200\n",
      " - 29s - loss: 0.7397 - auc: 0.9876 - val_loss: 0.3664 - val_auc: 0.9970\n",
      "Epoch 49/200\n",
      " - 29s - loss: 0.7453 - auc: 0.9876 - val_loss: 0.3533 - val_auc: 0.9975\n",
      "Epoch 50/200\n",
      " - 29s - loss: 0.7489 - auc: 0.9868 - val_loss: 0.3724 - val_auc: 0.9971\n",
      "Epoch 51/200\n",
      " - 29s - loss: 0.7314 - auc: 0.9875 - val_loss: 0.3416 - val_auc: 0.9975\n",
      "Epoch 52/200\n",
      " - 29s - loss: 0.7563 - auc: 0.9864 - val_loss: 0.3681 - val_auc: 0.9974\n",
      "Epoch 53/200\n",
      " - 29s - loss: 0.7291 - auc: 0.9885 - val_loss: 0.3717 - val_auc: 0.9972\n",
      "Epoch 54/200\n",
      " - 29s - loss: 0.7341 - auc: 0.9876 - val_loss: 0.3875 - val_auc: 0.9972\n",
      "Epoch 55/200\n",
      " - 29s - loss: 0.7389 - auc: 0.9886 - val_loss: 0.3366 - val_auc: 0.9976\n",
      "Epoch 56/200\n",
      " - 29s - loss: 0.7165 - auc: 0.9892 - val_loss: 0.3522 - val_auc: 0.9972\n",
      "Epoch 57/200\n",
      " - 29s - loss: 0.7255 - auc: 0.9875 - val_loss: 0.3613 - val_auc: 0.9972\n",
      "Epoch 58/200\n",
      " - 29s - loss: 0.7527 - auc: 0.9875 - val_loss: 0.3702 - val_auc: 0.9971\n",
      "Epoch 59/200\n",
      " - 29s - loss: 0.7365 - auc: 0.9882 - val_loss: 0.3776 - val_auc: 0.9972\n",
      "Epoch 60/200\n",
      " - 29s - loss: 0.7298 - auc: 0.9873 - val_loss: 0.3753 - val_auc: 0.9971\n",
      "Epoch 61/200\n",
      " - 29s - loss: 0.7228 - auc: 0.9877 - val_loss: 0.3724 - val_auc: 0.9970\n",
      "Epoch 62/200\n",
      " - 29s - loss: 0.7031 - auc: 0.9879 - val_loss: 0.3512 - val_auc: 0.9974\n",
      "Epoch 63/200\n",
      " - 29s - loss: 0.7218 - auc: 0.9887 - val_loss: 0.3737 - val_auc: 0.9971\n",
      "Epoch 64/200\n",
      " - 29s - loss: 0.6968 - auc: 0.9891 - val_loss: 0.3576 - val_auc: 0.9971\n",
      "Epoch 65/200\n",
      " - 29s - loss: 0.6966 - auc: 0.9905 - val_loss: 0.3467 - val_auc: 0.9974\n",
      "Epoch 66/200\n",
      " - 29s - loss: 0.6942 - auc: 0.9898 - val_loss: 0.3129 - val_auc: 0.9977\n",
      "Epoch 67/200\n",
      " - 29s - loss: 0.7270 - auc: 0.9875 - val_loss: 0.3608 - val_auc: 0.9973\n",
      "Epoch 68/200\n",
      " - 29s - loss: 0.7461 - auc: 0.9862 - val_loss: 0.3476 - val_auc: 0.9974\n",
      "Epoch 69/200\n",
      " - 29s - loss: 0.7127 - auc: 0.9886 - val_loss: 0.3500 - val_auc: 0.9973\n",
      "Epoch 70/200\n",
      " - 29s - loss: 0.7082 - auc: 0.9886 - val_loss: 0.3560 - val_auc: 0.9972\n",
      "Epoch 71/200\n",
      " - 29s - loss: 0.7275 - auc: 0.9868 - val_loss: 0.3437 - val_auc: 0.9974\n",
      "Epoch 72/200\n",
      " - 29s - loss: 0.7070 - auc: 0.9902 - val_loss: 0.3365 - val_auc: 0.9975\n",
      "Epoch 73/200\n",
      " - 29s - loss: 0.7180 - auc: 0.9888 - val_loss: 0.3651 - val_auc: 0.9972\n",
      "Epoch 74/200\n",
      " - 29s - loss: 0.6956 - auc: 0.9895 - val_loss: 0.3641 - val_auc: 0.9972\n",
      "Epoch 75/200\n",
      " - 29s - loss: 0.7060 - auc: 0.9877 - val_loss: 0.3573 - val_auc: 0.9972\n",
      "Epoch 76/200\n",
      " - 29s - loss: 0.7064 - auc: 0.9895 - val_loss: 0.4260 - val_auc: 0.9965\n",
      "Epoch 77/200\n",
      " - 29s - loss: 0.7057 - auc: 0.9875 - val_loss: 0.3678 - val_auc: 0.9971\n",
      "Epoch 78/200\n",
      " - 29s - loss: 0.6935 - auc: 0.9888 - val_loss: 0.3627 - val_auc: 0.9973\n",
      "Epoch 79/200\n",
      " - 29s - loss: 0.6966 - auc: 0.9892 - val_loss: 0.3738 - val_auc: 0.9972\n",
      "Epoch 80/200\n",
      " - 29s - loss: 0.6812 - auc: 0.9893 - val_loss: 0.3547 - val_auc: 0.9975\n",
      "Epoch 81/200\n",
      " - 29s - loss: 0.6858 - auc: 0.9893 - val_loss: 0.3306 - val_auc: 0.9976\n",
      "Epoch 82/200\n",
      " - 29s - loss: 0.6975 - auc: 0.9871 - val_loss: 0.3494 - val_auc: 0.9976\n",
      "Epoch 83/200\n",
      " - 29s - loss: 0.6786 - auc: 0.9874 - val_loss: 0.3672 - val_auc: 0.9973\n",
      "Epoch 84/200\n",
      " - 29s - loss: 0.7013 - auc: 0.9875 - val_loss: 0.3742 - val_auc: 0.9971\n",
      "Epoch 85/200\n",
      " - 29s - loss: 0.6688 - auc: 0.9888 - val_loss: 0.3694 - val_auc: 0.9973\n",
      "Epoch 86/200\n",
      " - 29s - loss: 0.6893 - auc: 0.9891 - val_loss: 0.3685 - val_auc: 0.9973\n",
      "Epoch 87/200\n",
      " - 29s - loss: 0.6777 - auc: 0.9901 - val_loss: 0.3446 - val_auc: 0.9975\n",
      "Epoch 88/200\n",
      " - 29s - loss: 0.6713 - auc: 0.9905 - val_loss: 0.3436 - val_auc: 0.9976\n",
      "Epoch 89/200\n",
      " - 29s - loss: 0.6888 - auc: 0.9892 - val_loss: 0.3702 - val_auc: 0.9972\n",
      "Epoch 90/200\n",
      " - 29s - loss: 0.6642 - auc: 0.9890 - val_loss: 0.3559 - val_auc: 0.9971\n",
      "Epoch 91/200\n",
      " - 29s - loss: 0.6759 - auc: 0.9893 - val_loss: 0.3529 - val_auc: 0.9974\n",
      "Epoch 92/200\n",
      " - 29s - loss: 0.6727 - auc: 0.9892 - val_loss: 0.3355 - val_auc: 0.9975\n",
      "Epoch 93/200\n",
      " - 29s - loss: 0.6834 - auc: 0.9890 - val_loss: 0.3780 - val_auc: 0.9971\n",
      "Epoch 94/200\n",
      " - 29s - loss: 0.7092 - auc: 0.9882 - val_loss: 0.3790 - val_auc: 0.9971\n",
      "Epoch 95/200\n",
      " - 29s - loss: 0.6659 - auc: 0.9898 - val_loss: 0.3435 - val_auc: 0.9975\n",
      "Epoch 96/200\n",
      " - 29s - loss: 0.6722 - auc: 0.9889 - val_loss: 0.3726 - val_auc: 0.9972\n",
      "Epoch 97/200\n",
      " - 29s - loss: 0.6598 - auc: 0.9892 - val_loss: 0.3425 - val_auc: 0.9975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/200\n",
      " - 29s - loss: 0.6876 - auc: 0.9884 - val_loss: 0.3404 - val_auc: 0.9976\n",
      "Epoch 99/200\n",
      " - 29s - loss: 0.6657 - auc: 0.9906 - val_loss: 0.3491 - val_auc: 0.9976\n",
      "Epoch 100/200\n",
      " - 29s - loss: 0.6631 - auc: 0.9902 - val_loss: 0.3610 - val_auc: 0.9974\n",
      "Epoch 101/200\n",
      " - 29s - loss: 0.6720 - auc: 0.9900 - val_loss: 0.3567 - val_auc: 0.9973\n",
      "Epoch 102/200\n",
      " - 29s - loss: 0.7088 - auc: 0.9880 - val_loss: 0.3601 - val_auc: 0.9973\n",
      "Epoch 103/200\n",
      " - 29s - loss: 0.6836 - auc: 0.9875 - val_loss: 0.3268 - val_auc: 0.9976\n",
      "Epoch 104/200\n",
      " - 29s - loss: 0.6898 - auc: 0.9899 - val_loss: 0.3422 - val_auc: 0.9974\n",
      "Epoch 105/200\n",
      " - 29s - loss: 0.6692 - auc: 0.9905 - val_loss: 0.3388 - val_auc: 0.9976\n",
      "Epoch 106/200\n",
      " - 29s - loss: 0.6910 - auc: 0.9894 - val_loss: 0.3922 - val_auc: 0.9969\n",
      "Epoch 107/200\n",
      " - 29s - loss: 0.6649 - auc: 0.9892 - val_loss: 0.3461 - val_auc: 0.9974\n",
      "Epoch 108/200\n",
      " - 29s - loss: 0.6677 - auc: 0.9898 - val_loss: 0.3156 - val_auc: 0.9976\n",
      "Epoch 109/200\n",
      " - 29s - loss: 0.6737 - auc: 0.9899 - val_loss: 0.3538 - val_auc: 0.9973\n",
      "Epoch 110/200\n",
      " - 29s - loss: 0.6608 - auc: 0.9912 - val_loss: 0.3595 - val_auc: 0.9972\n",
      "Epoch 111/200\n",
      " - 29s - loss: 0.6855 - auc: 0.9881 - val_loss: 0.3641 - val_auc: 0.9971\n",
      "Epoch 112/200\n",
      " - 29s - loss: 0.6740 - auc: 0.9903 - val_loss: 0.3406 - val_auc: 0.9975\n",
      "Epoch 113/200\n",
      " - 29s - loss: 0.6444 - auc: 0.9897 - val_loss: 0.3511 - val_auc: 0.9974\n",
      "Epoch 114/200\n",
      " - 29s - loss: 0.6282 - auc: 0.9901 - val_loss: 0.3212 - val_auc: 0.9976\n",
      "Epoch 115/200\n",
      " - 29s - loss: 0.6517 - auc: 0.9898 - val_loss: 0.3663 - val_auc: 0.9972\n",
      "Epoch 116/200\n",
      " - 29s - loss: 0.6725 - auc: 0.9897 - val_loss: 0.3372 - val_auc: 0.9975\n",
      "Epoch 117/200\n",
      " - 29s - loss: 0.6547 - auc: 0.9912 - val_loss: 0.3243 - val_auc: 0.9976\n",
      "Epoch 118/200\n",
      " - 29s - loss: 0.6586 - auc: 0.9878 - val_loss: 0.3165 - val_auc: 0.9975\n",
      "Epoch 119/200\n",
      " - 29s - loss: 0.6671 - auc: 0.9893 - val_loss: 0.3417 - val_auc: 0.9975\n",
      "Epoch 120/200\n",
      " - 29s - loss: 0.6322 - auc: 0.9912 - val_loss: 0.3085 - val_auc: 0.9977\n",
      "Epoch 121/200\n",
      " - 29s - loss: 0.6767 - auc: 0.9906 - val_loss: 0.3673 - val_auc: 0.9972\n",
      "Epoch 122/200\n",
      " - 29s - loss: 0.6681 - auc: 0.9899 - val_loss: 0.3346 - val_auc: 0.9976\n",
      "Epoch 123/200\n",
      " - 29s - loss: 0.6461 - auc: 0.9908 - val_loss: 0.3275 - val_auc: 0.9976\n",
      "Epoch 124/200\n",
      " - 29s - loss: 0.6669 - auc: 0.9886 - val_loss: 0.3219 - val_auc: 0.9976\n",
      "Epoch 125/200\n",
      " - 29s - loss: 0.6740 - auc: 0.9889 - val_loss: 0.3644 - val_auc: 0.9973\n",
      "Epoch 126/200\n",
      " - 29s - loss: 0.6371 - auc: 0.9907 - val_loss: 0.3880 - val_auc: 0.9970\n",
      "Epoch 127/200\n",
      " - 29s - loss: 0.6402 - auc: 0.9899 - val_loss: 0.3365 - val_auc: 0.9975\n",
      "Epoch 128/200\n",
      " - 29s - loss: 0.6539 - auc: 0.9898 - val_loss: 0.3641 - val_auc: 0.9973\n",
      "Epoch 129/200\n",
      " - 29s - loss: 0.6746 - auc: 0.9909 - val_loss: 0.3542 - val_auc: 0.9973\n",
      "Epoch 130/200\n",
      " - 29s - loss: 0.6236 - auc: 0.9908 - val_loss: 0.3471 - val_auc: 0.9974\n",
      "Epoch 131/200\n",
      " - 29s - loss: 0.6428 - auc: 0.9910 - val_loss: 0.3426 - val_auc: 0.9976\n",
      "Epoch 132/200\n",
      " - 29s - loss: 0.6665 - auc: 0.9900 - val_loss: 0.3634 - val_auc: 0.9973\n",
      "Epoch 133/200\n",
      " - 29s - loss: 0.6277 - auc: 0.9910 - val_loss: 0.3596 - val_auc: 0.9971\n",
      "Epoch 134/200\n",
      " - 29s - loss: 0.6496 - auc: 0.9894 - val_loss: 0.3543 - val_auc: 0.9972\n",
      "Epoch 135/200\n",
      " - 29s - loss: 0.6772 - auc: 0.9883 - val_loss: 0.3775 - val_auc: 0.9972\n",
      "Epoch 136/200\n",
      " - 29s - loss: 0.6537 - auc: 0.9907 - val_loss: 0.3729 - val_auc: 0.9971\n",
      "Epoch 137/200\n",
      " - 29s - loss: 0.6569 - auc: 0.9891 - val_loss: 0.3561 - val_auc: 0.9973\n",
      "Epoch 138/200\n",
      " - 29s - loss: 0.6188 - auc: 0.9894 - val_loss: 0.3640 - val_auc: 0.9972\n",
      "Epoch 139/200\n",
      " - 29s - loss: 0.6425 - auc: 0.9904 - val_loss: 0.3381 - val_auc: 0.9974\n",
      "Epoch 140/200\n",
      " - 29s - loss: 0.6744 - auc: 0.9889 - val_loss: 0.3441 - val_auc: 0.9974\n",
      "Epoch 141/200\n",
      " - 29s - loss: 0.6261 - auc: 0.9910 - val_loss: 0.3052 - val_auc: 0.9979\n",
      "Epoch 142/200\n",
      " - 29s - loss: 0.6268 - auc: 0.9892 - val_loss: 0.3683 - val_auc: 0.9970\n",
      "Epoch 143/200\n",
      " - 29s - loss: 0.6603 - auc: 0.9902 - val_loss: 0.3245 - val_auc: 0.9977\n",
      "Epoch 144/200\n",
      " - 29s - loss: 0.6626 - auc: 0.9904 - val_loss: 0.3236 - val_auc: 0.9975\n",
      "Epoch 145/200\n",
      " - 29s - loss: 0.6461 - auc: 0.9905 - val_loss: 0.3312 - val_auc: 0.9976\n",
      "Epoch 146/200\n",
      " - 29s - loss: 0.6378 - auc: 0.9910 - val_loss: 0.3538 - val_auc: 0.9973\n",
      "Epoch 147/200\n",
      " - 29s - loss: 0.6398 - auc: 0.9908 - val_loss: 0.3470 - val_auc: 0.9973\n",
      "Epoch 148/200\n",
      " - 29s - loss: 0.6472 - auc: 0.9894 - val_loss: 0.3067 - val_auc: 0.9979\n",
      "Epoch 149/200\n",
      " - 29s - loss: 0.6249 - auc: 0.9896 - val_loss: 0.3622 - val_auc: 0.9973\n",
      "Epoch 150/200\n",
      " - 29s - loss: 0.6598 - auc: 0.9909 - val_loss: 0.3402 - val_auc: 0.9975\n",
      "Epoch 151/200\n",
      " - 29s - loss: 0.6752 - auc: 0.9892 - val_loss: 0.3660 - val_auc: 0.9973\n",
      "Epoch 152/200\n",
      " - 29s - loss: 0.6228 - auc: 0.9901 - val_loss: 0.3449 - val_auc: 0.9973\n",
      "Epoch 153/200\n",
      " - 29s - loss: 0.6346 - auc: 0.9904 - val_loss: 0.3663 - val_auc: 0.9973\n",
      "Epoch 154/200\n",
      " - 29s - loss: 0.6587 - auc: 0.9893 - val_loss: 0.3361 - val_auc: 0.9976\n",
      "Epoch 155/200\n",
      " - 29s - loss: 0.6077 - auc: 0.9910 - val_loss: 0.3287 - val_auc: 0.9974\n",
      "Epoch 156/200\n",
      " - 29s - loss: 0.6229 - auc: 0.9921 - val_loss: 0.3482 - val_auc: 0.9974\n",
      "Epoch 157/200\n",
      " - 29s - loss: 0.6458 - auc: 0.9908 - val_loss: 0.3511 - val_auc: 0.9974\n",
      "Epoch 158/200\n",
      " - 29s - loss: 0.6138 - auc: 0.9908 - val_loss: 0.3454 - val_auc: 0.9974\n",
      "Epoch 159/200\n",
      " - 29s - loss: 0.6460 - auc: 0.9893 - val_loss: 0.3563 - val_auc: 0.9973\n",
      "Epoch 160/200\n",
      " - 29s - loss: 0.6588 - auc: 0.9884 - val_loss: 0.3622 - val_auc: 0.9972\n",
      "Epoch 161/200\n",
      " - 29s - loss: 0.6092 - auc: 0.9908 - val_loss: 0.3555 - val_auc: 0.9974\n",
      "Epoch 162/200\n",
      " - 28s - loss: 0.6387 - auc: 0.9911 - val_loss: 0.3194 - val_auc: 0.9977\n",
      "Epoch 163/200\n",
      " - 28s - loss: 0.6648 - auc: 0.9904 - val_loss: 0.3264 - val_auc: 0.9977\n",
      "Epoch 164/200\n",
      " - 29s - loss: 0.6293 - auc: 0.9896 - val_loss: 0.3367 - val_auc: 0.9976\n",
      "Epoch 165/200\n",
      " - 28s - loss: 0.6365 - auc: 0.9919 - val_loss: 0.3502 - val_auc: 0.9973\n",
      "Epoch 166/200\n",
      " - 29s - loss: 0.6327 - auc: 0.9890 - val_loss: 0.3197 - val_auc: 0.9977\n",
      "Epoch 167/200\n",
      " - 29s - loss: 0.6469 - auc: 0.9888 - val_loss: 0.3327 - val_auc: 0.9974\n",
      "Epoch 168/200\n",
      " - 29s - loss: 0.6231 - auc: 0.9907 - val_loss: 0.3700 - val_auc: 0.9971\n",
      "Epoch 169/200\n",
      " - 29s - loss: 0.6246 - auc: 0.9915 - val_loss: 0.3313 - val_auc: 0.9976\n",
      "Epoch 170/200\n",
      " - 29s - loss: 0.6266 - auc: 0.9910 - val_loss: 0.3220 - val_auc: 0.9977\n",
      "Epoch 171/200\n",
      " - 29s - loss: 0.6082 - auc: 0.9916 - val_loss: 0.3218 - val_auc: 0.9976\n",
      "Epoch 172/200\n",
      " - 29s - loss: 0.6379 - auc: 0.9899 - val_loss: 0.3457 - val_auc: 0.9973\n",
      "Epoch 173/200\n",
      " - 29s - loss: 0.6119 - auc: 0.9915 - val_loss: 0.3496 - val_auc: 0.9975\n",
      "Epoch 174/200\n",
      " - 29s - loss: 0.6296 - auc: 0.9891 - val_loss: 0.3638 - val_auc: 0.9974\n",
      "Epoch 175/200\n",
      " - 29s - loss: 0.6273 - auc: 0.9910 - val_loss: 0.3479 - val_auc: 0.9974\n",
      "Epoch 176/200\n",
      " - 29s - loss: 0.6228 - auc: 0.9912 - val_loss: 0.3515 - val_auc: 0.9974\n",
      "Epoch 177/200\n",
      " - 29s - loss: 0.6473 - auc: 0.9889 - val_loss: 0.3656 - val_auc: 0.9971\n",
      "Epoch 178/200\n",
      " - 29s - loss: 0.6181 - auc: 0.9911 - val_loss: 0.3764 - val_auc: 0.9972\n",
      "Epoch 179/200\n",
      " - 29s - loss: 0.6337 - auc: 0.9896 - val_loss: 0.3713 - val_auc: 0.9970\n",
      "Epoch 180/200\n",
      " - 29s - loss: 0.6286 - auc: 0.9905 - val_loss: 0.3808 - val_auc: 0.9970\n",
      "Epoch 181/200\n",
      " - 29s - loss: 0.6074 - auc: 0.9918 - val_loss: 0.3111 - val_auc: 0.9979\n",
      "Epoch 182/200\n",
      " - 29s - loss: 0.6118 - auc: 0.9918 - val_loss: 0.3342 - val_auc: 0.9975\n",
      "Epoch 183/200\n",
      " - 29s - loss: 0.6264 - auc: 0.9906 - val_loss: 0.3298 - val_auc: 0.9976\n",
      "Epoch 184/200\n",
      " - 29s - loss: 0.6150 - auc: 0.9900 - val_loss: 0.3524 - val_auc: 0.9973\n",
      "Epoch 185/200\n",
      " - 29s - loss: 0.6327 - auc: 0.9908 - val_loss: 0.3267 - val_auc: 0.9977\n",
      "Epoch 186/200\n",
      " - 29s - loss: 0.6380 - auc: 0.9895 - val_loss: 0.3340 - val_auc: 0.9976\n",
      "Epoch 187/200\n",
      " - 29s - loss: 0.5955 - auc: 0.9917 - val_loss: 0.3692 - val_auc: 0.9970\n",
      "Epoch 188/200\n",
      " - 29s - loss: 0.6362 - auc: 0.9901 - val_loss: 0.3433 - val_auc: 0.9975\n",
      "Epoch 189/200\n",
      " - 29s - loss: 0.6081 - auc: 0.9921 - val_loss: 0.3276 - val_auc: 0.9976\n",
      "Epoch 190/200\n",
      " - 29s - loss: 0.6577 - auc: 0.9899 - val_loss: 0.3707 - val_auc: 0.9972\n",
      "Epoch 191/200\n",
      " - 29s - loss: 0.6186 - auc: 0.9911 - val_loss: 0.3292 - val_auc: 0.9975\n",
      "Epoch 192/200\n",
      " - 29s - loss: 0.6281 - auc: 0.9912 - val_loss: 0.3244 - val_auc: 0.9976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/200\n",
      " - 29s - loss: 0.6347 - auc: 0.9900 - val_loss: 0.3428 - val_auc: 0.9975\n",
      "Epoch 194/200\n",
      " - 29s - loss: 0.6165 - auc: 0.9918 - val_loss: 0.3435 - val_auc: 0.9974\n",
      "Epoch 195/200\n",
      " - 29s - loss: 0.6025 - auc: 0.9921 - val_loss: 0.2984 - val_auc: 0.9979\n",
      "Epoch 196/200\n",
      " - 29s - loss: 0.6131 - auc: 0.9917 - val_loss: 0.3311 - val_auc: 0.9978\n",
      "Epoch 197/200\n",
      " - 29s - loss: 0.6473 - auc: 0.9899 - val_loss: 0.3015 - val_auc: 0.9979\n",
      "Epoch 198/200\n",
      " - 29s - loss: 0.6446 - auc: 0.9899 - val_loss: 0.3241 - val_auc: 0.9977\n",
      "Epoch 199/200\n",
      " - 29s - loss: 0.6020 - auc: 0.9920 - val_loss: 0.3440 - val_auc: 0.9977\n",
      "Epoch 200/200\n",
      " - 29s - loss: 0.6033 - auc: 0.9907 - val_loss: 0.3348 - val_auc: 0.9975\n",
      "SMOTETomek,MIT-BIH Arrhythmia Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keg/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:80: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1050 samples, validate on 263 samples\n",
      "Epoch 1/200\n",
      " - 43s - loss: 1.5946 - auc: 0.8917 - val_loss: 2.2155 - val_auc: 0.8685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keg/anaconda3/lib/python3.6/site-packages/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `roc_accuracy` which is not available. Available metrics are: val_loss,val_auc,loss,auc,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200\n",
      " - 6s - loss: 1.0237 - auc: 0.9610 - val_loss: 1.5772 - val_auc: 0.9378\n",
      "Epoch 3/200\n",
      " - 6s - loss: 0.9024 - auc: 0.9697 - val_loss: 0.8688 - val_auc: 0.9824\n",
      "Epoch 4/200\n",
      " - 5s - loss: 0.8457 - auc: 0.9729 - val_loss: 0.5939 - val_auc: 0.9852\n",
      "Epoch 5/200\n",
      " - 6s - loss: 0.7520 - auc: 0.9774 - val_loss: 0.4802 - val_auc: 0.9912\n",
      "Epoch 6/200\n",
      " - 5s - loss: 0.7447 - auc: 0.9770 - val_loss: 0.3921 - val_auc: 0.9920\n",
      "Epoch 7/200\n",
      " - 5s - loss: 0.7386 - auc: 0.9756 - val_loss: 0.4720 - val_auc: 0.9813\n",
      "Epoch 8/200\n",
      " - 5s - loss: 0.6383 - auc: 0.9838 - val_loss: 0.3789 - val_auc: 0.9911\n",
      "Epoch 9/200\n",
      " - 5s - loss: 0.6668 - auc: 0.9815 - val_loss: 0.3456 - val_auc: 0.9935\n",
      "Epoch 10/200\n",
      " - 5s - loss: 0.6184 - auc: 0.9831 - val_loss: 0.3907 - val_auc: 0.9876\n",
      "Epoch 11/200\n",
      " - 5s - loss: 0.6226 - auc: 0.9833 - val_loss: 0.3076 - val_auc: 0.9941\n",
      "Epoch 12/200\n",
      " - 5s - loss: 0.6274 - auc: 0.9834 - val_loss: 0.3124 - val_auc: 0.9941\n",
      "Epoch 13/200\n",
      " - 5s - loss: 0.5746 - auc: 0.9857 - val_loss: 0.3283 - val_auc: 0.9931\n",
      "Epoch 14/200\n",
      " - 5s - loss: 0.5956 - auc: 0.9850 - val_loss: 0.3190 - val_auc: 0.9935\n",
      "Epoch 15/200\n",
      " - 5s - loss: 0.5826 - auc: 0.9837 - val_loss: 0.3456 - val_auc: 0.9929\n",
      "Epoch 16/200\n",
      " - 5s - loss: 0.5238 - auc: 0.9872 - val_loss: 0.3122 - val_auc: 0.9940\n",
      "Epoch 17/200\n",
      " - 5s - loss: 0.5445 - auc: 0.9882 - val_loss: 0.2842 - val_auc: 0.9949\n",
      "Epoch 18/200\n",
      " - 5s - loss: 0.5880 - auc: 0.9850 - val_loss: 0.2935 - val_auc: 0.9944\n",
      "Epoch 19/200\n",
      " - 5s - loss: 0.5892 - auc: 0.9851 - val_loss: 0.2700 - val_auc: 0.9949\n",
      "Epoch 20/200\n",
      " - 5s - loss: 0.5895 - auc: 0.9838 - val_loss: 0.2610 - val_auc: 0.9954\n",
      "Epoch 21/200\n",
      " - 5s - loss: 0.5214 - auc: 0.9877 - val_loss: 0.2883 - val_auc: 0.9943\n",
      "Epoch 22/200\n",
      " - 5s - loss: 0.4923 - auc: 0.9893 - val_loss: 0.3279 - val_auc: 0.9930\n",
      "Epoch 23/200\n",
      " - 5s - loss: 0.5314 - auc: 0.9866 - val_loss: 0.3678 - val_auc: 0.9886\n",
      "Epoch 24/200\n",
      " - 6s - loss: 0.5009 - auc: 0.9892 - val_loss: 0.3180 - val_auc: 0.9929\n",
      "Epoch 25/200\n",
      " - 5s - loss: 0.5282 - auc: 0.9875 - val_loss: 0.2885 - val_auc: 0.9943\n",
      "Epoch 26/200\n",
      " - 6s - loss: 0.4897 - auc: 0.9895 - val_loss: 0.2767 - val_auc: 0.9944\n",
      "Epoch 27/200\n",
      " - 6s - loss: 0.4612 - auc: 0.9899 - val_loss: 0.3266 - val_auc: 0.9867\n",
      "Epoch 28/200\n",
      " - 5s - loss: 0.5150 - auc: 0.9866 - val_loss: 0.3003 - val_auc: 0.9936\n",
      "Epoch 29/200\n",
      " - 5s - loss: 0.4943 - auc: 0.9892 - val_loss: 0.2794 - val_auc: 0.9944\n",
      "Epoch 30/200\n",
      " - 6s - loss: 0.5295 - auc: 0.9865 - val_loss: 0.2851 - val_auc: 0.9942\n",
      "Epoch 31/200\n",
      " - 6s - loss: 0.5240 - auc: 0.9861 - val_loss: 0.2797 - val_auc: 0.9938\n",
      "Epoch 32/200\n",
      " - 6s - loss: 0.5200 - auc: 0.9867 - val_loss: 0.2941 - val_auc: 0.9964\n",
      "Epoch 33/200\n",
      " - 6s - loss: 0.4902 - auc: 0.9896 - val_loss: 0.2941 - val_auc: 0.9942\n",
      "Epoch 34/200\n",
      " - 6s - loss: 0.4872 - auc: 0.9872 - val_loss: 0.2516 - val_auc: 0.9981\n",
      "Epoch 35/200\n",
      " - 6s - loss: 0.4503 - auc: 0.9899 - val_loss: 0.2516 - val_auc: 0.9982\n",
      "Epoch 36/200\n",
      " - 6s - loss: 0.4562 - auc: 0.9909 - val_loss: 0.2523 - val_auc: 0.9945\n",
      "Epoch 37/200\n",
      " - 6s - loss: 0.4590 - auc: 0.9892 - val_loss: 0.3193 - val_auc: 0.9924\n",
      "Epoch 38/200\n",
      " - 6s - loss: 0.4620 - auc: 0.9900 - val_loss: 0.2847 - val_auc: 0.9968\n",
      "Epoch 39/200\n",
      " - 6s - loss: 0.4631 - auc: 0.9895 - val_loss: 0.2795 - val_auc: 0.9944\n",
      "Epoch 40/200\n",
      " - 6s - loss: 0.4665 - auc: 0.9901 - val_loss: 0.2938 - val_auc: 0.9874\n",
      "Epoch 41/200\n",
      " - 6s - loss: 0.4578 - auc: 0.9887 - val_loss: 0.2596 - val_auc: 0.9977\n",
      "Epoch 42/200\n",
      " - 6s - loss: 0.4581 - auc: 0.9900 - val_loss: 0.2350 - val_auc: 0.9951\n",
      "Epoch 43/200\n",
      " - 6s - loss: 0.5018 - auc: 0.9882 - val_loss: 0.2426 - val_auc: 0.9949\n",
      "Epoch 44/200\n",
      " - 6s - loss: 0.4561 - auc: 0.9896 - val_loss: 0.2817 - val_auc: 0.9945\n",
      "Epoch 45/200\n",
      " - 6s - loss: 0.4534 - auc: 0.9893 - val_loss: 0.2707 - val_auc: 0.9945\n",
      "Epoch 46/200\n",
      " - 6s - loss: 0.4534 - auc: 0.9882 - val_loss: 0.2775 - val_auc: 0.9940\n",
      "Epoch 47/200\n",
      " - 6s - loss: 0.4638 - auc: 0.9897 - val_loss: 0.2810 - val_auc: 0.9942\n",
      "Epoch 48/200\n",
      " - 6s - loss: 0.4508 - auc: 0.9892 - val_loss: 0.2625 - val_auc: 0.9972\n",
      "Epoch 49/200\n",
      " - 6s - loss: 0.4619 - auc: 0.9905 - val_loss: 0.2856 - val_auc: 0.9966\n",
      "Epoch 50/200\n",
      " - 6s - loss: 0.4159 - auc: 0.9916 - val_loss: 0.2601 - val_auc: 0.9975\n",
      "Epoch 51/200\n",
      " - 6s - loss: 0.4779 - auc: 0.9895 - val_loss: 0.2895 - val_auc: 0.9936\n",
      "Epoch 52/200\n",
      " - 6s - loss: 0.4864 - auc: 0.9867 - val_loss: 0.2944 - val_auc: 0.9932\n",
      "Epoch 53/200\n",
      " - 6s - loss: 0.4259 - auc: 0.9921 - val_loss: 0.2649 - val_auc: 0.9938\n",
      "Epoch 54/200\n",
      " - 6s - loss: 0.4370 - auc: 0.9912 - val_loss: 0.2183 - val_auc: 0.9987\n",
      "Epoch 55/200\n",
      " - 6s - loss: 0.4256 - auc: 0.9914 - val_loss: 0.2482 - val_auc: 0.9979\n",
      "Epoch 56/200\n",
      " - 6s - loss: 0.4355 - auc: 0.9901 - val_loss: 0.2217 - val_auc: 0.9956\n",
      "Epoch 57/200\n",
      " - 6s - loss: 0.4581 - auc: 0.9890 - val_loss: 0.2783 - val_auc: 0.9975\n",
      "Epoch 58/200\n",
      " - 6s - loss: 0.4071 - auc: 0.9933 - val_loss: 0.2410 - val_auc: 0.9950\n",
      "Epoch 59/200\n",
      " - 6s - loss: 0.4107 - auc: 0.9927 - val_loss: 0.2546 - val_auc: 0.9976\n",
      "Epoch 60/200\n",
      " - 6s - loss: 0.4707 - auc: 0.9878 - val_loss: 0.2321 - val_auc: 0.9985\n",
      "Epoch 61/200\n",
      " - 6s - loss: 0.3292 - auc: 0.9939 - val_loss: 0.2330 - val_auc: 0.9981\n",
      "Epoch 62/200\n",
      " - 6s - loss: 0.3721 - auc: 0.9917 - val_loss: 0.2738 - val_auc: 0.9940\n",
      "Epoch 63/200\n",
      " - 6s - loss: 0.4620 - auc: 0.9883 - val_loss: 0.1953 - val_auc: 0.9988\n",
      "Epoch 64/200\n",
      " - 6s - loss: 0.3907 - auc: 0.9919 - val_loss: 0.2399 - val_auc: 0.9979\n",
      "Epoch 65/200\n",
      " - 6s - loss: 0.3843 - auc: 0.9930 - val_loss: 0.1907 - val_auc: 0.9989\n",
      "Epoch 66/200\n",
      " - 6s - loss: 0.4258 - auc: 0.9903 - val_loss: 0.2337 - val_auc: 0.9947\n",
      "Epoch 67/200\n",
      " - 6s - loss: 0.4248 - auc: 0.9912 - val_loss: 0.2101 - val_auc: 0.9986\n",
      "Epoch 68/200\n",
      " - 6s - loss: 0.4297 - auc: 0.9911 - val_loss: 0.2742 - val_auc: 0.9977\n",
      "Epoch 69/200\n",
      " - 6s - loss: 0.4009 - auc: 0.9919 - val_loss: 0.2274 - val_auc: 0.9984\n",
      "Epoch 70/200\n",
      " - 6s - loss: 0.4247 - auc: 0.9903 - val_loss: 0.2400 - val_auc: 0.9945\n",
      "Epoch 71/200\n",
      " - 6s - loss: 0.3880 - auc: 0.9915 - val_loss: 0.2121 - val_auc: 0.9986\n",
      "Epoch 72/200\n",
      " - 6s - loss: 0.4207 - auc: 0.9928 - val_loss: 0.2200 - val_auc: 0.9951\n",
      "Epoch 73/200\n",
      " - 6s - loss: 0.3446 - auc: 0.9944 - val_loss: 0.1923 - val_auc: 0.9987\n",
      "Epoch 74/200\n",
      " - 6s - loss: 0.3622 - auc: 0.9925 - val_loss: 0.2183 - val_auc: 0.9952\n",
      "Epoch 75/200\n",
      " - 6s - loss: 0.4097 - auc: 0.9898 - val_loss: 0.2430 - val_auc: 0.9980\n",
      "Epoch 76/200\n",
      " - 6s - loss: 0.3987 - auc: 0.9926 - val_loss: 0.2061 - val_auc: 0.9987\n",
      "Epoch 77/200\n",
      " - 6s - loss: 0.3227 - auc: 0.9950 - val_loss: 0.2020 - val_auc: 0.9988\n",
      "Epoch 78/200\n",
      " - 6s - loss: 0.4472 - auc: 0.9899 - val_loss: 0.1911 - val_auc: 0.9990\n",
      "Epoch 79/200\n",
      " - 6s - loss: 0.3613 - auc: 0.9934 - val_loss: 0.2430 - val_auc: 0.9976\n",
      "Epoch 80/200\n",
      " - 6s - loss: 0.4115 - auc: 0.9932 - val_loss: 0.2046 - val_auc: 0.9984\n",
      "Epoch 81/200\n",
      " - 6s - loss: 0.4215 - auc: 0.9903 - val_loss: 0.1933 - val_auc: 0.9988\n",
      "Epoch 82/200\n",
      " - 6s - loss: 0.3814 - auc: 0.9932 - val_loss: 0.2156 - val_auc: 0.9984\n",
      "Epoch 83/200\n",
      " - 6s - loss: 0.3804 - auc: 0.9934 - val_loss: 0.1992 - val_auc: 0.9988\n",
      "Epoch 84/200\n",
      " - 6s - loss: 0.3668 - auc: 0.9930 - val_loss: 0.2190 - val_auc: 0.9983\n",
      "Epoch 85/200\n",
      " - 6s - loss: 0.3592 - auc: 0.9934 - val_loss: 0.1954 - val_auc: 0.9988\n",
      "Epoch 86/200\n",
      " - 6s - loss: 0.3588 - auc: 0.9945 - val_loss: 0.2099 - val_auc: 0.9988\n",
      "Epoch 87/200\n",
      " - 6s - loss: 0.3869 - auc: 0.9917 - val_loss: 0.2084 - val_auc: 0.9989\n",
      "Epoch 88/200\n",
      " - 6s - loss: 0.3823 - auc: 0.9915 - val_loss: 0.2238 - val_auc: 0.9984\n",
      "Epoch 89/200\n",
      " - 6s - loss: 0.3541 - auc: 0.9939 - val_loss: 0.2404 - val_auc: 0.9913\n",
      "Epoch 90/200\n",
      " - 6s - loss: 0.3962 - auc: 0.9926 - val_loss: 0.2383 - val_auc: 0.9980\n",
      "Epoch 91/200\n",
      " - 6s - loss: 0.4012 - auc: 0.9922 - val_loss: 0.2490 - val_auc: 0.9976\n",
      "Epoch 92/200\n",
      " - 6s - loss: 0.3938 - auc: 0.9911 - val_loss: 0.2351 - val_auc: 0.9979\n",
      "Epoch 93/200\n",
      " - 6s - loss: 0.4054 - auc: 0.9929 - val_loss: 0.2470 - val_auc: 0.9976\n",
      "Epoch 94/200\n",
      " - 6s - loss: 0.3892 - auc: 0.9917 - val_loss: 0.2405 - val_auc: 0.9980\n",
      "Epoch 95/200\n",
      " - 6s - loss: 0.3564 - auc: 0.9929 - val_loss: 0.2103 - val_auc: 0.9986\n",
      "Epoch 96/200\n",
      " - 6s - loss: 0.4016 - auc: 0.9904 - val_loss: 0.1987 - val_auc: 0.9987\n",
      "Epoch 97/200\n",
      " - 6s - loss: 0.3913 - auc: 0.9924 - val_loss: 0.2286 - val_auc: 0.9977\n",
      "Epoch 98/200\n",
      " - 6s - loss: 0.3744 - auc: 0.9930 - val_loss: 0.2102 - val_auc: 0.9982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/200\n",
      " - 6s - loss: 0.3949 - auc: 0.9920 - val_loss: 0.1899 - val_auc: 0.9989\n",
      "Epoch 100/200\n",
      " - 6s - loss: 0.3447 - auc: 0.9941 - val_loss: 0.1912 - val_auc: 0.9987\n",
      "Epoch 101/200\n",
      " - 6s - loss: 0.4214 - auc: 0.9903 - val_loss: 0.2016 - val_auc: 0.9987\n",
      "Epoch 102/200\n",
      " - 6s - loss: 0.3714 - auc: 0.9938 - val_loss: 0.1851 - val_auc: 0.9992\n",
      "Epoch 103/200\n",
      " - 6s - loss: 0.3835 - auc: 0.9922 - val_loss: 0.2363 - val_auc: 0.9980\n",
      "Epoch 104/200\n",
      " - 6s - loss: 0.3943 - auc: 0.9930 - val_loss: 0.2192 - val_auc: 0.9950\n",
      "Epoch 105/200\n",
      " - 6s - loss: 0.3393 - auc: 0.9941 - val_loss: 0.2143 - val_auc: 0.9982\n",
      "Epoch 106/200\n",
      " - 6s - loss: 0.3722 - auc: 0.9920 - val_loss: 0.2127 - val_auc: 0.9984\n",
      "Epoch 107/200\n",
      " - 6s - loss: 0.3690 - auc: 0.9933 - val_loss: 0.1846 - val_auc: 0.9989\n",
      "Epoch 108/200\n",
      " - 6s - loss: 0.3440 - auc: 0.9932 - val_loss: 0.1791 - val_auc: 0.9990\n",
      "Epoch 109/200\n",
      " - 6s - loss: 0.3721 - auc: 0.9935 - val_loss: 0.1851 - val_auc: 0.9987\n",
      "Epoch 110/200\n",
      " - 6s - loss: 0.4611 - auc: 0.9905 - val_loss: 0.2026 - val_auc: 0.9988\n",
      "Epoch 111/200\n",
      " - 6s - loss: 0.3799 - auc: 0.9907 - val_loss: 0.1779 - val_auc: 0.9992\n",
      "Epoch 112/200\n",
      " - 6s - loss: 0.3589 - auc: 0.9942 - val_loss: 0.1748 - val_auc: 0.9993\n",
      "Epoch 113/200\n",
      " - 6s - loss: 0.3164 - auc: 0.9947 - val_loss: 0.1633 - val_auc: 0.9995\n",
      "Epoch 114/200\n",
      " - 6s - loss: 0.4193 - auc: 0.9914 - val_loss: 0.1976 - val_auc: 0.9990\n",
      "Epoch 115/200\n",
      " - 6s - loss: 0.3668 - auc: 0.9938 - val_loss: 0.2124 - val_auc: 0.9984\n",
      "Epoch 116/200\n",
      " - 6s - loss: 0.3379 - auc: 0.9952 - val_loss: 0.2541 - val_auc: 0.9974\n",
      "Epoch 117/200\n",
      " - 6s - loss: 0.4230 - auc: 0.9899 - val_loss: 0.2409 - val_auc: 0.9980\n",
      "Epoch 118/200\n",
      " - 6s - loss: 0.3541 - auc: 0.9943 - val_loss: 0.2443 - val_auc: 0.9975\n",
      "Epoch 119/200\n",
      " - 6s - loss: 0.3793 - auc: 0.9912 - val_loss: 0.2179 - val_auc: 0.9984\n",
      "Epoch 120/200\n",
      " - 6s - loss: 0.3600 - auc: 0.9924 - val_loss: 0.2388 - val_auc: 0.9982\n",
      "Epoch 121/200\n",
      " - 6s - loss: 0.3500 - auc: 0.9936 - val_loss: 0.2197 - val_auc: 0.9982\n",
      "Epoch 122/200\n",
      " - 6s - loss: 0.3385 - auc: 0.9941 - val_loss: 0.2270 - val_auc: 0.9983\n",
      "Epoch 123/200\n",
      " - 6s - loss: 0.3728 - auc: 0.9937 - val_loss: 0.2495 - val_auc: 0.9976\n",
      "Epoch 124/200\n",
      " - 6s - loss: 0.4011 - auc: 0.9924 - val_loss: 0.2012 - val_auc: 0.9986\n",
      "Epoch 125/200\n",
      " - 6s - loss: 0.3338 - auc: 0.9951 - val_loss: 0.1695 - val_auc: 0.9994\n",
      "Epoch 126/200\n",
      " - 6s - loss: 0.3998 - auc: 0.9919 - val_loss: 0.1900 - val_auc: 0.9990\n",
      "Epoch 127/200\n",
      " - 6s - loss: 0.3665 - auc: 0.9936 - val_loss: 0.1727 - val_auc: 0.9993\n",
      "Epoch 128/200\n",
      " - 6s - loss: 0.3561 - auc: 0.9929 - val_loss: 0.2188 - val_auc: 0.9983\n",
      "Epoch 129/200\n",
      " - 6s - loss: 0.3654 - auc: 0.9916 - val_loss: 0.2195 - val_auc: 0.9982\n",
      "Epoch 130/200\n",
      " - 6s - loss: 0.3775 - auc: 0.9938 - val_loss: 0.1952 - val_auc: 0.9988\n",
      "Epoch 131/200\n",
      " - 6s - loss: 0.3901 - auc: 0.9902 - val_loss: 0.1931 - val_auc: 0.9989\n",
      "Epoch 132/200\n",
      " - 6s - loss: 0.3601 - auc: 0.9935 - val_loss: 0.2251 - val_auc: 0.9982\n",
      "Epoch 133/200\n",
      " - 6s - loss: 0.3433 - auc: 0.9937 - val_loss: 0.2056 - val_auc: 0.9985\n",
      "Epoch 134/200\n",
      " - 6s - loss: 0.3731 - auc: 0.9915 - val_loss: 0.2532 - val_auc: 0.9950\n",
      "Epoch 135/200\n",
      " - 6s - loss: 0.3638 - auc: 0.9930 - val_loss: 0.1945 - val_auc: 0.9988\n",
      "Epoch 136/200\n",
      " - 6s - loss: 0.3812 - auc: 0.9923 - val_loss: 0.2565 - val_auc: 0.9973\n",
      "Epoch 137/200\n",
      " - 6s - loss: 0.3783 - auc: 0.9923 - val_loss: 0.1976 - val_auc: 0.9988\n",
      "Epoch 138/200\n",
      " - 6s - loss: 0.3221 - auc: 0.9951 - val_loss: 0.2257 - val_auc: 0.9980\n",
      "Epoch 139/200\n",
      " - 6s - loss: 0.3768 - auc: 0.9930 - val_loss: 0.2106 - val_auc: 0.9986\n",
      "Epoch 140/200\n",
      " - 6s - loss: 0.3955 - auc: 0.9896 - val_loss: 0.2673 - val_auc: 0.9907\n",
      "Epoch 141/200\n",
      " - 6s - loss: 0.3576 - auc: 0.9937 - val_loss: 0.2211 - val_auc: 0.9978\n",
      "Epoch 142/200\n",
      " - 6s - loss: 0.3808 - auc: 0.9931 - val_loss: 0.1922 - val_auc: 0.9989\n",
      "Epoch 143/200\n",
      " - 6s - loss: 0.3508 - auc: 0.9946 - val_loss: 0.2232 - val_auc: 0.9982\n",
      "Epoch 144/200\n",
      " - 6s - loss: 0.3287 - auc: 0.9943 - val_loss: 0.1851 - val_auc: 0.9992\n",
      "Epoch 145/200\n",
      " - 6s - loss: 0.3330 - auc: 0.9937 - val_loss: 0.1682 - val_auc: 0.9993\n",
      "Epoch 146/200\n",
      " - 6s - loss: 0.3629 - auc: 0.9909 - val_loss: 0.1677 - val_auc: 0.9992\n",
      "Epoch 147/200\n",
      " - 6s - loss: 0.3396 - auc: 0.9930 - val_loss: 0.1538 - val_auc: 0.9995\n",
      "Epoch 148/200\n",
      " - 6s - loss: 0.3574 - auc: 0.9921 - val_loss: 0.2312 - val_auc: 0.9977\n",
      "Epoch 149/200\n",
      " - 6s - loss: 0.3802 - auc: 0.9913 - val_loss: 0.2193 - val_auc: 0.9981\n",
      "Epoch 150/200\n",
      " - 6s - loss: 0.3695 - auc: 0.9917 - val_loss: 0.1996 - val_auc: 0.9991\n",
      "Epoch 151/200\n",
      " - 6s - loss: 0.3393 - auc: 0.9940 - val_loss: 0.1755 - val_auc: 0.9992\n",
      "Epoch 152/200\n",
      " - 6s - loss: 0.3334 - auc: 0.9947 - val_loss: 0.1765 - val_auc: 0.9992\n",
      "Epoch 153/200\n",
      " - 6s - loss: 0.3340 - auc: 0.9935 - val_loss: 0.1781 - val_auc: 0.9989\n",
      "Epoch 154/200\n",
      " - 6s - loss: 0.3180 - auc: 0.9935 - val_loss: 0.1581 - val_auc: 0.9994\n",
      "Epoch 155/200\n",
      " - 6s - loss: 0.3418 - auc: 0.9931 - val_loss: 0.2250 - val_auc: 0.9982\n",
      "Epoch 156/200\n",
      " - 6s - loss: 0.3221 - auc: 0.9944 - val_loss: 0.1665 - val_auc: 0.9990\n",
      "Epoch 157/200\n",
      " - 6s - loss: 0.3594 - auc: 0.9931 - val_loss: 0.1711 - val_auc: 0.9990\n",
      "Epoch 158/200\n",
      " - 6s - loss: 0.3561 - auc: 0.9915 - val_loss: 0.1585 - val_auc: 0.9994\n",
      "Epoch 159/200\n",
      " - 6s - loss: 0.3218 - auc: 0.9952 - val_loss: 0.2090 - val_auc: 0.9983\n",
      "Epoch 160/200\n",
      " - 6s - loss: 0.3310 - auc: 0.9952 - val_loss: 0.1809 - val_auc: 0.9988\n",
      "Epoch 161/200\n",
      " - 6s - loss: 0.3817 - auc: 0.9919 - val_loss: 0.1924 - val_auc: 0.9990\n",
      "Epoch 162/200\n",
      " - 6s - loss: 0.3593 - auc: 0.9936 - val_loss: 0.2072 - val_auc: 0.9985\n",
      "Epoch 163/200\n",
      " - 6s - loss: 0.3712 - auc: 0.9927 - val_loss: 0.2041 - val_auc: 0.9985\n",
      "Epoch 164/200\n",
      " - 6s - loss: 0.3345 - auc: 0.9922 - val_loss: 0.2187 - val_auc: 0.9984\n",
      "Epoch 165/200\n",
      " - 6s - loss: 0.3311 - auc: 0.9952 - val_loss: 0.1980 - val_auc: 0.9989\n",
      "Epoch 166/200\n",
      " - 6s - loss: 0.3504 - auc: 0.9933 - val_loss: 0.1815 - val_auc: 0.9991\n",
      "Epoch 167/200\n",
      " - 6s - loss: 0.3115 - auc: 0.9952 - val_loss: 0.2004 - val_auc: 0.9986\n",
      "Epoch 168/200\n",
      " - 6s - loss: 0.3086 - auc: 0.9946 - val_loss: 0.2169 - val_auc: 0.9981\n",
      "Epoch 169/200\n",
      " - 6s - loss: 0.3914 - auc: 0.9918 - val_loss: 0.1646 - val_auc: 0.9993\n",
      "Epoch 170/200\n",
      " - 6s - loss: 0.3531 - auc: 0.9945 - val_loss: 0.2040 - val_auc: 0.9984\n",
      "Epoch 171/200\n",
      " - 6s - loss: 0.3460 - auc: 0.9923 - val_loss: 0.1699 - val_auc: 0.9992\n",
      "Epoch 172/200\n",
      " - 6s - loss: 0.3272 - auc: 0.9948 - val_loss: 0.2052 - val_auc: 0.9985\n",
      "Epoch 173/200\n",
      " - 6s - loss: 0.2846 - auc: 0.9963 - val_loss: 0.1818 - val_auc: 0.9993\n",
      "Epoch 174/200\n",
      " - 6s - loss: 0.3645 - auc: 0.9928 - val_loss: 0.1588 - val_auc: 0.9992\n",
      "Epoch 175/200\n",
      " - 6s - loss: 0.3393 - auc: 0.9936 - val_loss: 0.2105 - val_auc: 0.9988\n",
      "Epoch 176/200\n",
      " - 6s - loss: 0.3865 - auc: 0.9920 - val_loss: 0.2315 - val_auc: 0.9976\n",
      "Epoch 177/200\n",
      " - 6s - loss: 0.3399 - auc: 0.9941 - val_loss: 0.2340 - val_auc: 0.9944\n",
      "Epoch 178/200\n",
      " - 6s - loss: 0.2827 - auc: 0.9966 - val_loss: 0.2071 - val_auc: 0.9985\n",
      "Epoch 179/200\n",
      " - 6s - loss: 0.3860 - auc: 0.9928 - val_loss: 0.2041 - val_auc: 0.9985\n",
      "Epoch 180/200\n",
      " - 6s - loss: 0.3372 - auc: 0.9935 - val_loss: 0.2134 - val_auc: 0.9981\n",
      "Epoch 181/200\n",
      " - 6s - loss: 0.3076 - auc: 0.9948 - val_loss: 0.1975 - val_auc: 0.9985\n",
      "Epoch 182/200\n",
      " - 6s - loss: 0.3405 - auc: 0.9943 - val_loss: 0.1639 - val_auc: 0.9991\n",
      "Epoch 183/200\n",
      " - 6s - loss: 0.3032 - auc: 0.9950 - val_loss: 0.2019 - val_auc: 0.9986\n",
      "Epoch 184/200\n",
      " - 6s - loss: 0.3369 - auc: 0.9933 - val_loss: 0.1613 - val_auc: 0.9993\n",
      "Epoch 185/200\n",
      " - 6s - loss: 0.3455 - auc: 0.9932 - val_loss: 0.1600 - val_auc: 0.9995\n",
      "Epoch 186/200\n",
      " - 6s - loss: 0.3588 - auc: 0.9939 - val_loss: 0.1880 - val_auc: 0.9987\n",
      "Epoch 187/200\n",
      " - 6s - loss: 0.3144 - auc: 0.9953 - val_loss: 0.1916 - val_auc: 0.9986\n",
      "Epoch 188/200\n",
      " - 6s - loss: 0.3398 - auc: 0.9925 - val_loss: 0.1757 - val_auc: 0.9989\n",
      "Epoch 189/200\n",
      " - 6s - loss: 0.2613 - auc: 0.9969 - val_loss: 0.1989 - val_auc: 0.9983\n",
      "Epoch 190/200\n",
      " - 6s - loss: 0.3442 - auc: 0.9932 - val_loss: 0.2600 - val_auc: 0.9941\n",
      "Epoch 191/200\n",
      " - 6s - loss: 0.3458 - auc: 0.9930 - val_loss: 0.1846 - val_auc: 0.9990\n",
      "Epoch 192/200\n",
      " - 6s - loss: 0.3485 - auc: 0.9927 - val_loss: 0.1770 - val_auc: 0.9990\n",
      "Epoch 193/200\n",
      " - 6s - loss: 0.3502 - auc: 0.9929 - val_loss: 0.2257 - val_auc: 0.9915\n",
      "Epoch 194/200\n",
      " - 6s - loss: 0.2925 - auc: 0.9954 - val_loss: 0.1959 - val_auc: 0.9990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 195/200\n",
      " - 6s - loss: 0.3121 - auc: 0.9950 - val_loss: 0.2003 - val_auc: 0.9985\n",
      "Epoch 196/200\n",
      " - 6s - loss: 0.3481 - auc: 0.9935 - val_loss: 0.2150 - val_auc: 0.9981\n",
      "Epoch 197/200\n",
      " - 6s - loss: 0.3903 - auc: 0.9922 - val_loss: 0.1994 - val_auc: 0.9986\n",
      "Epoch 198/200\n",
      " - 6s - loss: 0.3211 - auc: 0.9950 - val_loss: 0.1900 - val_auc: 0.9986\n",
      "Epoch 199/200\n",
      " - 6s - loss: 0.3141 - auc: 0.9948 - val_loss: 0.1879 - val_auc: 0.9988\n",
      "Epoch 200/200\n",
      " - 6s - loss: 0.3373 - auc: 0.9933 - val_loss: 0.1619 - val_auc: 0.9992\n",
      "Original,MIT-BIH Normal Sinus Rhythm Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keg/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:80: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1808 samples, validate on 263 samples\n",
      "Epoch 1/200\n",
      " - 48s - loss: 1.4521 - auc: 0.9085 - val_loss: 1.9575 - val_auc: 0.9155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keg/anaconda3/lib/python3.6/site-packages/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `roc_accuracy` which is not available. Available metrics are: val_loss,val_auc,loss,auc,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200\n",
      " - 9s - loss: 0.9224 - auc: 0.9703 - val_loss: 0.7960 - val_auc: 0.9861\n",
      "Epoch 3/200\n",
      " - 9s - loss: 0.7758 - auc: 0.9781 - val_loss: 0.4682 - val_auc: 0.9886\n",
      "Epoch 4/200\n",
      " - 9s - loss: 0.7018 - auc: 0.9812 - val_loss: 0.4413 - val_auc: 0.9867\n",
      "Epoch 5/200\n",
      " - 9s - loss: 0.6812 - auc: 0.9801 - val_loss: 0.3666 - val_auc: 0.9918\n",
      "Epoch 6/200\n",
      " - 9s - loss: 0.6221 - auc: 0.9831 - val_loss: 0.3268 - val_auc: 0.9930\n",
      "Epoch 7/200\n",
      " - 9s - loss: 0.6019 - auc: 0.9847 - val_loss: 0.3438 - val_auc: 0.9901\n",
      "Epoch 8/200\n",
      " - 9s - loss: 0.6157 - auc: 0.9836 - val_loss: 0.3891 - val_auc: 0.9894\n",
      "Epoch 9/200\n",
      " - 9s - loss: 0.5844 - auc: 0.9850 - val_loss: 0.3150 - val_auc: 0.9933\n",
      "Epoch 10/200\n",
      " - 9s - loss: 0.5441 - auc: 0.9867 - val_loss: 0.3541 - val_auc: 0.9895\n",
      "Epoch 11/200\n",
      " - 9s - loss: 0.5469 - auc: 0.9865 - val_loss: 0.2962 - val_auc: 0.9928\n",
      "Epoch 12/200\n",
      " - 9s - loss: 0.5409 - auc: 0.9860 - val_loss: 0.3251 - val_auc: 0.9928\n",
      "Epoch 13/200\n",
      " - 9s - loss: 0.5300 - auc: 0.9872 - val_loss: 0.2929 - val_auc: 0.9937\n",
      "Epoch 14/200\n",
      " - 9s - loss: 0.4962 - auc: 0.9900 - val_loss: 0.3067 - val_auc: 0.9936\n",
      "Epoch 15/200\n",
      " - 9s - loss: 0.5057 - auc: 0.9867 - val_loss: 0.2883 - val_auc: 0.9933\n",
      "Epoch 16/200\n",
      " - 9s - loss: 0.4947 - auc: 0.9872 - val_loss: 0.3327 - val_auc: 0.9929\n",
      "Epoch 17/200\n",
      " - 9s - loss: 0.5175 - auc: 0.9872 - val_loss: 0.2760 - val_auc: 0.9939\n",
      "Epoch 18/200\n",
      " - 9s - loss: 0.4795 - auc: 0.9895 - val_loss: 0.3100 - val_auc: 0.9935\n",
      "Epoch 19/200\n",
      " - 9s - loss: 0.4803 - auc: 0.9890 - val_loss: 0.3221 - val_auc: 0.9925\n",
      "Epoch 20/200\n",
      " - 9s - loss: 0.4733 - auc: 0.9892 - val_loss: 0.3082 - val_auc: 0.9937\n",
      "Epoch 21/200\n",
      " - 9s - loss: 0.4567 - auc: 0.9906 - val_loss: 0.3009 - val_auc: 0.9934\n",
      "Epoch 22/200\n",
      " - 9s - loss: 0.4233 - auc: 0.9913 - val_loss: 0.2652 - val_auc: 0.9942\n",
      "Epoch 23/200\n",
      " - 9s - loss: 0.4381 - auc: 0.9898 - val_loss: 0.2959 - val_auc: 0.9901\n",
      "Epoch 24/200\n",
      " - 9s - loss: 0.4656 - auc: 0.9894 - val_loss: 0.3061 - val_auc: 0.9929\n",
      "Epoch 25/200\n",
      " - 9s - loss: 0.4525 - auc: 0.9908 - val_loss: 0.3104 - val_auc: 0.9937\n",
      "Epoch 26/200\n",
      " - 9s - loss: 0.4366 - auc: 0.9904 - val_loss: 0.2653 - val_auc: 0.9944\n",
      "Epoch 27/200\n",
      " - 9s - loss: 0.4646 - auc: 0.9893 - val_loss: 0.2780 - val_auc: 0.9937\n",
      "Epoch 28/200\n",
      " - 9s - loss: 0.4604 - auc: 0.9893 - val_loss: 0.3540 - val_auc: 0.9901\n",
      "Epoch 29/200\n",
      " - 9s - loss: 0.4432 - auc: 0.9907 - val_loss: 0.3205 - val_auc: 0.9899\n",
      "Epoch 30/200\n",
      " - 9s - loss: 0.4082 - auc: 0.9923 - val_loss: 0.3232 - val_auc: 0.9904\n",
      "Epoch 31/200\n",
      " - 9s - loss: 0.4516 - auc: 0.9881 - val_loss: 0.3013 - val_auc: 0.9934\n",
      "Epoch 32/200\n",
      " - 9s - loss: 0.4038 - auc: 0.9911 - val_loss: 0.2741 - val_auc: 0.9933\n",
      "Epoch 33/200\n",
      " - 9s - loss: 0.4195 - auc: 0.9917 - val_loss: 0.2678 - val_auc: 0.9932\n",
      "Epoch 34/200\n",
      " - 9s - loss: 0.3773 - auc: 0.9926 - val_loss: 0.3120 - val_auc: 0.9895\n",
      "Epoch 35/200\n",
      " - 9s - loss: 0.4061 - auc: 0.9918 - val_loss: 0.2718 - val_auc: 0.9937\n",
      "Epoch 36/200\n",
      " - 9s - loss: 0.4206 - auc: 0.9908 - val_loss: 0.2843 - val_auc: 0.9936\n",
      "Epoch 37/200\n",
      " - 9s - loss: 0.4220 - auc: 0.9907 - val_loss: 0.2667 - val_auc: 0.9934\n",
      "Epoch 38/200\n",
      " - 9s - loss: 0.3774 - auc: 0.9931 - val_loss: 0.2827 - val_auc: 0.9926\n",
      "Epoch 39/200\n",
      " - 9s - loss: 0.4704 - auc: 0.9889 - val_loss: 0.2847 - val_auc: 0.9938\n",
      "Epoch 40/200\n",
      " - 9s - loss: 0.3805 - auc: 0.9927 - val_loss: 0.3432 - val_auc: 0.9894\n",
      "Epoch 41/200\n",
      " - 9s - loss: 0.3773 - auc: 0.9934 - val_loss: 0.2773 - val_auc: 0.9938\n",
      "Epoch 42/200\n",
      " - 9s - loss: 0.3730 - auc: 0.9928 - val_loss: 0.2755 - val_auc: 0.9934\n",
      "Epoch 43/200\n",
      " - 9s - loss: 0.4199 - auc: 0.9906 - val_loss: 0.2564 - val_auc: 0.9940\n",
      "Epoch 44/200\n",
      " - 9s - loss: 0.4142 - auc: 0.9914 - val_loss: 0.2675 - val_auc: 0.9934\n",
      "Epoch 45/200\n",
      " - 9s - loss: 0.4206 - auc: 0.9907 - val_loss: 0.2855 - val_auc: 0.9936\n",
      "Epoch 46/200\n",
      " - 9s - loss: 0.3516 - auc: 0.9936 - val_loss: 0.2915 - val_auc: 0.9933\n",
      "Epoch 47/200\n",
      " - 9s - loss: 0.4380 - auc: 0.9889 - val_loss: 0.2906 - val_auc: 0.9922\n",
      "Epoch 48/200\n",
      " - 9s - loss: 0.3876 - auc: 0.9907 - val_loss: 0.2541 - val_auc: 0.9945\n",
      "Epoch 49/200\n",
      " - 9s - loss: 0.3808 - auc: 0.9916 - val_loss: 0.2387 - val_auc: 0.9945\n",
      "Epoch 50/200\n",
      " - 9s - loss: 0.3964 - auc: 0.9923 - val_loss: 0.2911 - val_auc: 0.9928\n",
      "Epoch 51/200\n",
      " - 9s - loss: 0.3778 - auc: 0.9924 - val_loss: 0.2460 - val_auc: 0.9940\n",
      "Epoch 52/200\n",
      " - 9s - loss: 0.3810 - auc: 0.9927 - val_loss: 0.2687 - val_auc: 0.9939\n",
      "Epoch 53/200\n",
      " - 9s - loss: 0.3603 - auc: 0.9922 - val_loss: 0.2802 - val_auc: 0.9927\n",
      "Epoch 54/200\n",
      " - 9s - loss: 0.4047 - auc: 0.9909 - val_loss: 0.2355 - val_auc: 0.9944\n",
      "Epoch 55/200\n",
      " - 9s - loss: 0.3778 - auc: 0.9917 - val_loss: 0.2613 - val_auc: 0.9937\n",
      "Epoch 56/200\n",
      " - 9s - loss: 0.3742 - auc: 0.9930 - val_loss: 0.2644 - val_auc: 0.9940\n",
      "Epoch 57/200\n",
      " - 9s - loss: 0.3550 - auc: 0.9936 - val_loss: 0.2864 - val_auc: 0.9928\n",
      "Epoch 58/200\n",
      " - 9s - loss: 0.3030 - auc: 0.9958 - val_loss: 0.2402 - val_auc: 0.9943\n",
      "Epoch 59/200\n",
      " - 9s - loss: 0.3848 - auc: 0.9909 - val_loss: 0.2740 - val_auc: 0.9936\n",
      "Epoch 60/200\n",
      " - 9s - loss: 0.3737 - auc: 0.9920 - val_loss: 0.2554 - val_auc: 0.9943\n",
      "Epoch 61/200\n",
      " - 9s - loss: 0.4177 - auc: 0.9896 - val_loss: 0.2939 - val_auc: 0.9929\n",
      "Epoch 62/200\n",
      " - 9s - loss: 0.3949 - auc: 0.9920 - val_loss: 0.2510 - val_auc: 0.9940\n",
      "Epoch 63/200\n",
      " - 9s - loss: 0.3660 - auc: 0.9924 - val_loss: 0.2498 - val_auc: 0.9969\n",
      "Epoch 64/200\n",
      " - 9s - loss: 0.3882 - auc: 0.9905 - val_loss: 0.2723 - val_auc: 0.9906\n",
      "Epoch 65/200\n",
      " - 9s - loss: 0.3797 - auc: 0.9920 - val_loss: 0.2527 - val_auc: 0.9945\n",
      "Epoch 66/200\n",
      " - 9s - loss: 0.3449 - auc: 0.9934 - val_loss: 0.2571 - val_auc: 0.9942\n",
      "Epoch 67/200\n",
      " - 9s - loss: 0.3074 - auc: 0.9957 - val_loss: 0.2765 - val_auc: 0.9936\n",
      "Epoch 68/200\n",
      " - 9s - loss: 0.3133 - auc: 0.9942 - val_loss: 0.2462 - val_auc: 0.9904\n",
      "Epoch 69/200\n",
      " - 9s - loss: 0.3087 - auc: 0.9952 - val_loss: 0.3015 - val_auc: 0.9903\n",
      "Epoch 70/200\n",
      " - 9s - loss: 0.3459 - auc: 0.9927 - val_loss: 0.2526 - val_auc: 0.9944\n",
      "Epoch 71/200\n",
      " - 9s - loss: 0.3893 - auc: 0.9919 - val_loss: 0.2578 - val_auc: 0.9939\n",
      "Epoch 72/200\n",
      " - 9s - loss: 0.3655 - auc: 0.9932 - val_loss: 0.2448 - val_auc: 0.9945\n",
      "Epoch 73/200\n",
      " - 9s - loss: 0.3705 - auc: 0.9932 - val_loss: 0.2987 - val_auc: 0.9933\n",
      "Epoch 74/200\n",
      " - 9s - loss: 0.3833 - auc: 0.9908 - val_loss: 0.2704 - val_auc: 0.9934\n",
      "Epoch 75/200\n",
      " - 9s - loss: 0.3891 - auc: 0.9918 - val_loss: 0.2410 - val_auc: 0.9973\n",
      "Epoch 76/200\n",
      " - 9s - loss: 0.3519 - auc: 0.9938 - val_loss: 0.3028 - val_auc: 0.9930\n",
      "Epoch 77/200\n",
      " - 9s - loss: 0.3604 - auc: 0.9924 - val_loss: 0.2521 - val_auc: 0.9972\n",
      "Epoch 78/200\n",
      " - 9s - loss: 0.3570 - auc: 0.9936 - val_loss: 0.2205 - val_auc: 0.9976\n",
      "Epoch 79/200\n",
      " - 9s - loss: 0.3439 - auc: 0.9934 - val_loss: 0.2325 - val_auc: 0.9973\n",
      "Epoch 80/200\n",
      " - 9s - loss: 0.3897 - auc: 0.9907 - val_loss: 0.2708 - val_auc: 0.9963\n",
      "Epoch 81/200\n",
      " - 9s - loss: 0.3674 - auc: 0.9921 - val_loss: 0.2682 - val_auc: 0.9937\n",
      "Epoch 82/200\n",
      " - 9s - loss: 0.3708 - auc: 0.9922 - val_loss: 0.2548 - val_auc: 0.9970\n",
      "Epoch 83/200\n",
      " - 9s - loss: 0.3485 - auc: 0.9926 - val_loss: 0.3016 - val_auc: 0.9931\n",
      "Epoch 84/200\n",
      " - 9s - loss: 0.3542 - auc: 0.9915 - val_loss: 0.2842 - val_auc: 0.9961\n",
      "Epoch 85/200\n",
      " - 9s - loss: 0.3784 - auc: 0.9910 - val_loss: 0.3247 - val_auc: 0.9924\n",
      "Epoch 86/200\n",
      " - 9s - loss: 0.3180 - auc: 0.9944 - val_loss: 0.2335 - val_auc: 0.9942\n",
      "Epoch 87/200\n",
      " - 9s - loss: 0.3363 - auc: 0.9940 - val_loss: 0.2552 - val_auc: 0.9940\n",
      "Epoch 88/200\n",
      " - 9s - loss: 0.3415 - auc: 0.9938 - val_loss: 0.2746 - val_auc: 0.9935\n",
      "Epoch 89/200\n",
      " - 9s - loss: 0.3269 - auc: 0.9935 - val_loss: 0.2680 - val_auc: 0.9934\n",
      "Epoch 90/200\n",
      " - 9s - loss: 0.3499 - auc: 0.9924 - val_loss: 0.3052 - val_auc: 0.9895\n",
      "Epoch 91/200\n",
      " - 9s - loss: 0.3154 - auc: 0.9951 - val_loss: 0.2356 - val_auc: 0.9971\n",
      "Epoch 92/200\n",
      " - 9s - loss: 0.3659 - auc: 0.9929 - val_loss: 0.2396 - val_auc: 0.9942\n",
      "Epoch 93/200\n",
      " - 9s - loss: 0.3581 - auc: 0.9920 - val_loss: 0.2559 - val_auc: 0.9940\n",
      "Epoch 94/200\n",
      " - 9s - loss: 0.3620 - auc: 0.9937 - val_loss: 0.2263 - val_auc: 0.9973\n",
      "Epoch 95/200\n",
      " - 9s - loss: 0.3575 - auc: 0.9929 - val_loss: 0.2549 - val_auc: 0.9940\n",
      "Epoch 96/200\n",
      " - 9s - loss: 0.3475 - auc: 0.9947 - val_loss: 0.2604 - val_auc: 0.9969\n",
      "Epoch 97/200\n",
      " - 9s - loss: 0.3442 - auc: 0.9934 - val_loss: 0.2622 - val_auc: 0.9936\n",
      "Epoch 98/200\n",
      " - 9s - loss: 0.3170 - auc: 0.9939 - val_loss: 0.2235 - val_auc: 0.9974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/200\n",
      " - 9s - loss: 0.3786 - auc: 0.9905 - val_loss: 0.2515 - val_auc: 0.9970\n",
      "Epoch 100/200\n",
      " - 9s - loss: 0.3302 - auc: 0.9935 - val_loss: 0.2186 - val_auc: 0.9976\n",
      "Epoch 101/200\n",
      " - 9s - loss: 0.3368 - auc: 0.9938 - val_loss: 0.2439 - val_auc: 0.9966\n",
      "Epoch 102/200\n",
      " - 9s - loss: 0.3307 - auc: 0.9924 - val_loss: 0.2412 - val_auc: 0.9977\n",
      "Epoch 103/200\n",
      " - 9s - loss: 0.2924 - auc: 0.9947 - val_loss: 0.2411 - val_auc: 0.9942\n",
      "Epoch 104/200\n",
      " - 9s - loss: 0.3365 - auc: 0.9937 - val_loss: 0.2235 - val_auc: 0.9949\n",
      "Epoch 105/200\n",
      " - 9s - loss: 0.3102 - auc: 0.9950 - val_loss: 0.2727 - val_auc: 0.9935\n",
      "Epoch 106/200\n",
      " - 9s - loss: 0.3223 - auc: 0.9935 - val_loss: 0.2360 - val_auc: 0.9970\n",
      "Epoch 107/200\n",
      " - 9s - loss: 0.3050 - auc: 0.9937 - val_loss: 0.2591 - val_auc: 0.9936\n",
      "Epoch 108/200\n",
      " - 9s - loss: 0.3336 - auc: 0.9945 - val_loss: 0.2568 - val_auc: 0.9938\n",
      "Epoch 109/200\n",
      " - 9s - loss: 0.3367 - auc: 0.9929 - val_loss: 0.2450 - val_auc: 0.9942\n",
      "Epoch 110/200\n",
      " - 9s - loss: 0.3648 - auc: 0.9922 - val_loss: 0.2494 - val_auc: 0.9970\n",
      "Epoch 111/200\n",
      " - 9s - loss: 0.3263 - auc: 0.9938 - val_loss: 0.2387 - val_auc: 0.9966\n",
      "Epoch 112/200\n",
      " - 9s - loss: 0.3683 - auc: 0.9911 - val_loss: 0.2176 - val_auc: 0.9947\n",
      "Epoch 113/200\n",
      " - 9s - loss: 0.3756 - auc: 0.9917 - val_loss: 0.2616 - val_auc: 0.9945\n",
      "Epoch 114/200\n",
      " - 9s - loss: 0.3420 - auc: 0.9926 - val_loss: 0.2256 - val_auc: 0.9944\n",
      "Epoch 115/200\n",
      " - 9s - loss: 0.3222 - auc: 0.9937 - val_loss: 0.2380 - val_auc: 0.9943\n",
      "Epoch 116/200\n",
      " - 9s - loss: 0.3279 - auc: 0.9937 - val_loss: 0.2279 - val_auc: 0.9976\n",
      "Epoch 117/200\n",
      " - 9s - loss: 0.3196 - auc: 0.9942 - val_loss: 0.2252 - val_auc: 0.9978\n",
      "Epoch 118/200\n",
      " - 9s - loss: 0.3065 - auc: 0.9951 - val_loss: 0.2656 - val_auc: 0.9970\n",
      "Epoch 119/200\n",
      " - 9s - loss: 0.3336 - auc: 0.9939 - val_loss: 0.2140 - val_auc: 0.9977\n",
      "Epoch 120/200\n",
      " - 9s - loss: 0.3253 - auc: 0.9942 - val_loss: 0.2719 - val_auc: 0.9963\n",
      "Epoch 121/200\n",
      " - 9s - loss: 0.3367 - auc: 0.9918 - val_loss: 0.2603 - val_auc: 0.9944\n",
      "Epoch 122/200\n",
      " - 9s - loss: 0.3140 - auc: 0.9951 - val_loss: 0.2401 - val_auc: 0.9941\n",
      "Epoch 123/200\n",
      " - 9s - loss: 0.2884 - auc: 0.9956 - val_loss: 0.2653 - val_auc: 0.9940\n",
      "Epoch 124/200\n",
      " - 9s - loss: 0.2951 - auc: 0.9945 - val_loss: 0.2293 - val_auc: 0.9969\n",
      "Epoch 125/200\n",
      " - 9s - loss: 0.3089 - auc: 0.9943 - val_loss: 0.2343 - val_auc: 0.9973\n",
      "Epoch 126/200\n",
      " - 9s - loss: 0.3212 - auc: 0.9926 - val_loss: 0.2509 - val_auc: 0.9969\n",
      "Epoch 127/200\n",
      " - 9s - loss: 0.3535 - auc: 0.9920 - val_loss: 0.2323 - val_auc: 0.9974\n",
      "Epoch 128/200\n",
      " - 9s - loss: 0.3303 - auc: 0.9938 - val_loss: 0.2669 - val_auc: 0.9965\n",
      "Epoch 129/200\n",
      " - 9s - loss: 0.3034 - auc: 0.9943 - val_loss: 0.2388 - val_auc: 0.9979\n",
      "Epoch 130/200\n",
      " - 9s - loss: 0.3247 - auc: 0.9934 - val_loss: 0.1909 - val_auc: 0.9984\n",
      "Epoch 131/200\n",
      " - 9s - loss: 0.3127 - auc: 0.9945 - val_loss: 0.2359 - val_auc: 0.9975\n",
      "Epoch 132/200\n",
      " - 9s - loss: 0.2724 - auc: 0.9960 - val_loss: 0.2410 - val_auc: 0.9973\n",
      "Epoch 133/200\n",
      " - 9s - loss: 0.3260 - auc: 0.9940 - val_loss: 0.2493 - val_auc: 0.9968\n",
      "Epoch 134/200\n",
      " - 9s - loss: 0.3560 - auc: 0.9921 - val_loss: 0.2628 - val_auc: 0.9966\n",
      "Epoch 135/200\n",
      " - 9s - loss: 0.3074 - auc: 0.9935 - val_loss: 0.2185 - val_auc: 0.9980\n",
      "Epoch 136/200\n",
      " - 9s - loss: 0.3495 - auc: 0.9935 - val_loss: 0.2201 - val_auc: 0.9980\n",
      "Epoch 137/200\n",
      " - 9s - loss: 0.3331 - auc: 0.9937 - val_loss: 0.2554 - val_auc: 0.9965\n",
      "Epoch 138/200\n",
      " - 9s - loss: 0.3125 - auc: 0.9945 - val_loss: 0.2402 - val_auc: 0.9970\n",
      "Epoch 139/200\n",
      " - 9s - loss: 0.3104 - auc: 0.9933 - val_loss: 0.2385 - val_auc: 0.9973\n",
      "Epoch 140/200\n",
      " - 9s - loss: 0.3637 - auc: 0.9907 - val_loss: 0.2127 - val_auc: 0.9980\n",
      "Epoch 141/200\n",
      " - 9s - loss: 0.3386 - auc: 0.9921 - val_loss: 0.2326 - val_auc: 0.9944\n",
      "Epoch 142/200\n",
      " - 9s - loss: 0.3368 - auc: 0.9924 - val_loss: 0.2719 - val_auc: 0.9939\n",
      "Epoch 143/200\n",
      " - 9s - loss: 0.2965 - auc: 0.9942 - val_loss: 0.2259 - val_auc: 0.9976\n",
      "Epoch 144/200\n",
      " - 9s - loss: 0.3430 - auc: 0.9927 - val_loss: 0.2475 - val_auc: 0.9971\n",
      "Epoch 145/200\n",
      " - 9s - loss: 0.2979 - auc: 0.9952 - val_loss: 0.2394 - val_auc: 0.9942\n",
      "Epoch 146/200\n",
      " - 9s - loss: 0.2929 - auc: 0.9957 - val_loss: 0.2481 - val_auc: 0.9970\n",
      "Epoch 147/200\n",
      " - 9s - loss: 0.3102 - auc: 0.9940 - val_loss: 0.2211 - val_auc: 0.9977\n",
      "Epoch 148/200\n",
      " - 9s - loss: 0.2838 - auc: 0.9963 - val_loss: 0.2207 - val_auc: 0.9947\n",
      "Epoch 149/200\n",
      " - 9s - loss: 0.3314 - auc: 0.9926 - val_loss: 0.2178 - val_auc: 0.9976\n",
      "Epoch 150/200\n",
      " - 9s - loss: 0.3030 - auc: 0.9932 - val_loss: 0.2218 - val_auc: 0.9946\n",
      "Epoch 151/200\n",
      " - 9s - loss: 0.3241 - auc: 0.9938 - val_loss: 0.2205 - val_auc: 0.9975\n",
      "Epoch 152/200\n",
      " - 9s - loss: 0.2445 - auc: 0.9972 - val_loss: 0.2048 - val_auc: 0.9980\n",
      "Epoch 153/200\n",
      " - 9s - loss: 0.2974 - auc: 0.9935 - val_loss: 0.2008 - val_auc: 0.9983\n",
      "Epoch 154/200\n",
      " - 9s - loss: 0.3052 - auc: 0.9948 - val_loss: 0.2138 - val_auc: 0.9979\n",
      "Epoch 155/200\n",
      " - 9s - loss: 0.3123 - auc: 0.9938 - val_loss: 0.2197 - val_auc: 0.9978\n",
      "Epoch 156/200\n",
      " - 9s - loss: 0.3140 - auc: 0.9934 - val_loss: 0.2389 - val_auc: 0.9974\n",
      "Epoch 157/200\n",
      " - 9s - loss: 0.2978 - auc: 0.9950 - val_loss: 0.2426 - val_auc: 0.9967\n",
      "Epoch 158/200\n",
      " - 9s - loss: 0.3731 - auc: 0.9913 - val_loss: 0.2314 - val_auc: 0.9970\n",
      "Epoch 159/200\n",
      " - 9s - loss: 0.3203 - auc: 0.9942 - val_loss: 0.2587 - val_auc: 0.9972\n",
      "Epoch 160/200\n",
      " - 9s - loss: 0.3013 - auc: 0.9942 - val_loss: 0.2393 - val_auc: 0.9943\n",
      "Epoch 161/200\n",
      " - 9s - loss: 0.2988 - auc: 0.9939 - val_loss: 0.2258 - val_auc: 0.9944\n",
      "Epoch 162/200\n",
      " - 9s - loss: 0.2696 - auc: 0.9955 - val_loss: 0.2365 - val_auc: 0.9972\n",
      "Epoch 163/200\n",
      " - 9s - loss: 0.2945 - auc: 0.9944 - val_loss: 0.1893 - val_auc: 0.9981\n",
      "Epoch 164/200\n",
      " - 9s - loss: 0.3175 - auc: 0.9930 - val_loss: 0.2502 - val_auc: 0.9968\n",
      "Epoch 165/200\n",
      " - 9s - loss: 0.2792 - auc: 0.9946 - val_loss: 0.2556 - val_auc: 0.9967\n",
      "Epoch 166/200\n",
      " - 9s - loss: 0.2832 - auc: 0.9951 - val_loss: 0.2177 - val_auc: 0.9979\n",
      "Epoch 167/200\n",
      " - 9s - loss: 0.2920 - auc: 0.9951 - val_loss: 0.2277 - val_auc: 0.9974\n",
      "Epoch 168/200\n",
      " - 9s - loss: 0.2790 - auc: 0.9957 - val_loss: 0.2210 - val_auc: 0.9975\n",
      "Epoch 169/200\n",
      " - 9s - loss: 0.3245 - auc: 0.9942 - val_loss: 0.1934 - val_auc: 0.9983\n",
      "Epoch 170/200\n",
      " - 9s - loss: 0.3103 - auc: 0.9940 - val_loss: 0.2315 - val_auc: 0.9943\n",
      "Epoch 171/200\n",
      " - 9s - loss: 0.3111 - auc: 0.9933 - val_loss: 0.2059 - val_auc: 0.9975\n",
      "Epoch 172/200\n",
      " - 9s - loss: 0.3084 - auc: 0.9938 - val_loss: 0.2254 - val_auc: 0.9974\n",
      "Epoch 173/200\n",
      " - 9s - loss: 0.2752 - auc: 0.9949 - val_loss: 0.1972 - val_auc: 0.9977\n",
      "Epoch 174/200\n",
      " - 9s - loss: 0.2849 - auc: 0.9948 - val_loss: 0.2433 - val_auc: 0.9970\n",
      "Epoch 175/200\n",
      " - 9s - loss: 0.2817 - auc: 0.9955 - val_loss: 0.2273 - val_auc: 0.9972\n",
      "Epoch 176/200\n",
      " - 9s - loss: 0.3150 - auc: 0.9943 - val_loss: 0.2200 - val_auc: 0.9975\n",
      "Epoch 177/200\n",
      " - 9s - loss: 0.3026 - auc: 0.9936 - val_loss: 0.2097 - val_auc: 0.9978\n",
      "Epoch 178/200\n",
      " - 9s - loss: 0.3014 - auc: 0.9924 - val_loss: 0.2381 - val_auc: 0.9970\n",
      "Epoch 179/200\n",
      " - 9s - loss: 0.2821 - auc: 0.9952 - val_loss: 0.2266 - val_auc: 0.9942\n",
      "Epoch 180/200\n",
      " - 9s - loss: 0.2944 - auc: 0.9951 - val_loss: 0.2266 - val_auc: 0.9972\n",
      "Epoch 181/200\n",
      " - 9s - loss: 0.3068 - auc: 0.9959 - val_loss: 0.2233 - val_auc: 0.9976\n",
      "Epoch 182/200\n",
      " - 9s - loss: 0.2756 - auc: 0.9963 - val_loss: 0.2169 - val_auc: 0.9977\n",
      "Epoch 183/200\n",
      " - 9s - loss: 0.2887 - auc: 0.9952 - val_loss: 0.2331 - val_auc: 0.9973\n",
      "Epoch 184/200\n",
      " - 9s - loss: 0.3176 - auc: 0.9938 - val_loss: 0.2198 - val_auc: 0.9977\n",
      "Epoch 185/200\n",
      " - 9s - loss: 0.3168 - auc: 0.9951 - val_loss: 0.1975 - val_auc: 0.9981\n",
      "Epoch 186/200\n",
      " - 9s - loss: 0.2946 - auc: 0.9947 - val_loss: 0.2230 - val_auc: 0.9975\n",
      "Epoch 187/200\n",
      " - 9s - loss: 0.2522 - auc: 0.9960 - val_loss: 0.2057 - val_auc: 0.9977\n",
      "Epoch 188/200\n",
      " - 9s - loss: 0.3072 - auc: 0.9948 - val_loss: 0.2282 - val_auc: 0.9974\n",
      "Epoch 189/200\n",
      " - 9s - loss: 0.3239 - auc: 0.9919 - val_loss: 0.2475 - val_auc: 0.9970\n",
      "Epoch 190/200\n",
      " - 9s - loss: 0.2991 - auc: 0.9942 - val_loss: 0.2278 - val_auc: 0.9977\n",
      "Epoch 191/200\n",
      " - 9s - loss: 0.3085 - auc: 0.9952 - val_loss: 0.2167 - val_auc: 0.9977\n",
      "Epoch 192/200\n",
      " - 9s - loss: 0.2992 - auc: 0.9943 - val_loss: 0.2084 - val_auc: 0.9977\n",
      "Epoch 193/200\n",
      " - 9s - loss: 0.3276 - auc: 0.9937 - val_loss: 0.2062 - val_auc: 0.9981\n",
      "Epoch 194/200\n",
      " - 9s - loss: 0.2692 - auc: 0.9955 - val_loss: 0.2147 - val_auc: 0.9978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 195/200\n",
      " - 9s - loss: 0.2554 - auc: 0.9955 - val_loss: 0.2558 - val_auc: 0.9973\n",
      "Epoch 196/200\n",
      " - 9s - loss: 0.2987 - auc: 0.9949 - val_loss: 0.2310 - val_auc: 0.9972\n",
      "Epoch 197/200\n",
      " - 9s - loss: 0.2764 - auc: 0.9956 - val_loss: 0.2126 - val_auc: 0.9978\n",
      "Epoch 198/200\n",
      " - 9s - loss: 0.3140 - auc: 0.9937 - val_loss: 0.2003 - val_auc: 0.9979\n",
      "Epoch 199/200\n",
      " - 9s - loss: 0.2707 - auc: 0.9947 - val_loss: 0.2180 - val_auc: 0.9976\n",
      "Epoch 200/200\n",
      " - 9s - loss: 0.2956 - auc: 0.9940 - val_loss: 0.2138 - val_auc: 0.9979\n",
      "SMOTE,MIT-BIH Normal Sinus Rhythm Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keg/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:80: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1773 samples, validate on 263 samples\n",
      "Epoch 1/200\n",
      " - 48s - loss: 1.5664 - auc: 0.8964 - val_loss: 1.7892 - val_auc: 0.9727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keg/anaconda3/lib/python3.6/site-packages/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `roc_accuracy` which is not available. Available metrics are: val_loss,val_auc,loss,auc,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200\n",
      " - 9s - loss: 1.0083 - auc: 0.9643 - val_loss: 0.7767 - val_auc: 0.9915\n",
      "Epoch 3/200\n",
      " - 9s - loss: 0.8835 - auc: 0.9697 - val_loss: 0.3786 - val_auc: 0.9971\n",
      "Epoch 4/200\n",
      " - 9s - loss: 0.8233 - auc: 0.9742 - val_loss: 0.3405 - val_auc: 0.9977\n",
      "Epoch 5/200\n",
      " - 9s - loss: 0.7393 - auc: 0.9774 - val_loss: 0.2757 - val_auc: 0.9984\n",
      "Epoch 6/200\n",
      " - 9s - loss: 0.7029 - auc: 0.9805 - val_loss: 0.2575 - val_auc: 0.9990\n",
      "Epoch 7/200\n",
      " - 9s - loss: 0.6897 - auc: 0.9812 - val_loss: 0.2594 - val_auc: 0.9982\n",
      "Epoch 8/200\n",
      " - 9s - loss: 0.6213 - auc: 0.9842 - val_loss: 0.2683 - val_auc: 0.9981\n",
      "Epoch 9/200\n",
      " - 9s - loss: 0.6106 - auc: 0.9837 - val_loss: 0.2457 - val_auc: 0.9987\n",
      "Epoch 10/200\n",
      " - 9s - loss: 0.6130 - auc: 0.9824 - val_loss: 0.2256 - val_auc: 0.9989\n",
      "Epoch 11/200\n",
      " - 9s - loss: 0.6407 - auc: 0.9824 - val_loss: 0.2234 - val_auc: 0.9988\n",
      "Epoch 12/200\n",
      " - 9s - loss: 0.6247 - auc: 0.9834 - val_loss: 0.2061 - val_auc: 0.9989\n",
      "Epoch 13/200\n",
      " - 9s - loss: 0.5769 - auc: 0.9858 - val_loss: 0.2370 - val_auc: 0.9980\n",
      "Epoch 14/200\n",
      " - 9s - loss: 0.6175 - auc: 0.9798 - val_loss: 0.2358 - val_auc: 0.9986\n",
      "Epoch 15/200\n",
      " - 9s - loss: 0.5545 - auc: 0.9861 - val_loss: 0.2316 - val_auc: 0.9981\n",
      "Epoch 16/200\n",
      " - 9s - loss: 0.5198 - auc: 0.9870 - val_loss: 0.2309 - val_auc: 0.9989\n",
      "Epoch 17/200\n",
      " - 9s - loss: 0.5902 - auc: 0.9840 - val_loss: 0.2023 - val_auc: 0.9992\n",
      "Epoch 18/200\n",
      " - 9s - loss: 0.5586 - auc: 0.9854 - val_loss: 0.2038 - val_auc: 0.9992\n",
      "Epoch 19/200\n",
      " - 9s - loss: 0.5504 - auc: 0.9870 - val_loss: 0.1930 - val_auc: 0.9991\n",
      "Epoch 20/200\n",
      " - 9s - loss: 0.5307 - auc: 0.9866 - val_loss: 0.2195 - val_auc: 0.9991\n",
      "Epoch 21/200\n",
      " - 9s - loss: 0.5960 - auc: 0.9841 - val_loss: 0.2084 - val_auc: 0.9995\n",
      "Epoch 22/200\n",
      " - 9s - loss: 0.5734 - auc: 0.9859 - val_loss: 0.2007 - val_auc: 0.9993\n",
      "Epoch 23/200\n",
      " - 9s - loss: 0.5152 - auc: 0.9872 - val_loss: 0.2202 - val_auc: 0.9989\n",
      "Epoch 24/200\n",
      " - 9s - loss: 0.5779 - auc: 0.9834 - val_loss: 0.2046 - val_auc: 0.9991\n",
      "Epoch 25/200\n",
      " - 9s - loss: 0.5211 - auc: 0.9872 - val_loss: 0.2282 - val_auc: 0.9989\n",
      "Epoch 26/200\n",
      " - 9s - loss: 0.4777 - auc: 0.9887 - val_loss: 0.1966 - val_auc: 0.9990\n",
      "Epoch 27/200\n",
      " - 9s - loss: 0.5503 - auc: 0.9863 - val_loss: 0.2205 - val_auc: 0.9987\n",
      "Epoch 28/200\n",
      " - 9s - loss: 0.4866 - auc: 0.9897 - val_loss: 0.2128 - val_auc: 0.9988\n",
      "Epoch 29/200\n",
      " - 9s - loss: 0.5134 - auc: 0.9870 - val_loss: 0.2135 - val_auc: 0.9989\n",
      "Epoch 30/200\n",
      " - 9s - loss: 0.4754 - auc: 0.9871 - val_loss: 0.1941 - val_auc: 0.9992\n",
      "Epoch 31/200\n",
      " - 9s - loss: 0.4912 - auc: 0.9891 - val_loss: 0.2144 - val_auc: 0.9990\n",
      "Epoch 32/200\n",
      " - 9s - loss: 0.5523 - auc: 0.9853 - val_loss: 0.2042 - val_auc: 0.9995\n",
      "Epoch 33/200\n",
      " - 9s - loss: 0.4551 - auc: 0.9903 - val_loss: 0.2404 - val_auc: 0.9982\n",
      "Epoch 34/200\n",
      " - 9s - loss: 0.4576 - auc: 0.9888 - val_loss: 0.2088 - val_auc: 0.9980\n",
      "Epoch 35/200\n",
      " - 9s - loss: 0.4868 - auc: 0.9888 - val_loss: 0.1970 - val_auc: 0.9991\n",
      "Epoch 36/200\n",
      " - 9s - loss: 0.5094 - auc: 0.9869 - val_loss: 0.1707 - val_auc: 0.9994\n",
      "Epoch 37/200\n",
      " - 9s - loss: 0.4767 - auc: 0.9879 - val_loss: 0.2283 - val_auc: 0.9985\n",
      "Epoch 38/200\n",
      " - 9s - loss: 0.4838 - auc: 0.9876 - val_loss: 0.1695 - val_auc: 0.9991\n",
      "Epoch 39/200\n",
      " - 9s - loss: 0.4644 - auc: 0.9905 - val_loss: 0.2167 - val_auc: 0.9989\n",
      "Epoch 40/200\n",
      " - 9s - loss: 0.4967 - auc: 0.9880 - val_loss: 0.2071 - val_auc: 0.9990\n",
      "Epoch 41/200\n",
      " - 9s - loss: 0.4635 - auc: 0.9890 - val_loss: 0.2008 - val_auc: 0.9991\n",
      "Epoch 42/200\n",
      " - 9s - loss: 0.4671 - auc: 0.9889 - val_loss: 0.1949 - val_auc: 0.9992\n",
      "Epoch 43/200\n",
      " - 9s - loss: 0.4662 - auc: 0.9892 - val_loss: 0.1777 - val_auc: 0.9995\n",
      "Epoch 44/200\n",
      " - 9s - loss: 0.4693 - auc: 0.9902 - val_loss: 0.2059 - val_auc: 0.9989\n",
      "Epoch 45/200\n",
      " - 9s - loss: 0.5125 - auc: 0.9878 - val_loss: 0.1851 - val_auc: 0.9992\n",
      "Epoch 46/200\n",
      " - 9s - loss: 0.4071 - auc: 0.9925 - val_loss: 0.2001 - val_auc: 0.9992\n",
      "Epoch 47/200\n",
      " - 9s - loss: 0.4492 - auc: 0.9890 - val_loss: 0.2274 - val_auc: 0.9987\n",
      "Epoch 48/200\n",
      " - 9s - loss: 0.4712 - auc: 0.9865 - val_loss: 0.2050 - val_auc: 0.9991\n",
      "Epoch 49/200\n",
      " - 9s - loss: 0.4607 - auc: 0.9895 - val_loss: 0.2147 - val_auc: 0.9989\n",
      "Epoch 50/200\n",
      " - 9s - loss: 0.4580 - auc: 0.9897 - val_loss: 0.2101 - val_auc: 0.9986\n",
      "Epoch 51/200\n",
      " - 9s - loss: 0.4256 - auc: 0.9903 - val_loss: 0.2414 - val_auc: 0.9975\n",
      "Epoch 52/200\n",
      " - 9s - loss: 0.4311 - auc: 0.9897 - val_loss: 0.1526 - val_auc: 0.9996\n",
      "Epoch 53/200\n",
      " - 9s - loss: 0.3991 - auc: 0.9916 - val_loss: 0.1949 - val_auc: 0.9985\n",
      "Epoch 54/200\n",
      " - 9s - loss: 0.3831 - auc: 0.9926 - val_loss: 0.1938 - val_auc: 0.9991\n",
      "Epoch 55/200\n",
      " - 9s - loss: 0.4305 - auc: 0.9914 - val_loss: 0.1711 - val_auc: 0.9994\n",
      "Epoch 56/200\n",
      " - 9s - loss: 0.4164 - auc: 0.9924 - val_loss: 0.1665 - val_auc: 0.9994\n",
      "Epoch 57/200\n",
      " - 9s - loss: 0.4200 - auc: 0.9911 - val_loss: 0.1584 - val_auc: 0.9995\n",
      "Epoch 58/200\n",
      " - 9s - loss: 0.4356 - auc: 0.9897 - val_loss: 0.2091 - val_auc: 0.9990\n",
      "Epoch 59/200\n",
      " - 9s - loss: 0.4591 - auc: 0.9849 - val_loss: 0.1928 - val_auc: 0.9991\n",
      "Epoch 60/200\n",
      " - 9s - loss: 0.4328 - auc: 0.9872 - val_loss: 0.2016 - val_auc: 0.9989\n",
      "Epoch 61/200\n",
      " - 9s - loss: 0.4414 - auc: 0.9910 - val_loss: 0.1926 - val_auc: 0.9989\n",
      "Epoch 62/200\n",
      " - 9s - loss: 0.3866 - auc: 0.9927 - val_loss: 0.2049 - val_auc: 0.9990\n",
      "Epoch 63/200\n",
      " - 9s - loss: 0.4526 - auc: 0.9889 - val_loss: 0.2049 - val_auc: 0.9985\n",
      "Epoch 64/200\n",
      " - 9s - loss: 0.4305 - auc: 0.9896 - val_loss: 0.1832 - val_auc: 0.9991\n",
      "Epoch 65/200\n",
      " - 9s - loss: 0.4262 - auc: 0.9890 - val_loss: 0.1884 - val_auc: 0.9991\n",
      "Epoch 66/200\n",
      " - 9s - loss: 0.4602 - auc: 0.9883 - val_loss: 0.2171 - val_auc: 0.9988\n",
      "Epoch 67/200\n",
      " - 9s - loss: 0.4468 - auc: 0.9918 - val_loss: 0.1713 - val_auc: 0.9995\n",
      "Epoch 68/200\n",
      " - 9s - loss: 0.4107 - auc: 0.9895 - val_loss: 0.1708 - val_auc: 0.9991\n",
      "Epoch 69/200\n",
      " - 9s - loss: 0.4063 - auc: 0.9912 - val_loss: 0.1899 - val_auc: 0.9992\n",
      "Epoch 70/200\n",
      " - 9s - loss: 0.4194 - auc: 0.9890 - val_loss: 0.1923 - val_auc: 0.9991\n",
      "Epoch 71/200\n",
      " - 9s - loss: 0.4093 - auc: 0.9907 - val_loss: 0.1921 - val_auc: 0.9992\n",
      "Epoch 72/200\n",
      " - 9s - loss: 0.4229 - auc: 0.9906 - val_loss: 0.2078 - val_auc: 0.9988\n",
      "Epoch 73/200\n",
      " - 9s - loss: 0.4296 - auc: 0.9908 - val_loss: 0.1698 - val_auc: 0.9992\n",
      "Epoch 74/200\n",
      " - 9s - loss: 0.3646 - auc: 0.9936 - val_loss: 0.1625 - val_auc: 0.9994\n",
      "Epoch 75/200\n",
      " - 9s - loss: 0.4063 - auc: 0.9926 - val_loss: 0.1710 - val_auc: 0.9992\n",
      "Epoch 76/200\n",
      " - 9s - loss: 0.3978 - auc: 0.9901 - val_loss: 0.1593 - val_auc: 0.9994\n",
      "Epoch 77/200\n",
      " - 9s - loss: 0.3933 - auc: 0.9929 - val_loss: 0.1535 - val_auc: 0.9995\n",
      "Epoch 78/200\n",
      " - 9s - loss: 0.3832 - auc: 0.9916 - val_loss: 0.1976 - val_auc: 0.9983\n",
      "Epoch 79/200\n",
      " - 9s - loss: 0.3913 - auc: 0.9931 - val_loss: 0.1615 - val_auc: 0.9994\n",
      "Epoch 80/200\n",
      " - 9s - loss: 0.4009 - auc: 0.9930 - val_loss: 0.1622 - val_auc: 0.9994\n",
      "Epoch 81/200\n",
      " - 9s - loss: 0.4359 - auc: 0.9902 - val_loss: 0.1786 - val_auc: 0.9987\n",
      "Epoch 82/200\n",
      " - 9s - loss: 0.4036 - auc: 0.9914 - val_loss: 0.1955 - val_auc: 0.9985\n",
      "Epoch 83/200\n",
      " - 9s - loss: 0.3715 - auc: 0.9919 - val_loss: 0.1622 - val_auc: 0.9994\n",
      "Epoch 84/200\n",
      " - 9s - loss: 0.4076 - auc: 0.9894 - val_loss: 0.1781 - val_auc: 0.9991\n",
      "Epoch 85/200\n",
      " - 9s - loss: 0.4351 - auc: 0.9904 - val_loss: 0.2033 - val_auc: 0.9987\n",
      "Epoch 86/200\n",
      " - 9s - loss: 0.3541 - auc: 0.9941 - val_loss: 0.1633 - val_auc: 0.9994\n",
      "Epoch 87/200\n",
      " - 9s - loss: 0.3811 - auc: 0.9926 - val_loss: 0.1871 - val_auc: 0.9990\n",
      "Epoch 88/200\n",
      " - 9s - loss: 0.4085 - auc: 0.9876 - val_loss: 0.1853 - val_auc: 0.9996\n",
      "Epoch 89/200\n",
      " - 9s - loss: 0.4105 - auc: 0.9910 - val_loss: 0.1790 - val_auc: 0.9992\n",
      "Epoch 90/200\n",
      " - 9s - loss: 0.3877 - auc: 0.9924 - val_loss: 0.1666 - val_auc: 0.9989\n",
      "Epoch 91/200\n",
      " - 9s - loss: 0.3936 - auc: 0.9884 - val_loss: 0.2114 - val_auc: 0.9987\n",
      "Epoch 92/200\n",
      " - 9s - loss: 0.4172 - auc: 0.9907 - val_loss: 0.1693 - val_auc: 0.9993\n",
      "Epoch 93/200\n",
      " - 9s - loss: 0.3975 - auc: 0.9894 - val_loss: 0.1587 - val_auc: 0.9994\n",
      "Epoch 94/200\n",
      " - 9s - loss: 0.3867 - auc: 0.9920 - val_loss: 0.1924 - val_auc: 0.9990\n",
      "Epoch 95/200\n",
      " - 9s - loss: 0.3693 - auc: 0.9924 - val_loss: 0.1644 - val_auc: 0.9994\n",
      "Epoch 96/200\n",
      " - 9s - loss: 0.4097 - auc: 0.9910 - val_loss: 0.1980 - val_auc: 0.9990\n",
      "Epoch 97/200\n",
      " - 9s - loss: 0.3446 - auc: 0.9940 - val_loss: 0.1691 - val_auc: 0.9992\n",
      "Epoch 98/200\n",
      " - 9s - loss: 0.3731 - auc: 0.9915 - val_loss: 0.1524 - val_auc: 0.9994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/200\n",
      " - 9s - loss: 0.4076 - auc: 0.9911 - val_loss: 0.1569 - val_auc: 0.9993\n",
      "Epoch 100/200\n",
      " - 9s - loss: 0.3977 - auc: 0.9906 - val_loss: 0.1953 - val_auc: 0.9992\n",
      "Epoch 101/200\n",
      " - 9s - loss: 0.3849 - auc: 0.9908 - val_loss: 0.1632 - val_auc: 0.9992\n",
      "Epoch 102/200\n",
      " - 9s - loss: 0.4399 - auc: 0.9883 - val_loss: 0.2304 - val_auc: 0.9984\n",
      "Epoch 103/200\n",
      " - 9s - loss: 0.3974 - auc: 0.9906 - val_loss: 0.1831 - val_auc: 0.9992\n",
      "Epoch 104/200\n",
      " - 9s - loss: 0.3942 - auc: 0.9894 - val_loss: 0.1885 - val_auc: 0.9986\n",
      "Epoch 105/200\n",
      " - 9s - loss: 0.4432 - auc: 0.9914 - val_loss: 0.2023 - val_auc: 0.9988\n",
      "Epoch 106/200\n",
      " - 9s - loss: 0.3424 - auc: 0.9922 - val_loss: 0.1833 - val_auc: 0.9991\n",
      "Epoch 107/200\n",
      " - 9s - loss: 0.3657 - auc: 0.9928 - val_loss: 0.1942 - val_auc: 0.9991\n",
      "Epoch 108/200\n",
      " - 9s - loss: 0.3934 - auc: 0.9912 - val_loss: 0.2041 - val_auc: 0.9988\n",
      "Epoch 109/200\n",
      " - 9s - loss: 0.4031 - auc: 0.9893 - val_loss: 0.1573 - val_auc: 0.9994\n",
      "Epoch 110/200\n",
      " - 9s - loss: 0.3858 - auc: 0.9928 - val_loss: 0.1903 - val_auc: 0.9987\n",
      "Epoch 111/200\n",
      " - 9s - loss: 0.4072 - auc: 0.9916 - val_loss: 0.1609 - val_auc: 0.9991\n",
      "Epoch 112/200\n",
      " - 9s - loss: 0.3658 - auc: 0.9934 - val_loss: 0.1765 - val_auc: 0.9991\n",
      "Epoch 113/200\n",
      " - 9s - loss: 0.3596 - auc: 0.9937 - val_loss: 0.2088 - val_auc: 0.9985\n",
      "Epoch 114/200\n",
      " - 9s - loss: 0.4030 - auc: 0.9903 - val_loss: 0.1865 - val_auc: 0.9989\n",
      "Epoch 115/200\n",
      " - 9s - loss: 0.4158 - auc: 0.9899 - val_loss: 0.1535 - val_auc: 0.9995\n",
      "Epoch 116/200\n",
      " - 9s - loss: 0.3840 - auc: 0.9930 - val_loss: 0.1815 - val_auc: 0.9993\n",
      "Epoch 117/200\n",
      " - 9s - loss: 0.3744 - auc: 0.9941 - val_loss: 0.2001 - val_auc: 0.9990\n",
      "Epoch 118/200\n",
      " - 9s - loss: 0.4199 - auc: 0.9917 - val_loss: 0.2284 - val_auc: 0.9986\n",
      "Epoch 119/200\n",
      " - 9s - loss: 0.3914 - auc: 0.9924 - val_loss: 0.2022 - val_auc: 0.9993\n",
      "Epoch 120/200\n",
      " - 9s - loss: 0.3767 - auc: 0.9927 - val_loss: 0.2047 - val_auc: 0.9990\n",
      "Epoch 121/200\n",
      " - 9s - loss: 0.3835 - auc: 0.9915 - val_loss: 0.1801 - val_auc: 0.9992\n",
      "Epoch 122/200\n",
      " - 9s - loss: 0.3463 - auc: 0.9936 - val_loss: 0.1694 - val_auc: 0.9991\n",
      "Epoch 123/200\n",
      " - 9s - loss: 0.3971 - auc: 0.9913 - val_loss: 0.1766 - val_auc: 0.9993\n",
      "Epoch 124/200\n",
      " - 9s - loss: 0.3648 - auc: 0.9904 - val_loss: 0.2310 - val_auc: 0.9981\n",
      "Epoch 125/200\n",
      " - 9s - loss: 0.3797 - auc: 0.9924 - val_loss: 0.1566 - val_auc: 0.9993\n",
      "Epoch 126/200\n",
      " - 9s - loss: 0.3891 - auc: 0.9920 - val_loss: 0.1670 - val_auc: 0.9992\n",
      "Epoch 127/200\n",
      " - 9s - loss: 0.3667 - auc: 0.9936 - val_loss: 0.1572 - val_auc: 0.9995\n",
      "Epoch 128/200\n",
      " - 9s - loss: 0.3517 - auc: 0.9940 - val_loss: 0.1736 - val_auc: 0.9990\n",
      "Epoch 129/200\n",
      " - 9s - loss: 0.3770 - auc: 0.9921 - val_loss: 0.1774 - val_auc: 0.9993\n",
      "Epoch 130/200\n",
      " - 9s - loss: 0.4110 - auc: 0.9904 - val_loss: 0.1972 - val_auc: 0.9991\n",
      "Epoch 131/200\n",
      " - 9s - loss: 0.3743 - auc: 0.9920 - val_loss: 0.1528 - val_auc: 0.9995\n",
      "Epoch 132/200\n",
      " - 9s - loss: 0.3887 - auc: 0.9901 - val_loss: 0.1628 - val_auc: 0.9993\n",
      "Epoch 133/200\n",
      " - 9s - loss: 0.3458 - auc: 0.9927 - val_loss: 0.1512 - val_auc: 0.9995\n",
      "Epoch 134/200\n",
      " - 9s - loss: 0.3838 - auc: 0.9921 - val_loss: 0.1668 - val_auc: 0.9994\n",
      "Epoch 135/200\n",
      " - 9s - loss: 0.3777 - auc: 0.9925 - val_loss: 0.1482 - val_auc: 0.9994\n",
      "Epoch 136/200\n",
      " - 9s - loss: 0.3668 - auc: 0.9929 - val_loss: 0.1603 - val_auc: 0.9995\n",
      "Epoch 137/200\n",
      " - 9s - loss: 0.3766 - auc: 0.9919 - val_loss: 0.1592 - val_auc: 0.9995\n",
      "Epoch 138/200\n",
      " - 9s - loss: 0.3524 - auc: 0.9933 - val_loss: 0.1546 - val_auc: 0.9993\n",
      "Epoch 139/200\n",
      " - 9s - loss: 0.3756 - auc: 0.9929 - val_loss: 0.1564 - val_auc: 0.9993\n",
      "Epoch 140/200\n",
      " - 9s - loss: 0.3359 - auc: 0.9950 - val_loss: 0.1607 - val_auc: 0.9994\n",
      "Epoch 141/200\n",
      " - 9s - loss: 0.3553 - auc: 0.9880 - val_loss: 0.1559 - val_auc: 0.9991\n",
      "Epoch 142/200\n",
      " - 9s - loss: 0.3604 - auc: 0.9929 - val_loss: 0.1576 - val_auc: 0.9992\n",
      "Epoch 143/200\n",
      " - 9s - loss: 0.3893 - auc: 0.9917 - val_loss: 0.1694 - val_auc: 0.9994\n",
      "Epoch 144/200\n",
      " - 9s - loss: 0.3755 - auc: 0.9911 - val_loss: 0.1756 - val_auc: 0.9989\n",
      "Epoch 145/200\n",
      " - 9s - loss: 0.3521 - auc: 0.9916 - val_loss: 0.1564 - val_auc: 0.9993\n",
      "Epoch 146/200\n",
      " - 9s - loss: 0.3711 - auc: 0.9905 - val_loss: 0.1515 - val_auc: 0.9994\n",
      "Epoch 147/200\n",
      " - 9s - loss: 0.3465 - auc: 0.9938 - val_loss: 0.1574 - val_auc: 0.9992\n",
      "Epoch 148/200\n",
      " - 9s - loss: 0.3816 - auc: 0.9935 - val_loss: 0.1639 - val_auc: 0.9993\n",
      "Epoch 149/200\n",
      " - 9s - loss: 0.3738 - auc: 0.9923 - val_loss: 0.1671 - val_auc: 0.9991\n",
      "Epoch 150/200\n",
      " - 9s - loss: 0.3412 - auc: 0.9933 - val_loss: 0.1687 - val_auc: 0.9990\n",
      "Epoch 151/200\n",
      " - 9s - loss: 0.3459 - auc: 0.9939 - val_loss: 0.1724 - val_auc: 0.9992\n",
      "Epoch 152/200\n",
      " - 9s - loss: 0.3523 - auc: 0.9913 - val_loss: 0.1645 - val_auc: 0.9992\n",
      "Epoch 153/200\n",
      " - 9s - loss: 0.3531 - auc: 0.9920 - val_loss: 0.1744 - val_auc: 0.9992\n",
      "Epoch 154/200\n",
      " - 9s - loss: 0.3664 - auc: 0.9926 - val_loss: 0.1533 - val_auc: 0.9994\n",
      "Epoch 155/200\n",
      " - 9s - loss: 0.3676 - auc: 0.9912 - val_loss: 0.1566 - val_auc: 0.9995\n",
      "Epoch 156/200\n",
      " - 9s - loss: 0.3553 - auc: 0.9944 - val_loss: 0.1471 - val_auc: 0.9994\n",
      "Epoch 157/200\n",
      " - 9s - loss: 0.4317 - auc: 0.9882 - val_loss: 0.1722 - val_auc: 0.9993\n",
      "Epoch 158/200\n",
      " - 9s - loss: 0.3701 - auc: 0.9911 - val_loss: 0.1998 - val_auc: 0.9984\n",
      "Epoch 159/200\n",
      " - 9s - loss: 0.3319 - auc: 0.9938 - val_loss: 0.1655 - val_auc: 0.9989\n",
      "Epoch 160/200\n",
      " - 9s - loss: 0.3187 - auc: 0.9940 - val_loss: 0.1588 - val_auc: 0.9989\n",
      "Epoch 161/200\n",
      " - 9s - loss: 0.3379 - auc: 0.9947 - val_loss: 0.1614 - val_auc: 0.9994\n",
      "Epoch 162/200\n",
      " - 9s - loss: 0.3778 - auc: 0.9895 - val_loss: 0.1570 - val_auc: 0.9994\n",
      "Epoch 163/200\n",
      " - 9s - loss: 0.3928 - auc: 0.9918 - val_loss: 0.1688 - val_auc: 0.9989\n",
      "Epoch 164/200\n",
      " - 9s - loss: 0.3463 - auc: 0.9938 - val_loss: 0.1578 - val_auc: 0.9993\n",
      "Epoch 165/200\n",
      " - 9s - loss: 0.3366 - auc: 0.9936 - val_loss: 0.1613 - val_auc: 0.9993\n",
      "Epoch 166/200\n",
      " - 9s - loss: 0.3273 - auc: 0.9943 - val_loss: 0.1579 - val_auc: 0.9994\n",
      "Epoch 167/200\n",
      " - 9s - loss: 0.3371 - auc: 0.9941 - val_loss: 0.1649 - val_auc: 0.9991\n",
      "Epoch 168/200\n",
      " - 9s - loss: 0.3546 - auc: 0.9928 - val_loss: 0.1831 - val_auc: 0.9990\n",
      "Epoch 169/200\n",
      " - 9s - loss: 0.3476 - auc: 0.9942 - val_loss: 0.1778 - val_auc: 0.9992\n",
      "Epoch 170/200\n",
      " - 9s - loss: 0.3185 - auc: 0.9941 - val_loss: 0.1627 - val_auc: 0.9989\n",
      "Epoch 171/200\n",
      " - 9s - loss: 0.3869 - auc: 0.9920 - val_loss: 0.1704 - val_auc: 0.9991\n",
      "Epoch 172/200\n",
      " - 9s - loss: 0.3507 - auc: 0.9907 - val_loss: 0.1511 - val_auc: 0.9993\n",
      "Epoch 173/200\n",
      " - 9s - loss: 0.4195 - auc: 0.9901 - val_loss: 0.1803 - val_auc: 0.9990\n",
      "Epoch 174/200\n",
      " - 9s - loss: 0.3318 - auc: 0.9949 - val_loss: 0.1809 - val_auc: 0.9989\n",
      "Epoch 175/200\n",
      " - 9s - loss: 0.3806 - auc: 0.9927 - val_loss: 0.1481 - val_auc: 0.9994\n",
      "Epoch 176/200\n",
      " - 9s - loss: 0.3634 - auc: 0.9933 - val_loss: 0.1668 - val_auc: 0.9992\n",
      "Epoch 177/200\n",
      " - 9s - loss: 0.3596 - auc: 0.9928 - val_loss: 0.1682 - val_auc: 0.9992\n",
      "Epoch 178/200\n",
      " - 9s - loss: 0.3485 - auc: 0.9942 - val_loss: 0.1837 - val_auc: 0.9990\n",
      "Epoch 179/200\n",
      " - 9s - loss: 0.3194 - auc: 0.9937 - val_loss: 0.1665 - val_auc: 0.9993\n",
      "Epoch 180/200\n",
      " - 9s - loss: 0.3561 - auc: 0.9928 - val_loss: 0.1754 - val_auc: 0.9989\n",
      "Epoch 181/200\n",
      " - 9s - loss: 0.3404 - auc: 0.9943 - val_loss: 0.1909 - val_auc: 0.9987\n",
      "Epoch 182/200\n",
      " - 9s - loss: 0.3487 - auc: 0.9940 - val_loss: 0.1670 - val_auc: 0.9991\n",
      "Epoch 183/200\n",
      " - 9s - loss: 0.3622 - auc: 0.9930 - val_loss: 0.1856 - val_auc: 0.9991\n",
      "Epoch 184/200\n",
      " - 9s - loss: 0.3220 - auc: 0.9933 - val_loss: 0.2059 - val_auc: 0.9987\n",
      "Epoch 185/200\n",
      " - 9s - loss: 0.3860 - auc: 0.9926 - val_loss: 0.1951 - val_auc: 0.9989\n",
      "Epoch 186/200\n",
      " - 9s - loss: 0.3362 - auc: 0.9942 - val_loss: 0.1693 - val_auc: 0.9990\n",
      "Epoch 187/200\n",
      " - 9s - loss: 0.3503 - auc: 0.9941 - val_loss: 0.1591 - val_auc: 0.9993\n",
      "Epoch 188/200\n",
      " - 9s - loss: 0.3689 - auc: 0.9901 - val_loss: 0.1697 - val_auc: 0.9994\n",
      "Epoch 189/200\n",
      " - 9s - loss: 0.3571 - auc: 0.9929 - val_loss: 0.1707 - val_auc: 0.9993\n",
      "Epoch 190/200\n",
      " - 9s - loss: 0.3737 - auc: 0.9932 - val_loss: 0.1667 - val_auc: 0.9993\n",
      "Epoch 191/200\n",
      " - 9s - loss: 0.3453 - auc: 0.9945 - val_loss: 0.1726 - val_auc: 0.9990\n",
      "Epoch 192/200\n",
      " - 9s - loss: 0.3402 - auc: 0.9929 - val_loss: 0.1357 - val_auc: 0.9996\n",
      "Epoch 193/200\n",
      " - 9s - loss: 0.3436 - auc: 0.9922 - val_loss: 0.1737 - val_auc: 0.9991\n",
      "Epoch 194/200\n",
      " - 9s - loss: 0.3498 - auc: 0.9929 - val_loss: 0.1574 - val_auc: 0.9995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 195/200\n",
      " - 9s - loss: 0.3524 - auc: 0.9922 - val_loss: 0.1523 - val_auc: 0.9995\n",
      "Epoch 196/200\n",
      " - 9s - loss: 0.3430 - auc: 0.9943 - val_loss: 0.1408 - val_auc: 0.9993\n",
      "Epoch 197/200\n",
      " - 9s - loss: 0.3235 - auc: 0.9940 - val_loss: 0.1549 - val_auc: 0.9993\n",
      "Epoch 198/200\n",
      " - 9s - loss: 0.3322 - auc: 0.9948 - val_loss: 0.1556 - val_auc: 0.9994\n",
      "Epoch 199/200\n",
      " - 9s - loss: 0.3405 - auc: 0.9934 - val_loss: 0.1683 - val_auc: 0.9992\n",
      "Epoch 200/200\n",
      " - 9s - loss: 0.3370 - auc: 0.9943 - val_loss: 0.2404 - val_auc: 0.9979\n",
      "SVMSMOTE,MIT-BIH Normal Sinus Rhythm Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keg/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:80: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2000 samples, validate on 263 samples\n",
      "Epoch 1/200\n",
      " - 50s - loss: 1.5068 - auc: 0.9035 - val_loss: 1.7241 - val_auc: 0.9624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keg/anaconda3/lib/python3.6/site-packages/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `roc_accuracy` which is not available. Available metrics are: val_loss,val_auc,loss,auc,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200\n",
      " - 10s - loss: 0.9313 - auc: 0.9689 - val_loss: 0.7112 - val_auc: 0.9882\n",
      "Epoch 3/200\n",
      " - 10s - loss: 0.8077 - auc: 0.9758 - val_loss: 0.4419 - val_auc: 0.9893\n",
      "Epoch 4/200\n",
      " - 10s - loss: 0.7802 - auc: 0.9766 - val_loss: 0.3878 - val_auc: 0.9924\n",
      "Epoch 5/200\n",
      " - 10s - loss: 0.7108 - auc: 0.9797 - val_loss: 0.3853 - val_auc: 0.9899\n",
      "Epoch 6/200\n",
      " - 10s - loss: 0.6476 - auc: 0.9838 - val_loss: 0.3672 - val_auc: 0.9901\n",
      "Epoch 7/200\n",
      " - 10s - loss: 0.6465 - auc: 0.9831 - val_loss: 0.3385 - val_auc: 0.9934\n",
      "Epoch 8/200\n",
      " - 10s - loss: 0.6047 - auc: 0.9854 - val_loss: 0.3590 - val_auc: 0.9907\n",
      "Epoch 9/200\n",
      " - 10s - loss: 0.5984 - auc: 0.9854 - val_loss: 0.3815 - val_auc: 0.9905\n",
      "Epoch 10/200\n",
      " - 10s - loss: 0.5843 - auc: 0.9859 - val_loss: 0.3227 - val_auc: 0.9912\n",
      "Epoch 11/200\n",
      " - 10s - loss: 0.5738 - auc: 0.9858 - val_loss: 0.3179 - val_auc: 0.9939\n",
      "Epoch 12/200\n",
      " - 10s - loss: 0.5615 - auc: 0.9853 - val_loss: 0.3402 - val_auc: 0.9931\n",
      "Epoch 13/200\n",
      " - 10s - loss: 0.5961 - auc: 0.9837 - val_loss: 0.3291 - val_auc: 0.9904\n",
      "Epoch 14/200\n",
      " - 10s - loss: 0.5719 - auc: 0.9864 - val_loss: 0.3514 - val_auc: 0.9926\n",
      "Epoch 15/200\n",
      " - 10s - loss: 0.5995 - auc: 0.9826 - val_loss: 0.3383 - val_auc: 0.9908\n",
      "Epoch 16/200\n",
      " - 10s - loss: 0.5543 - auc: 0.9871 - val_loss: 0.3561 - val_auc: 0.9930\n",
      "Epoch 17/200\n",
      " - 10s - loss: 0.5851 - auc: 0.9848 - val_loss: 0.3069 - val_auc: 0.9910\n",
      "Epoch 18/200\n",
      " - 10s - loss: 0.4484 - auc: 0.9917 - val_loss: 0.3537 - val_auc: 0.9904\n",
      "Epoch 19/200\n",
      " - 10s - loss: 0.5515 - auc: 0.9862 - val_loss: 0.3667 - val_auc: 0.9917\n",
      "Epoch 20/200\n",
      " - 10s - loss: 0.5765 - auc: 0.9857 - val_loss: 0.3617 - val_auc: 0.9904\n",
      "Epoch 21/200\n",
      " - 10s - loss: 0.4968 - auc: 0.9888 - val_loss: 0.2919 - val_auc: 0.9942\n",
      "Epoch 22/200\n",
      " - 10s - loss: 0.5051 - auc: 0.9878 - val_loss: 0.2969 - val_auc: 0.9940\n",
      "Epoch 23/200\n",
      " - 10s - loss: 0.4687 - auc: 0.9887 - val_loss: 0.3075 - val_auc: 0.9936\n",
      "Epoch 24/200\n",
      " - 10s - loss: 0.5096 - auc: 0.9874 - val_loss: 0.2704 - val_auc: 0.9945\n",
      "Epoch 25/200\n",
      " - 10s - loss: 0.4801 - auc: 0.9892 - val_loss: 0.2925 - val_auc: 0.9935\n",
      "Epoch 26/200\n",
      " - 10s - loss: 0.4886 - auc: 0.9887 - val_loss: 0.2895 - val_auc: 0.9941\n",
      "Epoch 27/200\n",
      " - 10s - loss: 0.5159 - auc: 0.9877 - val_loss: 0.3267 - val_auc: 0.9929\n",
      "Epoch 28/200\n",
      " - 10s - loss: 0.5360 - auc: 0.9865 - val_loss: 0.3308 - val_auc: 0.9908\n",
      "Epoch 29/200\n",
      " - 10s - loss: 0.4842 - auc: 0.9890 - val_loss: 0.3241 - val_auc: 0.9903\n",
      "Epoch 30/200\n",
      " - 10s - loss: 0.4386 - auc: 0.9916 - val_loss: 0.2900 - val_auc: 0.9912\n",
      "Epoch 31/200\n",
      " - 10s - loss: 0.4760 - auc: 0.9895 - val_loss: 0.3010 - val_auc: 0.9934\n",
      "Epoch 32/200\n",
      " - 10s - loss: 0.4497 - auc: 0.9899 - val_loss: 0.3218 - val_auc: 0.9931\n",
      "Epoch 33/200\n",
      " - 10s - loss: 0.4797 - auc: 0.9883 - val_loss: 0.2926 - val_auc: 0.9940\n",
      "Epoch 34/200\n",
      " - 10s - loss: 0.4609 - auc: 0.9894 - val_loss: 0.2767 - val_auc: 0.9939\n",
      "Epoch 35/200\n",
      " - 10s - loss: 0.4721 - auc: 0.9885 - val_loss: 0.2719 - val_auc: 0.9942\n",
      "Epoch 36/200\n",
      " - 10s - loss: 0.4706 - auc: 0.9890 - val_loss: 0.2955 - val_auc: 0.9956\n",
      "Epoch 37/200\n",
      " - 10s - loss: 0.4589 - auc: 0.9900 - val_loss: 0.3148 - val_auc: 0.9908\n",
      "Epoch 38/200\n",
      " - 10s - loss: 0.4427 - auc: 0.9906 - val_loss: 0.3103 - val_auc: 0.9932\n",
      "Epoch 39/200\n",
      " - 10s - loss: 0.4323 - auc: 0.9901 - val_loss: 0.2951 - val_auc: 0.9932\n",
      "Epoch 40/200\n",
      " - 10s - loss: 0.4419 - auc: 0.9904 - val_loss: 0.2921 - val_auc: 0.9964\n",
      "Epoch 41/200\n",
      " - 10s - loss: 0.4415 - auc: 0.9912 - val_loss: 0.3006 - val_auc: 0.9935\n",
      "Epoch 42/200\n",
      " - 10s - loss: 0.4483 - auc: 0.9904 - val_loss: 0.3006 - val_auc: 0.9938\n",
      "Epoch 43/200\n",
      " - 10s - loss: 0.4096 - auc: 0.9909 - val_loss: 0.2799 - val_auc: 0.9942\n",
      "Epoch 44/200\n",
      " - 10s - loss: 0.4560 - auc: 0.9894 - val_loss: 0.2947 - val_auc: 0.9934\n",
      "Epoch 45/200\n",
      " - 10s - loss: 0.4160 - auc: 0.9913 - val_loss: 0.2888 - val_auc: 0.9945\n",
      "Epoch 46/200\n",
      " - 10s - loss: 0.4298 - auc: 0.9905 - val_loss: 0.2453 - val_auc: 0.9953\n",
      "Epoch 47/200\n",
      " - 10s - loss: 0.3769 - auc: 0.9936 - val_loss: 0.3117 - val_auc: 0.9935\n",
      "Epoch 48/200\n",
      " - 10s - loss: 0.4423 - auc: 0.9897 - val_loss: 0.2679 - val_auc: 0.9947\n",
      "Epoch 49/200\n",
      " - 10s - loss: 0.3846 - auc: 0.9930 - val_loss: 0.2756 - val_auc: 0.9952\n",
      "Epoch 50/200\n",
      " - 10s - loss: 0.4030 - auc: 0.9920 - val_loss: 0.2770 - val_auc: 0.9942\n",
      "Epoch 51/200\n",
      " - 10s - loss: 0.4125 - auc: 0.9912 - val_loss: 0.3061 - val_auc: 0.9934\n",
      "Epoch 52/200\n",
      " - 10s - loss: 0.4190 - auc: 0.9902 - val_loss: 0.2600 - val_auc: 0.9948\n",
      "Epoch 53/200\n",
      " - 10s - loss: 0.4334 - auc: 0.9893 - val_loss: 0.2865 - val_auc: 0.9946\n",
      "Epoch 54/200\n",
      " - 10s - loss: 0.4392 - auc: 0.9892 - val_loss: 0.2707 - val_auc: 0.9913\n",
      "Epoch 55/200\n",
      " - 10s - loss: 0.4226 - auc: 0.9894 - val_loss: 0.2657 - val_auc: 0.9945\n",
      "Epoch 56/200\n",
      " - 10s - loss: 0.4244 - auc: 0.9914 - val_loss: 0.2765 - val_auc: 0.9938\n",
      "Epoch 57/200\n",
      " - 10s - loss: 0.3938 - auc: 0.9926 - val_loss: 0.2690 - val_auc: 0.9914\n",
      "Epoch 58/200\n",
      " - 10s - loss: 0.3834 - auc: 0.9927 - val_loss: 0.2679 - val_auc: 0.9944\n",
      "Epoch 59/200\n",
      " - 10s - loss: 0.4082 - auc: 0.9912 - val_loss: 0.2832 - val_auc: 0.9914\n",
      "Epoch 60/200\n",
      " - 10s - loss: 0.4031 - auc: 0.9920 - val_loss: 0.3085 - val_auc: 0.9938\n",
      "Epoch 61/200\n",
      " - 10s - loss: 0.3864 - auc: 0.9910 - val_loss: 0.2863 - val_auc: 0.9935\n",
      "Epoch 62/200\n",
      " - 10s - loss: 0.3784 - auc: 0.9929 - val_loss: 0.2593 - val_auc: 0.9947\n",
      "Epoch 63/200\n",
      " - 10s - loss: 0.4005 - auc: 0.9908 - val_loss: 0.2822 - val_auc: 0.9906\n",
      "Epoch 64/200\n",
      " - 10s - loss: 0.4068 - auc: 0.9911 - val_loss: 0.2350 - val_auc: 0.9951\n",
      "Epoch 65/200\n",
      " - 10s - loss: 0.4069 - auc: 0.9913 - val_loss: 0.2795 - val_auc: 0.9940\n",
      "Epoch 66/200\n",
      " - 10s - loss: 0.4028 - auc: 0.9905 - val_loss: 0.2718 - val_auc: 0.9970\n",
      "Epoch 67/200\n",
      " - 10s - loss: 0.4103 - auc: 0.9908 - val_loss: 0.2864 - val_auc: 0.9940\n",
      "Epoch 68/200\n",
      " - 10s - loss: 0.4141 - auc: 0.9916 - val_loss: 0.2731 - val_auc: 0.9943\n",
      "Epoch 69/200\n",
      " - 10s - loss: 0.4058 - auc: 0.9919 - val_loss: 0.2625 - val_auc: 0.9949\n",
      "Epoch 70/200\n",
      " - 10s - loss: 0.3889 - auc: 0.9916 - val_loss: 0.3228 - val_auc: 0.9928\n",
      "Epoch 71/200\n",
      " - 10s - loss: 0.4222 - auc: 0.9920 - val_loss: 0.2792 - val_auc: 0.9938\n",
      "Epoch 72/200\n",
      " - 10s - loss: 0.3826 - auc: 0.9918 - val_loss: 0.2636 - val_auc: 0.9943\n",
      "Epoch 73/200\n",
      " - 10s - loss: 0.3994 - auc: 0.9914 - val_loss: 0.2668 - val_auc: 0.9914\n",
      "Epoch 74/200\n",
      " - 10s - loss: 0.3897 - auc: 0.9911 - val_loss: 0.2540 - val_auc: 0.9949\n",
      "Epoch 75/200\n",
      " - 10s - loss: 0.4159 - auc: 0.9915 - val_loss: 0.2976 - val_auc: 0.9935\n",
      "Epoch 76/200\n",
      " - 10s - loss: 0.3873 - auc: 0.9918 - val_loss: 0.2900 - val_auc: 0.9942\n",
      "Epoch 77/200\n",
      " - 10s - loss: 0.3892 - auc: 0.9927 - val_loss: 0.3054 - val_auc: 0.9936\n",
      "Epoch 78/200\n",
      " - 10s - loss: 0.3820 - auc: 0.9922 - val_loss: 0.2408 - val_auc: 0.9950\n",
      "Epoch 79/200\n",
      " - 10s - loss: 0.4117 - auc: 0.9902 - val_loss: 0.2539 - val_auc: 0.9949\n",
      "Epoch 80/200\n",
      " - 10s - loss: 0.3913 - auc: 0.9913 - val_loss: 0.2528 - val_auc: 0.9947\n",
      "Epoch 81/200\n",
      " - 10s - loss: 0.3776 - auc: 0.9929 - val_loss: 0.2692 - val_auc: 0.9949\n",
      "Epoch 82/200\n",
      " - 10s - loss: 0.3829 - auc: 0.9914 - val_loss: 0.2674 - val_auc: 0.9946\n",
      "Epoch 83/200\n",
      " - 10s - loss: 0.4010 - auc: 0.9911 - val_loss: 0.2575 - val_auc: 0.9949\n",
      "Epoch 84/200\n",
      " - 10s - loss: 0.3898 - auc: 0.9914 - val_loss: 0.2615 - val_auc: 0.9946\n",
      "Epoch 85/200\n",
      " - 10s - loss: 0.3730 - auc: 0.9925 - val_loss: 0.3074 - val_auc: 0.9937\n",
      "Epoch 86/200\n",
      " - 10s - loss: 0.3939 - auc: 0.9916 - val_loss: 0.2564 - val_auc: 0.9947\n",
      "Epoch 87/200\n",
      " - 10s - loss: 0.3875 - auc: 0.9900 - val_loss: 0.2635 - val_auc: 0.9947\n",
      "Epoch 88/200\n",
      " - 10s - loss: 0.3952 - auc: 0.9921 - val_loss: 0.2636 - val_auc: 0.9944\n",
      "Epoch 89/200\n",
      " - 10s - loss: 0.3864 - auc: 0.9909 - val_loss: 0.2755 - val_auc: 0.9945\n",
      "Epoch 90/200\n",
      " - 10s - loss: 0.3805 - auc: 0.9910 - val_loss: 0.2575 - val_auc: 0.9944\n",
      "Epoch 91/200\n",
      " - 10s - loss: 0.3907 - auc: 0.9919 - val_loss: 0.2582 - val_auc: 0.9950\n",
      "Epoch 92/200\n",
      " - 10s - loss: 0.3759 - auc: 0.9925 - val_loss: 0.2718 - val_auc: 0.9944\n",
      "Epoch 93/200\n",
      " - 10s - loss: 0.3291 - auc: 0.9932 - val_loss: 0.2503 - val_auc: 0.9972\n",
      "Epoch 94/200\n",
      " - 10s - loss: 0.3985 - auc: 0.9905 - val_loss: 0.2212 - val_auc: 0.9982\n",
      "Epoch 95/200\n",
      " - 10s - loss: 0.3774 - auc: 0.9926 - val_loss: 0.2502 - val_auc: 0.9948\n",
      "Epoch 96/200\n",
      " - 10s - loss: 0.3927 - auc: 0.9915 - val_loss: 0.2295 - val_auc: 0.9982\n",
      "Epoch 97/200\n",
      " - 10s - loss: 0.3947 - auc: 0.9915 - val_loss: 0.2483 - val_auc: 0.9977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/200\n",
      " - 10s - loss: 0.3374 - auc: 0.9943 - val_loss: 0.3086 - val_auc: 0.9958\n",
      "Epoch 99/200\n",
      " - 10s - loss: 0.3859 - auc: 0.9917 - val_loss: 0.2570 - val_auc: 0.9973\n",
      "Epoch 100/200\n",
      " - 10s - loss: 0.3536 - auc: 0.9940 - val_loss: 0.3073 - val_auc: 0.9934\n",
      "Epoch 101/200\n",
      " - 10s - loss: 0.3730 - auc: 0.9920 - val_loss: 0.2692 - val_auc: 0.9945\n",
      "Epoch 102/200\n",
      " - 10s - loss: 0.3913 - auc: 0.9913 - val_loss: 0.2550 - val_auc: 0.9945\n",
      "Epoch 103/200\n",
      " - 10s - loss: 0.3641 - auc: 0.9924 - val_loss: 0.2862 - val_auc: 0.9938\n",
      "Epoch 104/200\n",
      " - 10s - loss: 0.3360 - auc: 0.9944 - val_loss: 0.2612 - val_auc: 0.9972\n",
      "Epoch 105/200\n",
      " - 10s - loss: 0.3414 - auc: 0.9926 - val_loss: 0.3078 - val_auc: 0.9960\n",
      "Epoch 106/200\n",
      " - 10s - loss: 0.3706 - auc: 0.9918 - val_loss: 0.2491 - val_auc: 0.9947\n",
      "Epoch 107/200\n",
      " - 10s - loss: 0.3344 - auc: 0.9926 - val_loss: 0.2660 - val_auc: 0.9968\n",
      "Epoch 108/200\n",
      " - 10s - loss: 0.3805 - auc: 0.9933 - val_loss: 0.2324 - val_auc: 0.9951\n",
      "Epoch 109/200\n",
      " - 10s - loss: 0.3580 - auc: 0.9935 - val_loss: 0.2373 - val_auc: 0.9976\n",
      "Epoch 110/200\n",
      " - 10s - loss: 0.4198 - auc: 0.9890 - val_loss: 0.2546 - val_auc: 0.9947\n",
      "Epoch 111/200\n",
      " - 10s - loss: 0.3355 - auc: 0.9944 - val_loss: 0.2763 - val_auc: 0.9942\n",
      "Epoch 112/200\n",
      " - 10s - loss: 0.3491 - auc: 0.9932 - val_loss: 0.2337 - val_auc: 0.9950\n",
      "Epoch 113/200\n",
      " - 10s - loss: 0.3805 - auc: 0.9926 - val_loss: 0.2511 - val_auc: 0.9944\n",
      "Epoch 114/200\n",
      " - 10s - loss: 0.3653 - auc: 0.9929 - val_loss: 0.2552 - val_auc: 0.9975\n",
      "Epoch 115/200\n",
      " - 10s - loss: 0.3732 - auc: 0.9915 - val_loss: 0.2772 - val_auc: 0.9964\n",
      "Epoch 116/200\n",
      " - 10s - loss: 0.3525 - auc: 0.9924 - val_loss: 0.2514 - val_auc: 0.9971\n",
      "Epoch 117/200\n",
      " - 10s - loss: 0.3304 - auc: 0.9953 - val_loss: 0.2950 - val_auc: 0.9965\n",
      "Epoch 118/200\n",
      " - 10s - loss: 0.3589 - auc: 0.9929 - val_loss: 0.2520 - val_auc: 0.9977\n",
      "Epoch 119/200\n",
      " - 10s - loss: 0.3306 - auc: 0.9946 - val_loss: 0.2612 - val_auc: 0.9946\n",
      "Epoch 120/200\n",
      " - 10s - loss: 0.3311 - auc: 0.9942 - val_loss: 0.2508 - val_auc: 0.9971\n",
      "Epoch 121/200\n",
      " - 10s - loss: 0.3348 - auc: 0.9942 - val_loss: 0.2577 - val_auc: 0.9948\n",
      "Epoch 122/200\n",
      " - 10s - loss: 0.3524 - auc: 0.9934 - val_loss: 0.2351 - val_auc: 0.9979\n",
      "Epoch 123/200\n",
      " - 10s - loss: 0.3264 - auc: 0.9944 - val_loss: 0.2643 - val_auc: 0.9943\n",
      "Epoch 124/200\n",
      " - 10s - loss: 0.3550 - auc: 0.9933 - val_loss: 0.2761 - val_auc: 0.9968\n",
      "Epoch 125/200\n",
      " - 10s - loss: 0.3631 - auc: 0.9927 - val_loss: 0.2264 - val_auc: 0.9980\n",
      "Epoch 126/200\n",
      " - 10s - loss: 0.3353 - auc: 0.9942 - val_loss: 0.2257 - val_auc: 0.9979\n",
      "Epoch 127/200\n",
      " - 10s - loss: 0.3560 - auc: 0.9924 - val_loss: 0.2412 - val_auc: 0.9976\n",
      "Epoch 128/200\n",
      " - 10s - loss: 0.3521 - auc: 0.9936 - val_loss: 0.2314 - val_auc: 0.9951\n",
      "Epoch 129/200\n",
      " - 10s - loss: 0.3258 - auc: 0.9944 - val_loss: 0.2439 - val_auc: 0.9975\n",
      "Epoch 130/200\n",
      " - 10s - loss: 0.3420 - auc: 0.9935 - val_loss: 0.2212 - val_auc: 0.9984\n",
      "Epoch 131/200\n",
      " - 10s - loss: 0.3664 - auc: 0.9918 - val_loss: 0.2783 - val_auc: 0.9939\n",
      "Epoch 132/200\n",
      " - 10s - loss: 0.3210 - auc: 0.9940 - val_loss: 0.2285 - val_auc: 0.9979\n",
      "Epoch 133/200\n",
      " - 10s - loss: 0.3575 - auc: 0.9935 - val_loss: 0.1981 - val_auc: 0.9985\n",
      "Epoch 134/200\n",
      " - 10s - loss: 0.3077 - auc: 0.9949 - val_loss: 0.2201 - val_auc: 0.9982\n",
      "Epoch 135/200\n",
      " - 10s - loss: 0.3052 - auc: 0.9956 - val_loss: 0.2304 - val_auc: 0.9983\n",
      "Epoch 136/200\n",
      " - 10s - loss: 0.3426 - auc: 0.9927 - val_loss: 0.2398 - val_auc: 0.9976\n",
      "Epoch 137/200\n",
      " - 10s - loss: 0.3782 - auc: 0.9927 - val_loss: 0.2510 - val_auc: 0.9977\n",
      "Epoch 138/200\n",
      " - 10s - loss: 0.3542 - auc: 0.9920 - val_loss: 0.2722 - val_auc: 0.9971\n",
      "Epoch 139/200\n",
      " - 10s - loss: 0.3389 - auc: 0.9941 - val_loss: 0.2646 - val_auc: 0.9973\n",
      "Epoch 140/200\n",
      " - 10s - loss: 0.3179 - auc: 0.9948 - val_loss: 0.2475 - val_auc: 0.9975\n",
      "Epoch 141/200\n",
      " - 10s - loss: 0.3365 - auc: 0.9931 - val_loss: 0.2366 - val_auc: 0.9979\n",
      "Epoch 142/200\n",
      " - 10s - loss: 0.3595 - auc: 0.9925 - val_loss: 0.2095 - val_auc: 0.9988\n",
      "Epoch 143/200\n",
      " - 10s - loss: 0.3075 - auc: 0.9949 - val_loss: 0.2338 - val_auc: 0.9980\n",
      "Epoch 144/200\n",
      " - 10s - loss: 0.3708 - auc: 0.9912 - val_loss: 0.2835 - val_auc: 0.9967\n",
      "Epoch 145/200\n",
      " - 10s - loss: 0.4046 - auc: 0.9897 - val_loss: 0.2149 - val_auc: 0.9983\n",
      "Epoch 146/200\n",
      " - 10s - loss: 0.3661 - auc: 0.9934 - val_loss: 0.2473 - val_auc: 0.9975\n",
      "Epoch 147/200\n",
      " - 10s - loss: 0.3224 - auc: 0.9946 - val_loss: 0.2489 - val_auc: 0.9978\n",
      "Epoch 148/200\n",
      " - 10s - loss: 0.3066 - auc: 0.9957 - val_loss: 0.2231 - val_auc: 0.9983\n",
      "Epoch 149/200\n",
      " - 10s - loss: 0.3025 - auc: 0.9952 - val_loss: 0.2961 - val_auc: 0.9965\n",
      "Epoch 150/200\n",
      " - 10s - loss: 0.3266 - auc: 0.9931 - val_loss: 0.2344 - val_auc: 0.9978\n",
      "Epoch 151/200\n",
      " - 10s - loss: 0.3625 - auc: 0.9912 - val_loss: 0.2156 - val_auc: 0.9982\n",
      "Epoch 152/200\n",
      " - 10s - loss: 0.3439 - auc: 0.9926 - val_loss: 0.2160 - val_auc: 0.9980\n",
      "Epoch 153/200\n",
      " - 10s - loss: 0.3558 - auc: 0.9927 - val_loss: 0.2373 - val_auc: 0.9977\n",
      "Epoch 154/200\n",
      " - 10s - loss: 0.3449 - auc: 0.9942 - val_loss: 0.2280 - val_auc: 0.9978\n",
      "Epoch 155/200\n",
      " - 10s - loss: 0.3365 - auc: 0.9940 - val_loss: 0.2314 - val_auc: 0.9949\n",
      "Epoch 156/200\n",
      " - 10s - loss: 0.3282 - auc: 0.9933 - val_loss: 0.2403 - val_auc: 0.9979\n",
      "Epoch 157/200\n",
      " - 10s - loss: 0.3569 - auc: 0.9918 - val_loss: 0.2439 - val_auc: 0.9980\n",
      "Epoch 158/200\n",
      " - 10s - loss: 0.3161 - auc: 0.9946 - val_loss: 0.2091 - val_auc: 0.9983\n",
      "Epoch 159/200\n",
      " - 10s - loss: 0.3478 - auc: 0.9929 - val_loss: 0.2448 - val_auc: 0.9975\n",
      "Epoch 160/200\n",
      " - 10s - loss: 0.3407 - auc: 0.9934 - val_loss: 0.2626 - val_auc: 0.9973\n",
      "Epoch 161/200\n",
      " - 10s - loss: 0.3315 - auc: 0.9941 - val_loss: 0.2422 - val_auc: 0.9975\n",
      "Epoch 162/200\n",
      " - 10s - loss: 0.3079 - auc: 0.9951 - val_loss: 0.2329 - val_auc: 0.9981\n",
      "Epoch 163/200\n",
      " - 10s - loss: 0.3530 - auc: 0.9934 - val_loss: 0.2470 - val_auc: 0.9972\n",
      "Epoch 164/200\n",
      " - 10s - loss: 0.3231 - auc: 0.9933 - val_loss: 0.2334 - val_auc: 0.9981\n",
      "Epoch 165/200\n",
      " - 10s - loss: 0.3064 - auc: 0.9958 - val_loss: 0.2276 - val_auc: 0.9983\n",
      "Epoch 166/200\n",
      " - 10s - loss: 0.3204 - auc: 0.9948 - val_loss: 0.2458 - val_auc: 0.9981\n",
      "Epoch 167/200\n",
      " - 10s - loss: 0.3089 - auc: 0.9947 - val_loss: 0.2101 - val_auc: 0.9987\n",
      "Epoch 168/200\n",
      " - 10s - loss: 0.3487 - auc: 0.9925 - val_loss: 0.2366 - val_auc: 0.9978\n",
      "Epoch 169/200\n",
      " - 10s - loss: 0.3509 - auc: 0.9919 - val_loss: 0.1957 - val_auc: 0.9987\n",
      "Epoch 170/200\n",
      " - 10s - loss: 0.3463 - auc: 0.9920 - val_loss: 0.2600 - val_auc: 0.9975\n",
      "Epoch 171/200\n",
      " - 10s - loss: 0.3330 - auc: 0.9936 - val_loss: 0.2122 - val_auc: 0.9985\n",
      "Epoch 172/200\n",
      " - 10s - loss: 0.3152 - auc: 0.9948 - val_loss: 0.2214 - val_auc: 0.9984\n",
      "Epoch 173/200\n",
      " - 10s - loss: 0.3287 - auc: 0.9933 - val_loss: 0.2267 - val_auc: 0.9978\n",
      "Epoch 174/200\n",
      " - 10s - loss: 0.3179 - auc: 0.9938 - val_loss: 0.2611 - val_auc: 0.9971\n",
      "Epoch 175/200\n",
      " - 10s - loss: 0.3483 - auc: 0.9935 - val_loss: 0.2372 - val_auc: 0.9979\n",
      "Epoch 176/200\n",
      " - 10s - loss: 0.3352 - auc: 0.9942 - val_loss: 0.2071 - val_auc: 0.9983\n",
      "Epoch 177/200\n",
      " - 10s - loss: 0.2814 - auc: 0.9964 - val_loss: 0.2328 - val_auc: 0.9979\n",
      "Epoch 178/200\n",
      " - 10s - loss: 0.3383 - auc: 0.9931 - val_loss: 0.2411 - val_auc: 0.9975\n",
      "Epoch 179/200\n",
      " - 10s - loss: 0.3338 - auc: 0.9936 - val_loss: 0.2509 - val_auc: 0.9972\n",
      "Epoch 180/200\n",
      " - 10s - loss: 0.3386 - auc: 0.9932 - val_loss: 0.2065 - val_auc: 0.9986\n",
      "Epoch 181/200\n",
      " - 10s - loss: 0.2951 - auc: 0.9948 - val_loss: 0.2222 - val_auc: 0.9986\n",
      "Epoch 182/200\n",
      " - 10s - loss: 0.3171 - auc: 0.9940 - val_loss: 0.2214 - val_auc: 0.9983\n",
      "Epoch 183/200\n",
      " - 10s - loss: 0.3623 - auc: 0.9917 - val_loss: 0.2158 - val_auc: 0.9986\n",
      "Epoch 184/200\n",
      " - 10s - loss: 0.3333 - auc: 0.9940 - val_loss: 0.3107 - val_auc: 0.9957\n",
      "Epoch 185/200\n",
      " - 10s - loss: 0.3527 - auc: 0.9934 - val_loss: 0.2326 - val_auc: 0.9981\n",
      "Epoch 186/200\n",
      " - 10s - loss: 0.3377 - auc: 0.9931 - val_loss: 0.2342 - val_auc: 0.9978\n",
      "Epoch 187/200\n",
      " - 10s - loss: 0.3336 - auc: 0.9944 - val_loss: 0.2554 - val_auc: 0.9976\n",
      "Epoch 188/200\n",
      " - 10s - loss: 0.2900 - auc: 0.9957 - val_loss: 0.2520 - val_auc: 0.9972\n",
      "Epoch 189/200\n",
      " - 10s - loss: 0.3001 - auc: 0.9955 - val_loss: 0.2200 - val_auc: 0.9981\n",
      "Epoch 190/200\n",
      " - 10s - loss: 0.2962 - auc: 0.9945 - val_loss: 0.2746 - val_auc: 0.9973\n",
      "Epoch 191/200\n",
      " - 10s - loss: 0.3490 - auc: 0.9924 - val_loss: 0.2060 - val_auc: 0.9983\n",
      "Epoch 192/200\n",
      " - 10s - loss: 0.2903 - auc: 0.9958 - val_loss: 0.2099 - val_auc: 0.9984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/200\n",
      " - 10s - loss: 0.3282 - auc: 0.9935 - val_loss: 0.2238 - val_auc: 0.9982\n",
      "Epoch 194/200\n",
      " - 10s - loss: 0.3171 - auc: 0.9943 - val_loss: 0.2381 - val_auc: 0.9978\n",
      "Epoch 195/200\n",
      " - 10s - loss: 0.2979 - auc: 0.9945 - val_loss: 0.2243 - val_auc: 0.9981\n",
      "Epoch 196/200\n",
      " - 10s - loss: 0.3033 - auc: 0.9945 - val_loss: 0.2294 - val_auc: 0.9979\n",
      "Epoch 197/200\n",
      " - 10s - loss: 0.3053 - auc: 0.9944 - val_loss: 0.2524 - val_auc: 0.9978\n",
      "Epoch 198/200\n",
      " - 10s - loss: 0.3182 - auc: 0.9946 - val_loss: 0.2256 - val_auc: 0.9977\n",
      "Epoch 199/200\n",
      " - 10s - loss: 0.2789 - auc: 0.9958 - val_loss: 0.2169 - val_auc: 0.9984\n",
      "Epoch 200/200\n",
      " - 10s - loss: 0.3342 - auc: 0.9928 - val_loss: 0.2203 - val_auc: 0.9985\n",
      "ROS,MIT-BIH Normal Sinus Rhythm Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keg/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:80: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1918 samples, validate on 263 samples\n",
      "Epoch 1/200\n",
      " - 51s - loss: 1.5123 - auc: 0.9040 - val_loss: 1.8488 - val_auc: 0.9424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keg/anaconda3/lib/python3.6/site-packages/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `roc_accuracy` which is not available. Available metrics are: val_loss,val_auc,loss,auc,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200\n",
      " - 10s - loss: 0.9374 - auc: 0.9695 - val_loss: 0.6628 - val_auc: 0.9920\n",
      "Epoch 3/200\n",
      " - 10s - loss: 0.8301 - auc: 0.9743 - val_loss: 0.3937 - val_auc: 0.9910\n",
      "Epoch 4/200\n",
      " - 9s - loss: 0.7830 - auc: 0.9760 - val_loss: 0.3232 - val_auc: 0.9937\n",
      "Epoch 5/200\n",
      " - 9s - loss: 0.6682 - auc: 0.9830 - val_loss: 0.3060 - val_auc: 0.9938\n",
      "Epoch 6/200\n",
      " - 9s - loss: 0.6459 - auc: 0.9828 - val_loss: 0.3039 - val_auc: 0.9933\n",
      "Epoch 7/200\n",
      " - 10s - loss: 0.6292 - auc: 0.9835 - val_loss: 0.3433 - val_auc: 0.9923\n",
      "Epoch 8/200\n",
      " - 10s - loss: 0.6362 - auc: 0.9825 - val_loss: 0.3207 - val_auc: 0.9936\n",
      "Epoch 9/200\n",
      " - 10s - loss: 0.6070 - auc: 0.9843 - val_loss: 0.3002 - val_auc: 0.9935\n",
      "Epoch 10/200\n",
      " - 10s - loss: 0.5984 - auc: 0.9846 - val_loss: 0.2819 - val_auc: 0.9935\n",
      "Epoch 11/200\n",
      " - 10s - loss: 0.6219 - auc: 0.9835 - val_loss: 0.2938 - val_auc: 0.9928\n",
      "Epoch 12/200\n",
      " - 9s - loss: 0.5790 - auc: 0.9847 - val_loss: 0.2757 - val_auc: 0.9940\n",
      "Epoch 13/200\n",
      " - 9s - loss: 0.5359 - auc: 0.9878 - val_loss: 0.2765 - val_auc: 0.9936\n",
      "Epoch 14/200\n",
      " - 9s - loss: 0.5471 - auc: 0.9872 - val_loss: 0.2849 - val_auc: 0.9939\n",
      "Epoch 15/200\n",
      " - 9s - loss: 0.5359 - auc: 0.9880 - val_loss: 0.2737 - val_auc: 0.9938\n",
      "Epoch 16/200\n",
      " - 9s - loss: 0.4944 - auc: 0.9888 - val_loss: 0.2809 - val_auc: 0.9942\n",
      "Epoch 17/200\n",
      " - 9s - loss: 0.5311 - auc: 0.9886 - val_loss: 0.2571 - val_auc: 0.9946\n",
      "Epoch 18/200\n",
      " - 9s - loss: 0.5144 - auc: 0.9879 - val_loss: 0.2673 - val_auc: 0.9941\n",
      "Epoch 19/200\n",
      " - 9s - loss: 0.5022 - auc: 0.9889 - val_loss: 0.2631 - val_auc: 0.9903\n",
      "Epoch 20/200\n",
      " - 9s - loss: 0.4693 - auc: 0.9901 - val_loss: 0.2856 - val_auc: 0.9935\n",
      "Epoch 21/200\n",
      " - 9s - loss: 0.5108 - auc: 0.9894 - val_loss: 0.2913 - val_auc: 0.9937\n",
      "Epoch 22/200\n",
      " - 9s - loss: 0.4541 - auc: 0.9904 - val_loss: 0.2761 - val_auc: 0.9942\n",
      "Epoch 23/200\n",
      " - 10s - loss: 0.4963 - auc: 0.9891 - val_loss: 0.3046 - val_auc: 0.9932\n",
      "Epoch 24/200\n",
      " - 9s - loss: 0.4731 - auc: 0.9893 - val_loss: 0.2476 - val_auc: 0.9943\n",
      "Epoch 25/200\n",
      " - 9s - loss: 0.4720 - auc: 0.9896 - val_loss: 0.2641 - val_auc: 0.9946\n",
      "Epoch 26/200\n",
      " - 10s - loss: 0.4372 - auc: 0.9898 - val_loss: 0.2597 - val_auc: 0.9944\n",
      "Epoch 27/200\n",
      " - 9s - loss: 0.4685 - auc: 0.9898 - val_loss: 0.2516 - val_auc: 0.9942\n",
      "Epoch 28/200\n",
      " - 9s - loss: 0.4479 - auc: 0.9882 - val_loss: 0.2524 - val_auc: 0.9944\n",
      "Epoch 29/200\n",
      " - 9s - loss: 0.4678 - auc: 0.9900 - val_loss: 0.2630 - val_auc: 0.9943\n",
      "Epoch 30/200\n",
      " - 9s - loss: 0.4693 - auc: 0.9902 - val_loss: 0.2636 - val_auc: 0.9939\n",
      "Epoch 31/200\n",
      " - 9s - loss: 0.4741 - auc: 0.9895 - val_loss: 0.2350 - val_auc: 0.9944\n",
      "Epoch 32/200\n",
      " - 10s - loss: 0.4622 - auc: 0.9909 - val_loss: 0.2572 - val_auc: 0.9939\n",
      "Epoch 33/200\n",
      " - 9s - loss: 0.4393 - auc: 0.9909 - val_loss: 0.2945 - val_auc: 0.9906\n",
      "Epoch 34/200\n",
      " - 9s - loss: 0.4587 - auc: 0.9905 - val_loss: 0.3222 - val_auc: 0.9900\n",
      "Epoch 35/200\n",
      " - 9s - loss: 0.4542 - auc: 0.9886 - val_loss: 0.2527 - val_auc: 0.9936\n",
      "Epoch 36/200\n",
      " - 9s - loss: 0.4421 - auc: 0.9904 - val_loss: 0.2967 - val_auc: 0.9930\n",
      "Epoch 37/200\n",
      " - 9s - loss: 0.4326 - auc: 0.9915 - val_loss: 0.2981 - val_auc: 0.9938\n",
      "Epoch 38/200\n",
      " - 9s - loss: 0.3992 - auc: 0.9917 - val_loss: 0.3043 - val_auc: 0.9904\n",
      "Epoch 39/200\n",
      " - 9s - loss: 0.4480 - auc: 0.9913 - val_loss: 0.2587 - val_auc: 0.9940\n",
      "Epoch 40/200\n",
      " - 9s - loss: 0.4072 - auc: 0.9922 - val_loss: 0.2767 - val_auc: 0.9941\n",
      "Epoch 41/200\n",
      " - 9s - loss: 0.4382 - auc: 0.9911 - val_loss: 0.2947 - val_auc: 0.9939\n",
      "Epoch 42/200\n",
      " - 9s - loss: 0.4415 - auc: 0.9888 - val_loss: 0.2710 - val_auc: 0.9942\n",
      "Epoch 43/200\n",
      " - 9s - loss: 0.4020 - auc: 0.9922 - val_loss: 0.2734 - val_auc: 0.9938\n",
      "Epoch 44/200\n",
      " - 9s - loss: 0.4068 - auc: 0.9913 - val_loss: 0.2344 - val_auc: 0.9941\n",
      "Epoch 45/200\n",
      " - 9s - loss: 0.4285 - auc: 0.9906 - val_loss: 0.2520 - val_auc: 0.9944\n",
      "Epoch 46/200\n",
      " - 9s - loss: 0.4129 - auc: 0.9912 - val_loss: 0.2394 - val_auc: 0.9944\n",
      "Epoch 47/200\n",
      " - 9s - loss: 0.4143 - auc: 0.9910 - val_loss: 0.2445 - val_auc: 0.9940\n",
      "Epoch 48/200\n",
      " - 9s - loss: 0.4274 - auc: 0.9903 - val_loss: 0.2505 - val_auc: 0.9946\n",
      "Epoch 49/200\n",
      " - 9s - loss: 0.3997 - auc: 0.9926 - val_loss: 0.2421 - val_auc: 0.9947\n",
      "Epoch 50/200\n",
      " - 9s - loss: 0.3893 - auc: 0.9921 - val_loss: 0.2541 - val_auc: 0.9948\n",
      "Epoch 51/200\n",
      " - 9s - loss: 0.3753 - auc: 0.9932 - val_loss: 0.2383 - val_auc: 0.9945\n",
      "Epoch 52/200\n",
      " - 10s - loss: 0.4283 - auc: 0.9909 - val_loss: 0.2840 - val_auc: 0.9908\n",
      "Epoch 53/200\n",
      " - 9s - loss: 0.4315 - auc: 0.9889 - val_loss: 0.2439 - val_auc: 0.9948\n",
      "Epoch 54/200\n",
      " - 9s - loss: 0.4064 - auc: 0.9911 - val_loss: 0.2324 - val_auc: 0.9946\n",
      "Epoch 55/200\n",
      " - 9s - loss: 0.3745 - auc: 0.9932 - val_loss: 0.2515 - val_auc: 0.9946\n",
      "Epoch 56/200\n",
      " - 9s - loss: 0.3775 - auc: 0.9911 - val_loss: 0.2560 - val_auc: 0.9944\n",
      "Epoch 57/200\n",
      " - 10s - loss: 0.3743 - auc: 0.9919 - val_loss: 0.2857 - val_auc: 0.9935\n",
      "Epoch 58/200\n",
      " - 10s - loss: 0.3889 - auc: 0.9922 - val_loss: 0.2436 - val_auc: 0.9944\n",
      "Epoch 59/200\n",
      " - 9s - loss: 0.3759 - auc: 0.9926 - val_loss: 0.2466 - val_auc: 0.9943\n",
      "Epoch 60/200\n",
      " - 10s - loss: 0.4113 - auc: 0.9901 - val_loss: 0.2675 - val_auc: 0.9904\n",
      "Epoch 61/200\n",
      " - 10s - loss: 0.3475 - auc: 0.9935 - val_loss: 0.2442 - val_auc: 0.9942\n",
      "Epoch 62/200\n",
      " - 10s - loss: 0.3906 - auc: 0.9922 - val_loss: 0.2995 - val_auc: 0.9939\n",
      "Epoch 63/200\n",
      " - 10s - loss: 0.3584 - auc: 0.9929 - val_loss: 0.2241 - val_auc: 0.9949\n",
      "Epoch 64/200\n",
      " - 9s - loss: 0.4349 - auc: 0.9890 - val_loss: 0.2562 - val_auc: 0.9946\n",
      "Epoch 65/200\n",
      " - 10s - loss: 0.3932 - auc: 0.9911 - val_loss: 0.2502 - val_auc: 0.9949\n",
      "Epoch 66/200\n",
      " - 9s - loss: 0.3713 - auc: 0.9928 - val_loss: 0.2206 - val_auc: 0.9947\n",
      "Epoch 67/200\n",
      " - 9s - loss: 0.3722 - auc: 0.9926 - val_loss: 0.2337 - val_auc: 0.9948\n",
      "Epoch 68/200\n",
      " - 9s - loss: 0.3893 - auc: 0.9924 - val_loss: 0.2476 - val_auc: 0.9948\n",
      "Epoch 69/200\n",
      " - 10s - loss: 0.3850 - auc: 0.9899 - val_loss: 0.2602 - val_auc: 0.9944\n",
      "Epoch 70/200\n",
      " - 10s - loss: 0.3752 - auc: 0.9920 - val_loss: 0.2592 - val_auc: 0.9942\n",
      "Epoch 71/200\n",
      " - 9s - loss: 0.3923 - auc: 0.9903 - val_loss: 0.2192 - val_auc: 0.9949\n",
      "Epoch 72/200\n",
      " - 10s - loss: 0.4317 - auc: 0.9901 - val_loss: 0.2013 - val_auc: 0.9951\n",
      "Epoch 73/200\n",
      " - 9s - loss: 0.4014 - auc: 0.9921 - val_loss: 0.2341 - val_auc: 0.9948\n",
      "Epoch 74/200\n",
      " - 10s - loss: 0.3725 - auc: 0.9917 - val_loss: 0.2324 - val_auc: 0.9948\n",
      "Epoch 75/200\n",
      " - 9s - loss: 0.3666 - auc: 0.9925 - val_loss: 0.2242 - val_auc: 0.9948\n",
      "Epoch 76/200\n",
      " - 10s - loss: 0.3486 - auc: 0.9933 - val_loss: 0.2185 - val_auc: 0.9978\n",
      "Epoch 77/200\n",
      " - 9s - loss: 0.3546 - auc: 0.9932 - val_loss: 0.2150 - val_auc: 0.9951\n",
      "Epoch 78/200\n",
      " - 10s - loss: 0.3745 - auc: 0.9931 - val_loss: 0.2333 - val_auc: 0.9950\n",
      "Epoch 79/200\n",
      " - 10s - loss: 0.3892 - auc: 0.9921 - val_loss: 0.2231 - val_auc: 0.9949\n",
      "Epoch 80/200\n",
      " - 10s - loss: 0.3715 - auc: 0.9920 - val_loss: 0.2116 - val_auc: 0.9951\n",
      "Epoch 81/200\n",
      " - 9s - loss: 0.3635 - auc: 0.9927 - val_loss: 0.2300 - val_auc: 0.9976\n",
      "Epoch 82/200\n",
      " - 10s - loss: 0.3883 - auc: 0.9914 - val_loss: 0.2374 - val_auc: 0.9950\n",
      "Epoch 83/200\n",
      " - 10s - loss: 0.3752 - auc: 0.9925 - val_loss: 0.2572 - val_auc: 0.9970\n",
      "Epoch 84/200\n",
      " - 9s - loss: 0.3419 - auc: 0.9933 - val_loss: 0.2423 - val_auc: 0.9947\n",
      "Epoch 85/200\n",
      " - 10s - loss: 0.3626 - auc: 0.9927 - val_loss: 0.2388 - val_auc: 0.9948\n",
      "Epoch 86/200\n",
      " - 10s - loss: 0.3681 - auc: 0.9911 - val_loss: 0.2203 - val_auc: 0.9950\n",
      "Epoch 87/200\n",
      " - 9s - loss: 0.3802 - auc: 0.9922 - val_loss: 0.2289 - val_auc: 0.9950\n",
      "Epoch 88/200\n",
      " - 10s - loss: 0.3487 - auc: 0.9933 - val_loss: 0.2227 - val_auc: 0.9947\n",
      "Epoch 89/200\n",
      " - 9s - loss: 0.3308 - auc: 0.9948 - val_loss: 0.2149 - val_auc: 0.9974\n",
      "Epoch 90/200\n",
      " - 10s - loss: 0.3296 - auc: 0.9930 - val_loss: 0.2542 - val_auc: 0.9940\n",
      "Epoch 91/200\n",
      " - 10s - loss: 0.3561 - auc: 0.9929 - val_loss: 0.2376 - val_auc: 0.9971\n",
      "Epoch 92/200\n",
      " - 9s - loss: 0.3686 - auc: 0.9934 - val_loss: 0.2244 - val_auc: 0.9948\n",
      "Epoch 93/200\n",
      " - 9s - loss: 0.3991 - auc: 0.9882 - val_loss: 0.2169 - val_auc: 0.9952\n",
      "Epoch 94/200\n",
      " - 10s - loss: 0.3363 - auc: 0.9932 - val_loss: 0.2008 - val_auc: 0.9951\n",
      "Epoch 95/200\n",
      " - 10s - loss: 0.3474 - auc: 0.9936 - val_loss: 0.2091 - val_auc: 0.9950\n",
      "Epoch 96/200\n",
      " - 10s - loss: 0.3589 - auc: 0.9920 - val_loss: 0.2194 - val_auc: 0.9948\n",
      "Epoch 97/200\n",
      " - 10s - loss: 0.4111 - auc: 0.9888 - val_loss: 0.2274 - val_auc: 0.9976\n",
      "Epoch 98/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 10s - loss: 0.3514 - auc: 0.9945 - val_loss: 0.2178 - val_auc: 0.9979\n",
      "Epoch 99/200\n",
      " - 10s - loss: 0.3127 - auc: 0.9945 - val_loss: 0.2001 - val_auc: 0.9950\n",
      "Epoch 100/200\n",
      " - 10s - loss: 0.3276 - auc: 0.9941 - val_loss: 0.2295 - val_auc: 0.9945\n",
      "Epoch 101/200\n",
      " - 10s - loss: 0.3416 - auc: 0.9927 - val_loss: 0.2321 - val_auc: 0.9972\n",
      "Epoch 102/200\n",
      " - 10s - loss: 0.3426 - auc: 0.9923 - val_loss: 0.2140 - val_auc: 0.9947\n",
      "Epoch 103/200\n",
      " - 9s - loss: 0.3408 - auc: 0.9940 - val_loss: 0.2370 - val_auc: 0.9946\n",
      "Epoch 104/200\n",
      " - 9s - loss: 0.3418 - auc: 0.9936 - val_loss: 0.1976 - val_auc: 0.9980\n",
      "Epoch 105/200\n",
      " - 9s - loss: 0.3612 - auc: 0.9928 - val_loss: 0.2364 - val_auc: 0.9976\n",
      "Epoch 106/200\n",
      " - 10s - loss: 0.3883 - auc: 0.9913 - val_loss: 0.2605 - val_auc: 0.9971\n",
      "Epoch 107/200\n",
      " - 10s - loss: 0.3530 - auc: 0.9928 - val_loss: 0.2310 - val_auc: 0.9979\n",
      "Epoch 108/200\n",
      " - 10s - loss: 0.3414 - auc: 0.9933 - val_loss: 0.2169 - val_auc: 0.9978\n",
      "Epoch 109/200\n",
      " - 9s - loss: 0.3379 - auc: 0.9935 - val_loss: 0.2326 - val_auc: 0.9977\n",
      "Epoch 110/200\n",
      " - 10s - loss: 0.3212 - auc: 0.9937 - val_loss: 0.2011 - val_auc: 0.9983\n",
      "Epoch 111/200\n",
      " - 10s - loss: 0.3582 - auc: 0.9921 - val_loss: 0.2192 - val_auc: 0.9950\n",
      "Epoch 112/200\n",
      " - 9s - loss: 0.3371 - auc: 0.9931 - val_loss: 0.1995 - val_auc: 0.9985\n",
      "Epoch 113/200\n",
      " - 9s - loss: 0.3104 - auc: 0.9944 - val_loss: 0.2079 - val_auc: 0.9979\n",
      "Epoch 114/200\n",
      " - 10s - loss: 0.3267 - auc: 0.9935 - val_loss: 0.2030 - val_auc: 0.9950\n",
      "Epoch 115/200\n",
      " - 9s - loss: 0.3607 - auc: 0.9931 - val_loss: 0.2074 - val_auc: 0.9950\n",
      "Epoch 116/200\n",
      " - 9s - loss: 0.2844 - auc: 0.9952 - val_loss: 0.1994 - val_auc: 0.9985\n",
      "Epoch 117/200\n",
      " - 9s - loss: 0.3719 - auc: 0.9924 - val_loss: 0.1961 - val_auc: 0.9984\n",
      "Epoch 118/200\n",
      " - 9s - loss: 0.3551 - auc: 0.9928 - val_loss: 0.2532 - val_auc: 0.9944\n",
      "Epoch 119/200\n",
      " - 10s - loss: 0.3305 - auc: 0.9946 - val_loss: 0.2545 - val_auc: 0.9973\n",
      "Epoch 120/200\n",
      " - 9s - loss: 0.2967 - auc: 0.9955 - val_loss: 0.2514 - val_auc: 0.9967\n",
      "Epoch 121/200\n",
      " - 10s - loss: 0.3485 - auc: 0.9940 - val_loss: 0.2166 - val_auc: 0.9949\n",
      "Epoch 122/200\n",
      " - 9s - loss: 0.3291 - auc: 0.9943 - val_loss: 0.1897 - val_auc: 0.9985\n",
      "Epoch 123/200\n",
      " - 10s - loss: 0.3322 - auc: 0.9932 - val_loss: 0.1867 - val_auc: 0.9985\n",
      "Epoch 124/200\n",
      " - 10s - loss: 0.3169 - auc: 0.9941 - val_loss: 0.1803 - val_auc: 0.9986\n",
      "Epoch 125/200\n",
      " - 10s - loss: 0.3055 - auc: 0.9940 - val_loss: 0.1923 - val_auc: 0.9984\n",
      "Epoch 126/200\n",
      " - 9s - loss: 0.3283 - auc: 0.9931 - val_loss: 0.2157 - val_auc: 0.9980\n",
      "Epoch 127/200\n",
      " - 10s - loss: 0.3552 - auc: 0.9922 - val_loss: 0.1749 - val_auc: 0.9989\n",
      "Epoch 128/200\n",
      " - 10s - loss: 0.3489 - auc: 0.9942 - val_loss: 0.1843 - val_auc: 0.9986\n",
      "Epoch 129/200\n",
      " - 9s - loss: 0.3352 - auc: 0.9930 - val_loss: 0.2183 - val_auc: 0.9979\n",
      "Epoch 130/200\n",
      " - 10s - loss: 0.3310 - auc: 0.9941 - val_loss: 0.1912 - val_auc: 0.9983\n",
      "Epoch 131/200\n",
      " - 9s - loss: 0.3488 - auc: 0.9929 - val_loss: 0.2309 - val_auc: 0.9980\n",
      "Epoch 132/200\n",
      " - 9s - loss: 0.3296 - auc: 0.9945 - val_loss: 0.1836 - val_auc: 0.9986\n",
      "Epoch 133/200\n",
      " - 10s - loss: 0.2978 - auc: 0.9950 - val_loss: 0.1982 - val_auc: 0.9981\n",
      "Epoch 134/200\n",
      " - 9s - loss: 0.3510 - auc: 0.9930 - val_loss: 0.2400 - val_auc: 0.9976\n",
      "Epoch 135/200\n",
      " - 10s - loss: 0.3142 - auc: 0.9936 - val_loss: 0.2148 - val_auc: 0.9982\n",
      "Epoch 136/200\n",
      " - 9s - loss: 0.3163 - auc: 0.9936 - val_loss: 0.2049 - val_auc: 0.9953\n",
      "Epoch 137/200\n",
      " - 9s - loss: 0.3084 - auc: 0.9935 - val_loss: 0.1847 - val_auc: 0.9986\n",
      "Epoch 138/200\n",
      " - 9s - loss: 0.3154 - auc: 0.9950 - val_loss: 0.2148 - val_auc: 0.9978\n",
      "Epoch 139/200\n",
      " - 9s - loss: 0.3124 - auc: 0.9945 - val_loss: 0.2146 - val_auc: 0.9981\n",
      "Epoch 140/200\n",
      " - 10s - loss: 0.3246 - auc: 0.9941 - val_loss: 0.2003 - val_auc: 0.9983\n",
      "Epoch 141/200\n",
      " - 9s - loss: 0.3191 - auc: 0.9930 - val_loss: 0.2124 - val_auc: 0.9980\n",
      "Epoch 142/200\n",
      " - 10s - loss: 0.2993 - auc: 0.9954 - val_loss: 0.2276 - val_auc: 0.9976\n",
      "Epoch 143/200\n",
      " - 10s - loss: 0.3418 - auc: 0.9923 - val_loss: 0.2164 - val_auc: 0.9980\n",
      "Epoch 144/200\n",
      " - 9s - loss: 0.3208 - auc: 0.9937 - val_loss: 0.1791 - val_auc: 0.9985\n",
      "Epoch 145/200\n",
      " - 10s - loss: 0.3463 - auc: 0.9932 - val_loss: 0.2098 - val_auc: 0.9983\n",
      "Epoch 146/200\n",
      " - 9s - loss: 0.2720 - auc: 0.9965 - val_loss: 0.1905 - val_auc: 0.9986\n",
      "Epoch 147/200\n",
      " - 10s - loss: 0.3548 - auc: 0.9941 - val_loss: 0.1797 - val_auc: 0.9984\n",
      "Epoch 148/200\n",
      " - 10s - loss: 0.3323 - auc: 0.9926 - val_loss: 0.2087 - val_auc: 0.9978\n",
      "Epoch 149/200\n",
      " - 10s - loss: 0.3209 - auc: 0.9940 - val_loss: 0.2280 - val_auc: 0.9944\n",
      "Epoch 150/200\n",
      " - 9s - loss: 0.3116 - auc: 0.9943 - val_loss: 0.1985 - val_auc: 0.9982\n",
      "Epoch 151/200\n",
      " - 10s - loss: 0.2849 - auc: 0.9945 - val_loss: 0.2203 - val_auc: 0.9979\n",
      "Epoch 152/200\n",
      " - 9s - loss: 0.3160 - auc: 0.9928 - val_loss: 0.2173 - val_auc: 0.9981\n",
      "Epoch 153/200\n",
      " - 10s - loss: 0.3143 - auc: 0.9950 - val_loss: 0.1899 - val_auc: 0.9984\n",
      "Epoch 154/200\n",
      " - 9s - loss: 0.3451 - auc: 0.9933 - val_loss: 0.1906 - val_auc: 0.9983\n",
      "Epoch 155/200\n",
      " - 9s - loss: 0.3483 - auc: 0.9925 - val_loss: 0.1830 - val_auc: 0.9987\n",
      "Epoch 156/200\n",
      " - 10s - loss: 0.3037 - auc: 0.9947 - val_loss: 0.2273 - val_auc: 0.9978\n",
      "Epoch 157/200\n",
      " - 9s - loss: 0.2981 - auc: 0.9945 - val_loss: 0.2323 - val_auc: 0.9974\n",
      "Epoch 158/200\n",
      " - 9s - loss: 0.3201 - auc: 0.9933 - val_loss: 0.1945 - val_auc: 0.9981\n",
      "Epoch 159/200\n",
      " - 10s - loss: 0.3079 - auc: 0.9939 - val_loss: 0.1922 - val_auc: 0.9985\n",
      "Epoch 160/200\n",
      " - 9s - loss: 0.3006 - auc: 0.9944 - val_loss: 0.1789 - val_auc: 0.9987\n",
      "Epoch 161/200\n",
      " - 10s - loss: 0.3122 - auc: 0.9933 - val_loss: 0.1963 - val_auc: 0.9981\n",
      "Epoch 162/200\n",
      " - 10s - loss: 0.3033 - auc: 0.9949 - val_loss: 0.1984 - val_auc: 0.9982\n",
      "Epoch 163/200\n",
      " - 10s - loss: 0.3451 - auc: 0.9936 - val_loss: 0.2114 - val_auc: 0.9980\n",
      "Epoch 164/200\n",
      " - 9s - loss: 0.2761 - auc: 0.9957 - val_loss: 0.1935 - val_auc: 0.9980\n",
      "Epoch 165/200\n",
      " - 9s - loss: 0.3094 - auc: 0.9930 - val_loss: 0.1885 - val_auc: 0.9985\n",
      "Epoch 166/200\n",
      " - 10s - loss: 0.3032 - auc: 0.9948 - val_loss: 0.1822 - val_auc: 0.9982\n",
      "Epoch 167/200\n",
      " - 10s - loss: 0.3570 - auc: 0.9919 - val_loss: 0.1967 - val_auc: 0.9982\n",
      "Epoch 168/200\n",
      " - 10s - loss: 0.3096 - auc: 0.9947 - val_loss: 0.1947 - val_auc: 0.9983\n",
      "Epoch 169/200\n",
      " - 9s - loss: 0.2769 - auc: 0.9959 - val_loss: 0.2058 - val_auc: 0.9982\n",
      "Epoch 170/200\n",
      " - 10s - loss: 0.3119 - auc: 0.9950 - val_loss: 0.1940 - val_auc: 0.9981\n",
      "Epoch 171/200\n",
      " - 9s - loss: 0.3267 - auc: 0.9940 - val_loss: 0.1975 - val_auc: 0.9982\n",
      "Epoch 172/200\n",
      " - 9s - loss: 0.2615 - auc: 0.9958 - val_loss: 0.1857 - val_auc: 0.9980\n",
      "Epoch 173/200\n",
      " - 9s - loss: 0.3100 - auc: 0.9942 - val_loss: 0.1999 - val_auc: 0.9981\n",
      "Epoch 174/200\n",
      " - 9s - loss: 0.3240 - auc: 0.9946 - val_loss: 0.1941 - val_auc: 0.9984\n",
      "Epoch 175/200\n",
      " - 9s - loss: 0.3322 - auc: 0.9947 - val_loss: 0.2112 - val_auc: 0.9981\n",
      "Epoch 176/200\n",
      " - 10s - loss: 0.3122 - auc: 0.9943 - val_loss: 0.2108 - val_auc: 0.9980\n",
      "Epoch 177/200\n",
      " - 9s - loss: 0.2709 - auc: 0.9963 - val_loss: 0.2078 - val_auc: 0.9982\n",
      "Epoch 178/200\n",
      " - 9s - loss: 0.3148 - auc: 0.9951 - val_loss: 0.1988 - val_auc: 0.9981\n",
      "Epoch 179/200\n",
      " - 9s - loss: 0.3145 - auc: 0.9943 - val_loss: 0.1787 - val_auc: 0.9985\n",
      "Epoch 180/200\n",
      " - 9s - loss: 0.3270 - auc: 0.9938 - val_loss: 0.2130 - val_auc: 0.9980\n",
      "Epoch 181/200\n",
      " - 10s - loss: 0.3307 - auc: 0.9932 - val_loss: 0.2276 - val_auc: 0.9979\n",
      "Epoch 182/200\n",
      " - 9s - loss: 0.2884 - auc: 0.9956 - val_loss: 0.2093 - val_auc: 0.9982\n",
      "Epoch 183/200\n",
      " - 10s - loss: 0.3140 - auc: 0.9931 - val_loss: 0.2361 - val_auc: 0.9975\n",
      "Epoch 184/200\n",
      " - 10s - loss: 0.3160 - auc: 0.9933 - val_loss: 0.1977 - val_auc: 0.9985\n",
      "Epoch 185/200\n",
      " - 10s - loss: 0.3397 - auc: 0.9936 - val_loss: 0.2226 - val_auc: 0.9982\n",
      "Epoch 186/200\n",
      " - 10s - loss: 0.3218 - auc: 0.9927 - val_loss: 0.2070 - val_auc: 0.9983\n",
      "Epoch 187/200\n",
      " - 9s - loss: 0.3154 - auc: 0.9931 - val_loss: 0.1729 - val_auc: 0.9988\n",
      "Epoch 188/200\n",
      " - 10s - loss: 0.2505 - auc: 0.9967 - val_loss: 0.2130 - val_auc: 0.9980\n",
      "Epoch 189/200\n",
      " - 9s - loss: 0.3126 - auc: 0.9937 - val_loss: 0.1988 - val_auc: 0.9987\n",
      "Epoch 190/200\n",
      " - 10s - loss: 0.3162 - auc: 0.9940 - val_loss: 0.1862 - val_auc: 0.9984\n",
      "Epoch 191/200\n",
      " - 9s - loss: 0.2824 - auc: 0.9951 - val_loss: 0.2087 - val_auc: 0.9980\n",
      "Epoch 192/200\n",
      " - 9s - loss: 0.3032 - auc: 0.9933 - val_loss: 0.1744 - val_auc: 0.9986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/200\n",
      " - 9s - loss: 0.3082 - auc: 0.9938 - val_loss: 0.2210 - val_auc: 0.9978\n",
      "Epoch 194/200\n",
      " - 9s - loss: 0.3144 - auc: 0.9944 - val_loss: 0.1801 - val_auc: 0.9988\n",
      "Epoch 195/200\n",
      " - 10s - loss: 0.3272 - auc: 0.9915 - val_loss: 0.2402 - val_auc: 0.9978\n",
      "Epoch 196/200\n",
      " - 10s - loss: 0.3058 - auc: 0.9948 - val_loss: 0.1974 - val_auc: 0.9983\n",
      "Epoch 197/200\n",
      " - 10s - loss: 0.3277 - auc: 0.9947 - val_loss: 0.1916 - val_auc: 0.9986\n",
      "Epoch 198/200\n",
      " - 10s - loss: 0.2762 - auc: 0.9962 - val_loss: 0.1904 - val_auc: 0.9986\n",
      "Epoch 199/200\n",
      " - 10s - loss: 0.2762 - auc: 0.9959 - val_loss: 0.1908 - val_auc: 0.9985\n",
      "Epoch 200/200\n",
      " - 9s - loss: 0.3432 - auc: 0.9924 - val_loss: 0.2128 - val_auc: 0.9977\n",
      "BorderlineSMOTE,MIT-BIH Normal Sinus Rhythm Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keg/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:80: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2128 samples, validate on 263 samples\n",
      "Epoch 1/200\n",
      " - 52s - loss: 1.3811 - auc: 0.9166 - val_loss: 1.5856 - val_auc: 0.9667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keg/anaconda3/lib/python3.6/site-packages/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `roc_accuracy` which is not available. Available metrics are: val_loss,val_auc,loss,auc,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200\n",
      " - 10s - loss: 0.8844 - auc: 0.9722 - val_loss: 0.4984 - val_auc: 0.9942\n",
      "Epoch 3/200\n",
      " - 10s - loss: 0.7314 - auc: 0.9795 - val_loss: 0.3556 - val_auc: 0.9962\n",
      "Epoch 4/200\n",
      " - 10s - loss: 0.6987 - auc: 0.9806 - val_loss: 0.2983 - val_auc: 0.9973\n",
      "Epoch 5/200\n",
      " - 10s - loss: 0.6670 - auc: 0.9805 - val_loss: 0.2641 - val_auc: 0.9972\n",
      "Epoch 6/200\n",
      " - 10s - loss: 0.6476 - auc: 0.9821 - val_loss: 0.2549 - val_auc: 0.9983\n",
      "Epoch 7/200\n",
      " - 10s - loss: 0.6090 - auc: 0.9830 - val_loss: 0.2395 - val_auc: 0.9981\n",
      "Epoch 8/200\n",
      " - 10s - loss: 0.5678 - auc: 0.9855 - val_loss: 0.2360 - val_auc: 0.9973\n",
      "Epoch 9/200\n",
      " - 10s - loss: 0.5343 - auc: 0.9860 - val_loss: 0.3040 - val_auc: 0.9939\n",
      "Epoch 10/200\n",
      " - 10s - loss: 0.6252 - auc: 0.9822 - val_loss: 0.2338 - val_auc: 0.9978\n",
      "Epoch 11/200\n",
      " - 10s - loss: 0.5315 - auc: 0.9876 - val_loss: 0.2992 - val_auc: 0.9940\n",
      "Epoch 12/200\n",
      " - 10s - loss: 0.5712 - auc: 0.9860 - val_loss: 0.2624 - val_auc: 0.9977\n",
      "Epoch 13/200\n",
      " - 10s - loss: 0.5395 - auc: 0.9864 - val_loss: 0.2725 - val_auc: 0.9945\n",
      "Epoch 14/200\n",
      " - 10s - loss: 0.5258 - auc: 0.9851 - val_loss: 0.2347 - val_auc: 0.9979\n",
      "Epoch 15/200\n",
      " - 10s - loss: 0.4962 - auc: 0.9881 - val_loss: 0.2058 - val_auc: 0.9987\n",
      "Epoch 16/200\n",
      " - 10s - loss: 0.4841 - auc: 0.9881 - val_loss: 0.1819 - val_auc: 0.9991\n",
      "Epoch 17/200\n",
      " - 10s - loss: 0.4973 - auc: 0.9879 - val_loss: 0.2509 - val_auc: 0.9946\n",
      "Epoch 18/200\n",
      " - 10s - loss: 0.4654 - auc: 0.9885 - val_loss: 0.2246 - val_auc: 0.9982\n",
      "Epoch 19/200\n",
      " - 10s - loss: 0.4769 - auc: 0.9881 - val_loss: 0.1947 - val_auc: 0.9989\n",
      "Epoch 20/200\n",
      " - 10s - loss: 0.4575 - auc: 0.9896 - val_loss: 0.2289 - val_auc: 0.9982\n",
      "Epoch 21/200\n",
      " - 10s - loss: 0.4494 - auc: 0.9895 - val_loss: 0.1974 - val_auc: 0.9987\n",
      "Epoch 22/200\n",
      " - 10s - loss: 0.4425 - auc: 0.9907 - val_loss: 0.1970 - val_auc: 0.9986\n",
      "Epoch 23/200\n",
      " - 10s - loss: 0.4752 - auc: 0.9881 - val_loss: 0.2072 - val_auc: 0.9987\n",
      "Epoch 24/200\n",
      " - 10s - loss: 0.4823 - auc: 0.9888 - val_loss: 0.2091 - val_auc: 0.9989\n",
      "Epoch 25/200\n",
      " - 10s - loss: 0.4423 - auc: 0.9892 - val_loss: 0.1855 - val_auc: 0.9990\n",
      "Epoch 26/200\n",
      " - 10s - loss: 0.4824 - auc: 0.9894 - val_loss: 0.2041 - val_auc: 0.9988\n",
      "Epoch 27/200\n",
      " - 10s - loss: 0.4283 - auc: 0.9904 - val_loss: 0.1869 - val_auc: 0.9992\n",
      "Epoch 28/200\n",
      " - 10s - loss: 0.4280 - auc: 0.9915 - val_loss: 0.2227 - val_auc: 0.9948\n",
      "Epoch 29/200\n",
      " - 10s - loss: 0.4499 - auc: 0.9900 - val_loss: 0.2075 - val_auc: 0.9985\n",
      "Epoch 30/200\n",
      " - 10s - loss: 0.4542 - auc: 0.9906 - val_loss: 0.1738 - val_auc: 0.9995\n",
      "Epoch 31/200\n",
      " - 10s - loss: 0.4315 - auc: 0.9886 - val_loss: 0.1826 - val_auc: 0.9990\n",
      "Epoch 32/200\n",
      " - 10s - loss: 0.3901 - auc: 0.9920 - val_loss: 0.1608 - val_auc: 0.9993\n",
      "Epoch 33/200\n",
      " - 10s - loss: 0.4422 - auc: 0.9911 - val_loss: 0.2369 - val_auc: 0.9981\n",
      "Epoch 34/200\n",
      " - 10s - loss: 0.3785 - auc: 0.9929 - val_loss: 0.2189 - val_auc: 0.9979\n",
      "Epoch 35/200\n",
      " - 10s - loss: 0.4440 - auc: 0.9890 - val_loss: 0.1869 - val_auc: 0.9985\n",
      "Epoch 36/200\n",
      " - 10s - loss: 0.4035 - auc: 0.9922 - val_loss: 0.2299 - val_auc: 0.9980\n",
      "Epoch 37/200\n",
      " - 10s - loss: 0.4103 - auc: 0.9906 - val_loss: 0.1730 - val_auc: 0.9991\n",
      "Epoch 38/200\n",
      " - 10s - loss: 0.3994 - auc: 0.9920 - val_loss: 0.1780 - val_auc: 0.9990\n",
      "Epoch 39/200\n",
      " - 10s - loss: 0.4310 - auc: 0.9909 - val_loss: 0.1947 - val_auc: 0.9988\n",
      "Epoch 40/200\n",
      " - 10s - loss: 0.3784 - auc: 0.9928 - val_loss: 0.1852 - val_auc: 0.9992\n",
      "Epoch 41/200\n",
      " - 10s - loss: 0.3996 - auc: 0.9928 - val_loss: 0.1731 - val_auc: 0.9990\n",
      "Epoch 42/200\n",
      " - 10s - loss: 0.3989 - auc: 0.9913 - val_loss: 0.1791 - val_auc: 0.9987\n",
      "Epoch 43/200\n",
      " - 10s - loss: 0.3504 - auc: 0.9938 - val_loss: 0.1748 - val_auc: 0.9988\n",
      "Epoch 44/200\n",
      " - 10s - loss: 0.3764 - auc: 0.9923 - val_loss: 0.1909 - val_auc: 0.9987\n",
      "Epoch 45/200\n",
      " - 10s - loss: 0.3797 - auc: 0.9934 - val_loss: 0.2130 - val_auc: 0.9950\n",
      "Epoch 46/200\n",
      " - 10s - loss: 0.4040 - auc: 0.9913 - val_loss: 0.2051 - val_auc: 0.9986\n",
      "Epoch 47/200\n",
      " - 10s - loss: 0.3981 - auc: 0.9922 - val_loss: 0.1836 - val_auc: 0.9988\n",
      "Epoch 48/200\n",
      " - 10s - loss: 0.3568 - auc: 0.9932 - val_loss: 0.1666 - val_auc: 0.9991\n",
      "Epoch 49/200\n",
      " - 10s - loss: 0.3513 - auc: 0.9934 - val_loss: 0.1799 - val_auc: 0.9989\n",
      "Epoch 50/200\n",
      " - 10s - loss: 0.3786 - auc: 0.9920 - val_loss: 0.1759 - val_auc: 0.9987\n",
      "Epoch 51/200\n",
      " - 10s - loss: 0.4085 - auc: 0.9920 - val_loss: 0.1958 - val_auc: 0.9983\n",
      "Epoch 52/200\n",
      " - 10s - loss: 0.3800 - auc: 0.9910 - val_loss: 0.1709 - val_auc: 0.9990\n",
      "Epoch 53/200\n",
      " - 10s - loss: 0.4048 - auc: 0.9901 - val_loss: 0.1513 - val_auc: 0.9993\n",
      "Epoch 54/200\n",
      " - 10s - loss: 0.3824 - auc: 0.9904 - val_loss: 0.1741 - val_auc: 0.9993\n",
      "Epoch 55/200\n",
      " - 10s - loss: 0.3617 - auc: 0.9931 - val_loss: 0.1827 - val_auc: 0.9991\n",
      "Epoch 56/200\n",
      " - 10s - loss: 0.3271 - auc: 0.9934 - val_loss: 0.1575 - val_auc: 0.9991\n",
      "Epoch 57/200\n",
      " - 10s - loss: 0.3167 - auc: 0.9945 - val_loss: 0.1580 - val_auc: 0.9990\n",
      "Epoch 58/200\n",
      " - 10s - loss: 0.3756 - auc: 0.9926 - val_loss: 0.1585 - val_auc: 0.9995\n",
      "Epoch 59/200\n",
      " - 10s - loss: 0.3644 - auc: 0.9930 - val_loss: 0.1524 - val_auc: 0.9993\n",
      "Epoch 60/200\n",
      " - 10s - loss: 0.3581 - auc: 0.9923 - val_loss: 0.1769 - val_auc: 0.9986\n",
      "Epoch 61/200\n",
      " - 10s - loss: 0.3608 - auc: 0.9927 - val_loss: 0.1675 - val_auc: 0.9990\n",
      "Epoch 62/200\n",
      " - 10s - loss: 0.3560 - auc: 0.9939 - val_loss: 0.1404 - val_auc: 0.9995\n",
      "Epoch 63/200\n",
      " - 10s - loss: 0.3789 - auc: 0.9918 - val_loss: 0.1425 - val_auc: 0.9994\n",
      "Epoch 64/200\n",
      " - 10s - loss: 0.3840 - auc: 0.9932 - val_loss: 0.1938 - val_auc: 0.9984\n",
      "Epoch 65/200\n",
      " - 10s - loss: 0.3447 - auc: 0.9943 - val_loss: 0.1832 - val_auc: 0.9989\n",
      "Epoch 66/200\n",
      " - 10s - loss: 0.3680 - auc: 0.9922 - val_loss: 0.1639 - val_auc: 0.9991\n",
      "Epoch 67/200\n",
      " - 10s - loss: 0.3818 - auc: 0.9915 - val_loss: 0.1833 - val_auc: 0.9986\n",
      "Epoch 68/200\n",
      " - 10s - loss: 0.3919 - auc: 0.9923 - val_loss: 0.1848 - val_auc: 0.9986\n",
      "Epoch 69/200\n",
      " - 10s - loss: 0.3496 - auc: 0.9944 - val_loss: 0.1955 - val_auc: 0.9984\n",
      "Epoch 70/200\n",
      " - 10s - loss: 0.3616 - auc: 0.9934 - val_loss: 0.1440 - val_auc: 0.9994\n",
      "Epoch 71/200\n",
      " - 10s - loss: 0.3411 - auc: 0.9930 - val_loss: 0.1889 - val_auc: 0.9990\n",
      "Epoch 72/200\n",
      " - 10s - loss: 0.3468 - auc: 0.9920 - val_loss: 0.1686 - val_auc: 0.9990\n",
      "Epoch 73/200\n",
      " - 10s - loss: 0.3665 - auc: 0.9920 - val_loss: 0.1521 - val_auc: 0.9991\n",
      "Epoch 74/200\n",
      " - 10s - loss: 0.3129 - auc: 0.9946 - val_loss: 0.1510 - val_auc: 0.9990\n",
      "Epoch 75/200\n",
      " - 10s - loss: 0.3681 - auc: 0.9911 - val_loss: 0.1644 - val_auc: 0.9991\n",
      "Epoch 76/200\n",
      " - 10s - loss: 0.3419 - auc: 0.9934 - val_loss: 0.1479 - val_auc: 0.9990\n",
      "Epoch 77/200\n",
      " - 10s - loss: 0.3336 - auc: 0.9940 - val_loss: 0.1764 - val_auc: 0.9991\n",
      "Epoch 78/200\n",
      " - 10s - loss: 0.3911 - auc: 0.9903 - val_loss: 0.1782 - val_auc: 0.9988\n",
      "Epoch 79/200\n",
      " - 10s - loss: 0.3320 - auc: 0.9932 - val_loss: 0.2037 - val_auc: 0.9984\n",
      "Epoch 80/200\n",
      " - 10s - loss: 0.3543 - auc: 0.9927 - val_loss: 0.1715 - val_auc: 0.9990\n",
      "Epoch 81/200\n",
      " - 10s - loss: 0.3697 - auc: 0.9938 - val_loss: 0.1852 - val_auc: 0.9985\n",
      "Epoch 82/200\n",
      " - 10s - loss: 0.3246 - auc: 0.9940 - val_loss: 0.1683 - val_auc: 0.9990\n",
      "Epoch 83/200\n",
      " - 10s - loss: 0.3356 - auc: 0.9939 - val_loss: 0.1618 - val_auc: 0.9990\n",
      "Epoch 84/200\n",
      " - 10s - loss: 0.3529 - auc: 0.9925 - val_loss: 0.1701 - val_auc: 0.9988\n",
      "Epoch 85/200\n",
      " - 10s - loss: 0.3308 - auc: 0.9930 - val_loss: 0.1725 - val_auc: 0.9988\n",
      "Epoch 86/200\n",
      " - 10s - loss: 0.3282 - auc: 0.9937 - val_loss: 0.1750 - val_auc: 0.9986\n",
      "Epoch 87/200\n",
      " - 10s - loss: 0.3526 - auc: 0.9932 - val_loss: 0.1588 - val_auc: 0.9992\n",
      "Epoch 88/200\n",
      " - 10s - loss: 0.3491 - auc: 0.9931 - val_loss: 0.1808 - val_auc: 0.9987\n",
      "Epoch 89/200\n",
      " - 10s - loss: 0.3254 - auc: 0.9946 - val_loss: 0.1808 - val_auc: 0.9987\n",
      "Epoch 90/200\n",
      " - 10s - loss: 0.3573 - auc: 0.9927 - val_loss: 0.1684 - val_auc: 0.9988\n",
      "Epoch 91/200\n",
      " - 10s - loss: 0.3157 - auc: 0.9940 - val_loss: 0.1747 - val_auc: 0.9990\n",
      "Epoch 92/200\n",
      " - 10s - loss: 0.2915 - auc: 0.9949 - val_loss: 0.1531 - val_auc: 0.9993\n",
      "Epoch 93/200\n",
      " - 10s - loss: 0.2823 - auc: 0.9956 - val_loss: 0.1565 - val_auc: 0.9990\n",
      "Epoch 94/200\n",
      " - 10s - loss: 0.3200 - auc: 0.9936 - val_loss: 0.1636 - val_auc: 0.9991\n",
      "Epoch 95/200\n",
      " - 10s - loss: 0.3026 - auc: 0.9943 - val_loss: 0.1653 - val_auc: 0.9990\n",
      "Epoch 96/200\n",
      " - 10s - loss: 0.2898 - auc: 0.9946 - val_loss: 0.1490 - val_auc: 0.9992\n",
      "Epoch 97/200\n",
      " - 10s - loss: 0.3278 - auc: 0.9938 - val_loss: 0.1615 - val_auc: 0.9990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/200\n",
      " - 10s - loss: 0.3469 - auc: 0.9921 - val_loss: 0.1799 - val_auc: 0.9988\n",
      "Epoch 99/200\n",
      " - 10s - loss: 0.3429 - auc: 0.9927 - val_loss: 0.1914 - val_auc: 0.9987\n",
      "Epoch 100/200\n",
      " - 10s - loss: 0.3258 - auc: 0.9938 - val_loss: 0.1916 - val_auc: 0.9986\n",
      "Epoch 101/200\n",
      " - 10s - loss: 0.3545 - auc: 0.9922 - val_loss: 0.1549 - val_auc: 0.9994\n",
      "Epoch 102/200\n",
      " - 10s - loss: 0.3272 - auc: 0.9944 - val_loss: 0.1798 - val_auc: 0.9987\n",
      "Epoch 103/200\n",
      " - 10s - loss: 0.3546 - auc: 0.9916 - val_loss: 0.1606 - val_auc: 0.9989\n",
      "Epoch 104/200\n",
      " - 10s - loss: 0.3557 - auc: 0.9933 - val_loss: 0.1737 - val_auc: 0.9986\n",
      "Epoch 105/200\n",
      " - 10s - loss: 0.3242 - auc: 0.9930 - val_loss: 0.1637 - val_auc: 0.9988\n",
      "Epoch 106/200\n",
      " - 10s - loss: 0.3163 - auc: 0.9944 - val_loss: 0.1687 - val_auc: 0.9987\n",
      "Epoch 107/200\n",
      " - 10s - loss: 0.3337 - auc: 0.9928 - val_loss: 0.1955 - val_auc: 0.9984\n",
      "Epoch 108/200\n",
      " - 10s - loss: 0.3304 - auc: 0.9938 - val_loss: 0.1704 - val_auc: 0.9989\n",
      "Epoch 109/200\n",
      " - 10s - loss: 0.3068 - auc: 0.9944 - val_loss: 0.1418 - val_auc: 0.9994\n",
      "Epoch 110/200\n",
      " - 10s - loss: 0.3163 - auc: 0.9934 - val_loss: 0.1666 - val_auc: 0.9988\n",
      "Epoch 111/200\n",
      " - 10s - loss: 0.3097 - auc: 0.9944 - val_loss: 0.1962 - val_auc: 0.9987\n",
      "Epoch 112/200\n",
      " - 10s - loss: 0.3036 - auc: 0.9951 - val_loss: 0.1495 - val_auc: 0.9991\n",
      "Epoch 113/200\n",
      " - 10s - loss: 0.3306 - auc: 0.9917 - val_loss: 0.1461 - val_auc: 0.9992\n",
      "Epoch 114/200\n",
      " - 10s - loss: 0.2990 - auc: 0.9946 - val_loss: 0.1591 - val_auc: 0.9989\n",
      "Epoch 115/200\n",
      " - 10s - loss: 0.3308 - auc: 0.9933 - val_loss: 0.1346 - val_auc: 0.9992\n",
      "Epoch 116/200\n",
      " - 10s - loss: 0.2868 - auc: 0.9952 - val_loss: 0.1646 - val_auc: 0.9991\n",
      "Epoch 117/200\n",
      " - 10s - loss: 0.2796 - auc: 0.9957 - val_loss: 0.1412 - val_auc: 0.9994\n",
      "Epoch 118/200\n",
      " - 10s - loss: 0.2746 - auc: 0.9960 - val_loss: 0.1631 - val_auc: 0.9986\n",
      "Epoch 119/200\n",
      " - 10s - loss: 0.3032 - auc: 0.9950 - val_loss: 0.1704 - val_auc: 0.9987\n",
      "Epoch 120/200\n",
      " - 10s - loss: 0.3086 - auc: 0.9945 - val_loss: 0.1739 - val_auc: 0.9988\n",
      "Epoch 121/200\n",
      " - 10s - loss: 0.3122 - auc: 0.9939 - val_loss: 0.1779 - val_auc: 0.9986\n",
      "Epoch 122/200\n",
      " - 10s - loss: 0.3232 - auc: 0.9935 - val_loss: 0.1531 - val_auc: 0.9988\n",
      "Epoch 123/200\n",
      " - 10s - loss: 0.3266 - auc: 0.9925 - val_loss: 0.1601 - val_auc: 0.9989\n",
      "Epoch 124/200\n",
      " - 10s - loss: 0.3059 - auc: 0.9945 - val_loss: 0.1576 - val_auc: 0.9988\n",
      "Epoch 125/200\n",
      " - 10s - loss: 0.2931 - auc: 0.9944 - val_loss: 0.1300 - val_auc: 0.9993\n",
      "Epoch 126/200\n",
      " - 10s - loss: 0.3152 - auc: 0.9936 - val_loss: 0.1764 - val_auc: 0.9986\n",
      "Epoch 127/200\n",
      " - 10s - loss: 0.2994 - auc: 0.9954 - val_loss: 0.1320 - val_auc: 0.9994\n",
      "Epoch 128/200\n",
      " - 10s - loss: 0.2841 - auc: 0.9949 - val_loss: 0.1527 - val_auc: 0.9989\n",
      "Epoch 129/200\n",
      " - 10s - loss: 0.2976 - auc: 0.9947 - val_loss: 0.1481 - val_auc: 0.9989\n",
      "Epoch 130/200\n",
      " - 10s - loss: 0.3195 - auc: 0.9937 - val_loss: 0.1899 - val_auc: 0.9986\n",
      "Epoch 131/200\n",
      " - 10s - loss: 0.3247 - auc: 0.9947 - val_loss: 0.1571 - val_auc: 0.9991\n",
      "Epoch 132/200\n",
      " - 10s - loss: 0.2860 - auc: 0.9950 - val_loss: 0.1664 - val_auc: 0.9989\n",
      "Epoch 133/200\n",
      " - 10s - loss: 0.3101 - auc: 0.9944 - val_loss: 0.1570 - val_auc: 0.9990\n",
      "Epoch 134/200\n",
      " - 10s - loss: 0.3143 - auc: 0.9944 - val_loss: 0.1805 - val_auc: 0.9988\n",
      "Epoch 135/200\n",
      " - 10s - loss: 0.2935 - auc: 0.9953 - val_loss: 0.1395 - val_auc: 0.9993\n",
      "Epoch 136/200\n",
      " - 10s - loss: 0.2786 - auc: 0.9949 - val_loss: 0.1759 - val_auc: 0.9984\n",
      "Epoch 137/200\n",
      " - 10s - loss: 0.2711 - auc: 0.9958 - val_loss: 0.1515 - val_auc: 0.9989\n",
      "Epoch 138/200\n",
      " - 10s - loss: 0.3105 - auc: 0.9933 - val_loss: 0.1507 - val_auc: 0.9992\n",
      "Epoch 139/200\n",
      " - 10s - loss: 0.3238 - auc: 0.9936 - val_loss: 0.1497 - val_auc: 0.9989\n",
      "Epoch 140/200\n",
      " - 10s - loss: 0.2874 - auc: 0.9950 - val_loss: 0.1405 - val_auc: 0.9994\n",
      "Epoch 141/200\n",
      " - 10s - loss: 0.2919 - auc: 0.9952 - val_loss: 0.1496 - val_auc: 0.9989\n",
      "Epoch 142/200\n",
      " - 10s - loss: 0.3126 - auc: 0.9939 - val_loss: 0.1408 - val_auc: 0.9993\n",
      "Epoch 143/200\n",
      " - 10s - loss: 0.3305 - auc: 0.9930 - val_loss: 0.1355 - val_auc: 0.9994\n",
      "Epoch 144/200\n",
      " - 10s - loss: 0.2844 - auc: 0.9953 - val_loss: 0.1509 - val_auc: 0.9992\n",
      "Epoch 145/200\n",
      " - 10s - loss: 0.2891 - auc: 0.9944 - val_loss: 0.1270 - val_auc: 0.9995\n",
      "Epoch 146/200\n",
      " - 10s - loss: 0.2915 - auc: 0.9954 - val_loss: 0.1668 - val_auc: 0.9988\n",
      "Epoch 147/200\n",
      " - 10s - loss: 0.2936 - auc: 0.9954 - val_loss: 0.1677 - val_auc: 0.9986\n",
      "Epoch 148/200\n",
      " - 10s - loss: 0.3021 - auc: 0.9952 - val_loss: 0.1628 - val_auc: 0.9989\n",
      "Epoch 149/200\n",
      " - 10s - loss: 0.3064 - auc: 0.9947 - val_loss: 0.1834 - val_auc: 0.9987\n",
      "Epoch 150/200\n",
      " - 10s - loss: 0.3089 - auc: 0.9932 - val_loss: 0.1368 - val_auc: 0.9992\n",
      "Epoch 151/200\n",
      " - 10s - loss: 0.3049 - auc: 0.9941 - val_loss: 0.1512 - val_auc: 0.9990\n",
      "Epoch 152/200\n",
      " - 10s - loss: 0.2897 - auc: 0.9952 - val_loss: 0.1513 - val_auc: 0.9990\n",
      "Epoch 153/200\n",
      " - 10s - loss: 0.3274 - auc: 0.9939 - val_loss: 0.1498 - val_auc: 0.9987\n",
      "Epoch 154/200\n",
      " - 10s - loss: 0.2964 - auc: 0.9935 - val_loss: 0.1479 - val_auc: 0.9990\n",
      "Epoch 155/200\n",
      " - 10s - loss: 0.2988 - auc: 0.9950 - val_loss: 0.1396 - val_auc: 0.9991\n",
      "Epoch 156/200\n",
      " - 10s - loss: 0.3004 - auc: 0.9949 - val_loss: 0.1492 - val_auc: 0.9991\n",
      "Epoch 157/200\n",
      " - 10s - loss: 0.2619 - auc: 0.9959 - val_loss: 0.1623 - val_auc: 0.9988\n",
      "Epoch 158/200\n",
      " - 10s - loss: 0.2480 - auc: 0.9964 - val_loss: 0.1462 - val_auc: 0.9989\n",
      "Epoch 159/200\n",
      " - 10s - loss: 0.3149 - auc: 0.9941 - val_loss: 0.1480 - val_auc: 0.9989\n",
      "Epoch 160/200\n",
      " - 10s - loss: 0.2837 - auc: 0.9948 - val_loss: 0.1503 - val_auc: 0.9989\n",
      "Epoch 161/200\n",
      " - 10s - loss: 0.2715 - auc: 0.9952 - val_loss: 0.1620 - val_auc: 0.9988\n",
      "Epoch 162/200\n",
      " - 10s - loss: 0.3047 - auc: 0.9948 - val_loss: 0.1510 - val_auc: 0.9992\n",
      "Epoch 163/200\n",
      " - 10s - loss: 0.3049 - auc: 0.9944 - val_loss: 0.1617 - val_auc: 0.9989\n",
      "Epoch 164/200\n",
      " - 10s - loss: 0.2684 - auc: 0.9963 - val_loss: 0.1804 - val_auc: 0.9983\n",
      "Epoch 165/200\n",
      " - 10s - loss: 0.3178 - auc: 0.9940 - val_loss: 0.1348 - val_auc: 0.9993\n",
      "Epoch 166/200\n",
      " - 10s - loss: 0.2774 - auc: 0.9955 - val_loss: 0.1614 - val_auc: 0.9991\n",
      "Epoch 167/200\n",
      " - 10s - loss: 0.2729 - auc: 0.9956 - val_loss: 0.1703 - val_auc: 0.9986\n",
      "Epoch 168/200\n",
      " - 10s - loss: 0.3053 - auc: 0.9940 - val_loss: 0.1765 - val_auc: 0.9985\n",
      "Epoch 169/200\n",
      " - 10s - loss: 0.2947 - auc: 0.9953 - val_loss: 0.1515 - val_auc: 0.9989\n",
      "Epoch 170/200\n",
      " - 10s - loss: 0.2569 - auc: 0.9968 - val_loss: 0.1510 - val_auc: 0.9990\n",
      "Epoch 171/200\n",
      " - 10s - loss: 0.3013 - auc: 0.9942 - val_loss: 0.1610 - val_auc: 0.9991\n",
      "Epoch 172/200\n",
      " - 10s - loss: 0.2814 - auc: 0.9962 - val_loss: 0.1522 - val_auc: 0.9990\n",
      "Epoch 173/200\n",
      " - 10s - loss: 0.2663 - auc: 0.9961 - val_loss: 0.1451 - val_auc: 0.9991\n",
      "Epoch 174/200\n",
      " - 10s - loss: 0.3099 - auc: 0.9947 - val_loss: 0.1345 - val_auc: 0.9994\n",
      "Epoch 175/200\n",
      " - 10s - loss: 0.2720 - auc: 0.9953 - val_loss: 0.1462 - val_auc: 0.9992\n",
      "Epoch 176/200\n",
      " - 10s - loss: 0.2693 - auc: 0.9954 - val_loss: 0.1563 - val_auc: 0.9989\n",
      "Epoch 177/200\n",
      " - 10s - loss: 0.3073 - auc: 0.9932 - val_loss: 0.1560 - val_auc: 0.9989\n",
      "Epoch 178/200\n",
      " - 10s - loss: 0.3330 - auc: 0.9934 - val_loss: 0.1452 - val_auc: 0.9991\n",
      "Epoch 179/200\n",
      " - 10s - loss: 0.3002 - auc: 0.9950 - val_loss: 0.1473 - val_auc: 0.9990\n",
      "Epoch 180/200\n",
      " - 10s - loss: 0.2833 - auc: 0.9948 - val_loss: 0.1694 - val_auc: 0.9991\n",
      "Epoch 181/200\n",
      " - 10s - loss: 0.2956 - auc: 0.9937 - val_loss: 0.1478 - val_auc: 0.9992\n",
      "Epoch 182/200\n",
      " - 10s - loss: 0.3176 - auc: 0.9931 - val_loss: 0.1510 - val_auc: 0.9992\n",
      "Epoch 183/200\n",
      " - 10s - loss: 0.2826 - auc: 0.9956 - val_loss: 0.1790 - val_auc: 0.9987\n",
      "Epoch 184/200\n",
      " - 10s - loss: 0.2983 - auc: 0.9953 - val_loss: 0.1484 - val_auc: 0.9989\n",
      "Epoch 185/200\n",
      " - 10s - loss: 0.2832 - auc: 0.9954 - val_loss: 0.1511 - val_auc: 0.9991\n",
      "Epoch 186/200\n",
      " - 10s - loss: 0.2703 - auc: 0.9959 - val_loss: 0.1397 - val_auc: 0.9991\n",
      "Epoch 187/200\n",
      " - 10s - loss: 0.2687 - auc: 0.9947 - val_loss: 0.1324 - val_auc: 0.9993\n",
      "Epoch 188/200\n",
      " - 10s - loss: 0.2573 - auc: 0.9958 - val_loss: 0.1364 - val_auc: 0.9990\n",
      "Epoch 189/200\n",
      " - 10s - loss: 0.2768 - auc: 0.9951 - val_loss: 0.1630 - val_auc: 0.9987\n",
      "Epoch 190/200\n",
      " - 10s - loss: 0.2805 - auc: 0.9949 - val_loss: 0.1464 - val_auc: 0.9991\n",
      "Epoch 191/200\n",
      " - 10s - loss: 0.2683 - auc: 0.9949 - val_loss: 0.1640 - val_auc: 0.9988\n",
      "Epoch 192/200\n",
      " - 10s - loss: 0.2653 - auc: 0.9962 - val_loss: 0.1573 - val_auc: 0.9988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/200\n",
      " - 10s - loss: 0.2887 - auc: 0.9954 - val_loss: 0.1441 - val_auc: 0.9993\n",
      "Epoch 194/200\n",
      " - 10s - loss: 0.2671 - auc: 0.9952 - val_loss: 0.1390 - val_auc: 0.9991\n",
      "Epoch 195/200\n",
      " - 10s - loss: 0.3237 - auc: 0.9924 - val_loss: 0.1531 - val_auc: 0.9990\n",
      "Epoch 196/200\n",
      " - 10s - loss: 0.2737 - auc: 0.9947 - val_loss: 0.1688 - val_auc: 0.9987\n",
      "Epoch 197/200\n",
      " - 10s - loss: 0.3081 - auc: 0.9947 - val_loss: 0.1505 - val_auc: 0.9991\n",
      "Epoch 198/200\n",
      " - 10s - loss: 0.2633 - auc: 0.9954 - val_loss: 0.1355 - val_auc: 0.9994\n",
      "Epoch 199/200\n",
      " - 10s - loss: 0.2781 - auc: 0.9956 - val_loss: 0.1413 - val_auc: 0.9989\n",
      "Epoch 200/200\n",
      " - 10s - loss: 0.2391 - auc: 0.9970 - val_loss: 0.1315 - val_auc: 0.9990\n",
      "SMOTETomek,MIT-BIH Normal Sinus Rhythm Data\n",
      "finish\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.utils import np_utils\n",
    "# CNN related\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.recurrent import GRU\n",
    "#from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.layers import Conv1D, MaxPooling1D, AtrousConvolution1D, RepeatVector\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras import regularizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import *\n",
    "from keras.optimizers import RMSprop, Adam, SGD, Nadam\n",
    "from keras.initializers import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE # doctest: +NORMALIZE_WHITESPACE\n",
    "from imblearn.over_sampling import RandomOverSampler # doctest: +NORMALIZE_WHITESPACE\n",
    "from imblearn.over_sampling import SVMSMOTE\n",
    "from imblearn.over_sampling import KMeansSMOTE\n",
    "from imblearn.over_sampling import BorderlineSMOTE # doctest: +NORMALIZE_WHITESPACE\n",
    "from imblearn.combine import SMOTETomek # doctest: +NORMALIZE_WHITESPACE\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "##################\n",
    "# AUC for a binary classifier\n",
    "def auc(y_true, y_pred):\n",
    "    ptas = tf.stack([binary_PTA(y_true,y_pred,k) for k in np.linspace(0, 1, 1000)],axis=0)\n",
    "    pfas = tf.stack([binary_PFA(y_true,y_pred,k) for k in np.linspace(0, 1, 1000)],axis=0)\n",
    "    pfas = tf.concat([tf.ones((1,)) ,pfas],axis=0)\n",
    "    binSizes = -(pfas[1:]-pfas[:-1])\n",
    "    s = ptas*binSizes\n",
    "    return K.sum(s, axis=0)\n",
    "    \n",
    "##################\n",
    "# PFA, prob false alert for binary classifier\n",
    "def binary_PFA(y_true, y_pred, threshold=K.variable(value=0.5)):\n",
    "    y_pred = K.cast(y_pred >= threshold, 'float32')\n",
    "    # N = total number of negative labels\n",
    "    N = K.sum(1 - y_true)\n",
    "    # FP = total number of false alerts, alerts from the negative class labels\n",
    "    FP = K.sum(y_pred - y_pred * y_true)\n",
    "    #print(FP/N)\n",
    "    return FP/N\n",
    "\n",
    "##################\n",
    "# P_TA prob true alerts for binary classifier\n",
    "def binary_PTA(y_true, y_pred, threshold=K.variable(value=0.5)):\n",
    "    y_pred = K.cast(y_pred >= threshold, 'float32')\n",
    "    # P = total number of positive labels\n",
    "    P = K.sum(y_true)\n",
    "    # TP = total number of correct alerts, alerts from the positive class labels\n",
    "    TP = K.sum(y_pred * y_true)\n",
    "    return TP/P\n",
    "\n",
    "class ecgcnn: \n",
    "    np.set_printoptions(threshold=np.inf)\n",
    "    def __init__(self, base_path, stkid, infosize, onehotsize ):\n",
    "        self.stkid = stkid\n",
    "        fname = base_path + stkid + '.csv'\n",
    "        self.INFOSIZE = infosize\n",
    "        self.ONEHOTSIZE = onehotsize\n",
    "        self.load_data(fname)\n",
    "        self.EMB_SIZE = self.INFOSIZE+self.ONEHOTSIZE\n",
    "        #self.ONEHOTSIZE = onehotsize\n",
    "        \n",
    "\n",
    "##################\n",
    "    def load_data(self, fname):\n",
    "        # load csv data\n",
    "        mat = pandas.read_csv(fname, sep=\",\", header=0, error_bad_lines=False).as_matrix()\n",
    "\n",
    "        self.info = []\n",
    "        self.sid=[]\n",
    "        for i in range(self.INFOSIZE):\n",
    "            self.info.append(self.matrix_col(mat, i))   \n",
    "        self.sid.append(self.matrix_col(mat,9))\n",
    "       # print(self.sid) \n",
    "        #x = self.find_category(self.sid)\n",
    "        #print(x)\n",
    "##################        \n",
    "    '''\n",
    "    def find_category0(self, sid):\n",
    "        print(sid[0][0])\n",
    "        y = list(map(int, sid[3:-1])) \n",
    "        #y = map(eval,sid[3:-1])\n",
    "        print(y)    \n",
    "        for n in range(len(sid)):\n",
    "            sidnum = [0]*51 \n",
    "            if ( y == 11 ):\n",
    "                print(\"456\") \n",
    "                sidnum [n]=sidnum [n]+1\n",
    "                print(sidnum)\n",
    "                return  sidnum\n",
    "    '''\n",
    "    def find_category(self, sid):\n",
    "        result = []\n",
    "        for sidstr in sid[0]:\n",
    "            index = int(sidstr.replace('sid', ''))\n",
    "            result.append(index)\n",
    "            \n",
    "        return result\n",
    "        \n",
    "    '''           \n",
    "            sidnum = [0]*51\n",
    "            #print(index)\n",
    "            sidnum[index-1] = 1\n",
    "            #print(sidnum)\n",
    "            result.append(sidnum)\n",
    "           \n",
    "            return result\n",
    "    ''' \n",
    "######################################################\n",
    "    def matrix_col(self, matrix, i):\n",
    "        return [row[i] for row in matrix]    \n",
    "    \n",
    "######################################################\n",
    "    def normalize(self, data):\n",
    "        #return (np.array(data)-np.mean(data))/np.std(data) \n",
    "        std = np.std(data)\n",
    "        if (std == 0):\n",
    "            data2 = np.zeros(len(data))\n",
    "            return data2\n",
    "        return (np.array(data)-np.mean(data))/std\n",
    "    \n",
    "######################################################\n",
    "    \n",
    "    def backtest_training_data(self,num,s):\n",
    "        x_train0, y_train_onehot = [], []  \n",
    "        x_train1, x_test1, y_train1, y_test1 = [], [], [], []\n",
    "        # normalize\n",
    "        nvals = []\n",
    "        for cval in self.info:\n",
    "            nvals.append(self.normalize(cval))\n",
    "        \n",
    "        # training preparation            \n",
    "        l2t = nvals\n",
    "        x_train0 = np.column_stack(l2t)\n",
    "        y_train_onehot = self.find_category(self.sid)\n",
    "\n",
    "        x_train = []\n",
    "        for rec in x_train0:\n",
    "            x_train.append(rec)\n",
    "        \n",
    "        x_train = np.array(x_train)\n",
    "        #y_train_onehot = np_utils.to_categorical(y_train)\n",
    "        y_train_onehot = np.array(y_train_onehot)\n",
    "\n",
    "        if num==0:\n",
    "            n = 40\n",
    "        if num==1:\n",
    "            n = 37\n",
    "        if num==2:\n",
    "            n = 16\n",
    "        if num==3:\n",
    "            n = 84\n",
    "        x_train1, x_test1, y_train1, y_test1 = train_test_split(x_train, y_train_onehot, test_size=0.2, random_state=None)\n",
    "        \n",
    "        \n",
    "        if s==0:\n",
    "            x_res, y_res = x_train1, y_train1\n",
    "        else:    \n",
    "            if s==1:\n",
    "                sm = SMOTE(random_state=0)\n",
    "            if s==2:\n",
    "                sm = SVMSMOTE(random_state=0)\n",
    "            if s==3:\n",
    "                sm = RandomOverSampler(random_state=0)\n",
    "            if s==4:\n",
    "                sm = BorderlineSMOTE(random_state=0) \n",
    "            if s==5:\n",
    "                sm = SMOTETomek(random_state=0)\n",
    "            #sm = KMeansSMOTE(random_state=0)  #X need 25 samples\n",
    "            \n",
    "            x_res, y_res = sm.fit_resample(x_train1, y_train1)\n",
    "            \n",
    "            #print(x_train)\n",
    "            #print('Resampled dataset shape %s' % Counter(y_res))\n",
    "\n",
    "        x_train_new = []\n",
    "        for rec in x_res:\n",
    "            x_train_new.append([rec])\n",
    "            #x_train_new.append(np.reshape(rec,(-1,self.EMB_SIZE)))\n",
    "        x_test_new = []\n",
    "        for rec1 in x_test1:\n",
    "            x_test_new.append([rec1])\n",
    "                \n",
    "        x_train_new = np.array(x_train_new)  \n",
    "        x_test_new = np.array(x_test_new)\n",
    "        #print(x_train_new)\n",
    "        \n",
    "        y_train_onehot_new = []\n",
    "        y_test_new = [] \n",
    "        y_test_new1 = [] \n",
    "        \n",
    "        for sid in y_res:\n",
    "            index = int(sid)\n",
    "            sidnum = [0]*n\n",
    "           \n",
    "            #print(index)\n",
    "            sidnum[index-1] = 1\n",
    "            #print(index)\n",
    "            #print(sidnum)\n",
    "            y_train_onehot_new.append(sidnum)  \n",
    "        for sidstr in y_test1:\n",
    "            index = int(sidstr)\n",
    "            sidnum1 = [0]*n\n",
    "            \n",
    "            #print(index)\n",
    "            sidnum1[index-1] = 1\n",
    "            #print(sidnum)\n",
    "            y_test_new.append(sidnum1) \n",
    "            y_test_new1.append([sidnum1])\n",
    "\n",
    "        return x_train_new, y_train_onehot_new, x_test_new, y_test_new, y_test_new1\n",
    "\n",
    "######################################################\n",
    "    def build_model(self,num):\n",
    "        return self.simple_model(num)\n",
    "\n",
    "######################################################\n",
    "    def simple_model(self,num):\n",
    "        model = Sequential()\n",
    "        model.add(Conv1D(input_shape=(1, self.EMB_SIZE), filters=128, kernel_size=16, padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU())\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(Conv1D(filters=64, kernel_size=8, padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU())\n",
    "        model.add(Dropout(0.5))\n",
    "       \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU())\n",
    "        if num==0:\n",
    "            model.add(Dense(40))\n",
    "        if num==1:\n",
    "            model.add(Dense(37))\n",
    "        if num==2:\n",
    "            model.add(Dense(16))\n",
    "        if num==3:\n",
    "            model.add(Dense(84))\n",
    "            \n",
    "        model.add(Activation('softmax'))\n",
    "\n",
    "        opt = Nadam(lr=0.002)\n",
    "        \n",
    "        model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=[auc])\n",
    "        #model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        #print(model.summary())\n",
    "        return model\n",
    "\n",
    "######################################################\n",
    "    def train_model(self, model, x_train, y_train_onehot, x_test1, y_test1 ):\n",
    "        model_name = 'cnn.'+self.stkid+'.model'\n",
    "        input_shape = x_train[0].shape\n",
    "        #reduce_lr = ReduceLROnPlateau(monitor='roc_auc_val', factor=0.8, patience=30, min_lr=0.000001, verbose=2)\n",
    "        reduce_lr = ReduceLROnPlateau(monitor='roc_accuracy', factor=0.8, patience=30, min_lr=0.000001, verbose=2)\n",
    "        checkpointer = ModelCheckpoint(filepath=model_name, verbose=0, save_best_only=True)\n",
    "        \n",
    "        train_history = model.fit(np.array(x_train),np.array(y_train_onehot), epochs = 200, batch_size = 10, verbose=2, \\\n",
    "                                  validation_data=(np.array(x_test1), np.array(y_test1)), callbacks=[reduce_lr, checkpointer], shuffle=True)\n",
    "        '''\n",
    "        train_history = model.fit(np.array(x_train),np.array(y_train_onehot), epochs = 200, batch_size = 100, verbose=0, \\\n",
    "                                   callbacks=[reduce_lr, checkpointer], shuffle=True)\n",
    "        '''\n",
    "        #show_train_history(train_history, 'accuracy', 'val_accuracy')\n",
    "        #show_train_history(train_history, 'auc', 'val_auc')\n",
    "        \n",
    "        #show_train_history(train_history, 'loss', 'val_loss')\n",
    "        return train_history\n",
    "\n",
    "######################################################\n",
    "    def do_backtest(self,num,s):\n",
    "\n",
    "        # cut data \n",
    "        x_train, y_train_onehot, x_test1, y_test1, y_test2 = self.backtest_training_data(num,s)\n",
    "        # build model \n",
    "        model = self.build_model(num)\n",
    "        train_history = self.train_model(model, x_train, y_train_onehot, x_test1, y_test1 )\n",
    "        \n",
    "        if num==0:\n",
    "            n = 40\n",
    "        if num==1:\n",
    "            n = 37\n",
    "        if num==2:\n",
    "            n = 16\n",
    "        if num==3:\n",
    "            n = 84\n",
    "            \n",
    "        count = 0\n",
    "        total = 0\n",
    "        #print(x_test1)\n",
    "        #print(np.array(y_test2))\n",
    "        #print(\"x : \"+str(x_test1.shape)+\" / y : \"+str(np.array(y_test2).shape))\n",
    "        for x_test, y_test in zip(x_test1, np.array(y_test2)):\n",
    "            \n",
    "            prediction = model.predict_classes(np.array([x_test]),verbose=0)\n",
    "            #print(proba[0], proba[1])\n",
    "            #print(datestr, prediction[0], y_test_onehot[0], scores[1], last_close)\n",
    "            \n",
    "      \n",
    "            index = int(prediction)+1\n",
    "            #print(\"prediction: \"+str(index))\n",
    "        \n",
    "            sidnum = [0]*n\n",
    "            #print(index)\n",
    "            sidnum[index-1] = 1\n",
    "            sidnum_x = np.array(sidnum)\n",
    "            \n",
    "            total += 1\n",
    "            \n",
    "            if (y_test[0][index-1] == sidnum_x[index-1]):\n",
    "                count += 1\n",
    "        if (total == 0):\n",
    "            return 0, 0\n",
    "        \n",
    "    \n",
    "        #print(total)\n",
    "        #print(count)\n",
    "        return count, total\n",
    "        \n",
    "######################################################\n",
    "\"\"\"\n",
    "def show_train_history(train_history, train, validation):\n",
    "    plt.plot(train_history.history[train])\n",
    "    #plt.plot(train_history.history[validation])\n",
    "    plt.title('Train History')\n",
    "    plt.ylabel(train)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()\n",
    "\"\"\"\n",
    "def main():\n",
    "    print(\"start\")\n",
    "    stkid = 'ALL_fiducial_2' \n",
    "    TID = 'fiducial'\n",
    "    DA = [\"AUSAIC Data\",\"MIT-BIH Arrhythmia Data\",\"MIT-BIH Normal Sinus Rhythm Data\",\"QT Data\"]\n",
    "    SMO = [\"Original\",\"SMOTE\",\"SVMSMOTE\",\"ROS\",\"BorderlineSMOTE\",\"SMOTETomek\"]\n",
    "    ADD = [\"/home/keg/桌面/ecg_data/AUSAIC Data/fiducial/\",\n",
    "          \"/home/keg/桌面/ecg_data/MIT-BIH Arrhythmia Data/fiducial/\",\n",
    "          \"/home/keg/桌面/ecg_data/MIT-BIH Normal Sinus Rhythm Data/fiducial/\",\n",
    "          \"/home/keg/桌面/ecg_data/QT Data/fiducial/\"]\n",
    "    NUMB = [0, 1, 2]\n",
    "    NUMBE = [0, 1, 2, 3, 4, 5]\n",
    "    info_size = 8\n",
    "    onehot_size = 0\n",
    "    #file = open('/home/keg/桌面/ecg_data/fiducial_accuracy-1.csv', 'w')\n",
    "    #file.write('Method,DATA,Ture/Total,accuracy'+'\\n')\n",
    "    for num in NUMB:\n",
    "        base_path = ADD[num]\n",
    "        #S=0  #SMOTE /S=1  #SVMSMOTE /S=2  #ROS  /S=3  #BorderlineSMOTE  /S=4  #SMOTETomek\n",
    "        for S in NUMBE:\n",
    "            ecg = ecgcnn(base_path, stkid, info_size, onehot_size )\n",
    "            count, total = ecg.do_backtest(num,S)\n",
    "            hitrate = 0.0\n",
    "            if (total > 0):\n",
    "                hitrate = float(count)/total\n",
    "                #print(SMO[S]+\",\"+DA[num]+\",(\"+str(count)+\"/\"+str(total)+\"),\"+str(hitrate))\n",
    "                print(SMO[S]+\",\"+DA[num])\n",
    "                plan =SMO[S]+\",\"+DA[num]+\",(\"+str(count)+\"/\"+str(total)+\"),\"+str(hitrate)+'\\n'\n",
    "                #file = open('/home/keg/桌面/ecg_data/fiducial_accuracy.txt', 'w')\n",
    "                #file.write(plan)\n",
    "    #file.close()\n",
    "    print(\"finish\")\n",
    "    #xt, yt = ecg.backtest_training_data()\n",
    "    #print(xt)\n",
    "    #print(yt[-1])\n",
    "    #for stkid in stklist:    \n",
    "    #    model = ecgcnn(base_path, stkid,info_size)\n",
    "                      \n",
    "if (__name__ == \"__main__\"):\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
